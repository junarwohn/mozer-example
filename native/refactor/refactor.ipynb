{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.dataflow_pattern import rewrite\n",
    "from tvm.relay.dataflow_pattern import *\n",
    "import numpy as np\n",
    "from tvm.relay import transform\n",
    "from tvm.relay.testing import run_opt_pass\n",
    "from tvm.relay import transform, build_module\n",
    "from tvm.relay import testing\n",
    "import tvm.testing\n",
    "# from SlicingMachine import TVMSlicer\n",
    "import mozer\n",
    "from mozer.slicer.SlicingMachine import TVMSlicer\n",
    "from mozer.slicer.Quantize import quantize\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import tvm\n",
    "import tvm.relay as relay\n",
    "from tvm.contrib import graph_executor \n",
    "import numpy as np\n",
    "import json\n",
    "import pygraphviz as pgv\n",
    "from argparse import ArgumentParser\n",
    "from tvm.relay.build_module import bind_params_by_name\n",
    "from tvm.relay.dataflow_pattern import *\n",
    "from tvm import rpc\n",
    "from tvm.autotvm.measure.measure_methods import set_cuda_target_arch\n",
    "from tensorflow import keras\n",
    "from tvm.contrib.download import download_testdata\n",
    "import subprocess\n",
    "from tvm.contrib import relay_viz\n",
    "from tvm.relay import build_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_split2(expr, split_conf, params=None):\n",
    "    \"\"\"Splitting the graph into a list of subgraphs\"\"\"\n",
    "\n",
    "    def get_dep_var(sub_var_dep):\n",
    "        return [var for var in sub_var_dep[len(sub_var_dep) - 1][\"ref_nodes\"]]\n",
    "\n",
    "    def parse_dependency(value, snode_dep, new_input_idx):\n",
    "        new_args = []\n",
    "        need_update = False\n",
    "        for var in value.args:\n",
    "            is_free_var = False\n",
    "            for dep in snode_dep[:-1]:\n",
    "                if var in dep[\"nodes\"]:\n",
    "                    # Mark the previous subgraph node as a dependency.\n",
    "                    dep[\"nodes\"][var] += 1\n",
    "                    dep[\"ref_nodes\"][var] = dep[\"nodes\"][var]\n",
    "                    # The var of this call is a free_var\n",
    "                    is_free_var = True\n",
    "            # if the var of this call is a free_var, recreate it and give it a fixed input name.\n",
    "            if is_free_var:\n",
    "                need_update = True\n",
    "                new_args.append(relay.var(f\"data_n_{new_input_idx}\", var.checked_type))\n",
    "                new_input_idx += 1\n",
    "            else:\n",
    "                new_args.append(var)\n",
    "        # if the 'tvm.relay.expr.Call' has a free_var, recreate it with new name as 'data_n_*'.\n",
    "        if need_update:\n",
    "            value = tvm.relay.expr.Call(\n",
    "                value.op, new_args, value.attrs, value.type_args, value.span\n",
    "            )\n",
    "        return value, snode_dep, new_input_idx\n",
    "\n",
    "    def merge_constant_expr(constant_expr, expr):\n",
    "        # merge constant express with a express\n",
    "        if not isinstance(constant_expr.body, tvm.relay.expr.Let):\n",
    "            return tvm.relay.expr.Let(constant_expr.var, constant_expr.value, expr)\n",
    "\n",
    "        return tvm.relay.expr.Let(\n",
    "            constant_expr.var, constant_expr.value, merge_constant_expr(constant_expr.body, expr)\n",
    "        )\n",
    "\n",
    "    def _recursion(anf, pipeline_mods, split_conf, constant_expr):\n",
    "        # Enumurate all operators of compute graph, then split the compute graph into a group of\n",
    "        # subgraph.\n",
    "        nonlocal operator_index_map\n",
    "        nonlocal new_input_idx\n",
    "        nonlocal snode_dep\n",
    "        # Get last element in snode_dep : current node's dependency\n",
    "        cur_node_dep = snode_dep[len(snode_dep) - 1]\n",
    "        # If function -> decouple\n",
    "        if isinstance(anf, tvm.relay.Function):\n",
    "            return tvm.relay.Function(\n",
    "                anf.params,\n",
    "                _recursion(anf.body, pipeline_mods, split_conf, constant_expr),\n",
    "                anf.ret_type,\n",
    "                anf.type_params,\n",
    "                anf.attrs,\n",
    "            )\n",
    "        # Function of Let\n",
    "        if isinstance(anf, tvm.relay.expr.Let):\n",
    "            value = anf.value\n",
    "            # record the constant expr to make sure all sugraphs can find correct constant.\n",
    "            if isinstance(value, tvm.relay.expr.Constant):\n",
    "                # cosntant_expr is initally None\n",
    "                if not constant_expr:\n",
    "                    constant_expr = tvm.relay.expr.Let(anf.var, value, anf.var)\n",
    "                else:\n",
    "                    constant_expr = tvm.relay.expr.Let(anf.var, value, constant_expr)\n",
    "            if isinstance(value, tvm.relay.expr.Call):\n",
    "                new_args = []\n",
    "                # build current var list\n",
    "                cur_node_dep[\"nodes\"][anf.var] = 0\n",
    "                # Get the dependency information of the nodes.\n",
    "                value, snode_dep, new_input_idx = parse_dependency(value, snode_dep, new_input_idx)\n",
    "                if isinstance(value.op, tvm.ir.Op):\n",
    "                    if value.op.name in operator_index_map:\n",
    "                        operator_index_map[value.op.name] += 1\n",
    "                    else:\n",
    "                        operator_index_map[value.op.name] = 0\n",
    "                    split_operator_name = split_conf[0][\"op_name\"] if split_conf else \"\"\n",
    "                    split_operator_index = split_conf[0][\"op_index\"] if split_conf else \"\"\n",
    "                    # if a operator name and repeating count in the network match with the values\n",
    "                    # of the 'split configuration', then this place is where we should do the\n",
    "                    # graph splitting.\n",
    "                    if (\n",
    "                        split_conf\n",
    "                        and split_operator_name in operator_index_map\n",
    "                        and operator_index_map[split_operator_name] >= split_operator_index\n",
    "                    ):\n",
    "                        # Do graph splitting.\n",
    "                        split_conf.pop(0)\n",
    "                        snode_dep.append({\"nodes\": {}, \"ref_nodes\": {}})\n",
    "                        ann = _recursion(\n",
    "                            anf.body,\n",
    "                            pipeline_mods,\n",
    "                            split_conf,\n",
    "                            constant_expr,\n",
    "                        )\n",
    "                        snode_dep.pop()\n",
    "                        dep_vars = get_dep_var(snode_dep)\n",
    "                        # When the nodes of the current subgraph are the depedency node of another\n",
    "                        # subgraph, we need to set them as the output of current subgraph.\n",
    "                        body = relay.Tuple(dep_vars) if len(dep_vars) > 1 else anf.var\n",
    "                        # when the operator of current subgraph uses previous subgraph constant\n",
    "                        # as the argument of a \"relay.expr.call\", such constant may become a free\n",
    "                        # varaible if the constant does not exist in the current subgraph.\n",
    "                        # merge the previous constant with current subgraph to avoid such issue.\n",
    "                        if constant_expr:\n",
    "                            ann = merge_constant_expr(constant_expr, ann)\n",
    "                        # ann = run_opt_pass(ann, transform.ToGraphNormalForm())\n",
    "                        # mod = tvm.IRModule.from_expr(ann)\n",
    "                        pipeline_mods.insert(0, ann)\n",
    "                        # Return the last node of the current subgraph.\n",
    "                        return tvm.relay.expr.Let(anf.var, value, body)\n",
    "            return tvm.relay.expr.Let(\n",
    "                anf.var,\n",
    "                value,\n",
    "                _recursion(anf.body, pipeline_mods, split_conf, constant_expr),\n",
    "            )\n",
    "        # Or End\n",
    "        else:\n",
    "            return anf\n",
    "    \n",
    "    def getting_inputs(mod):\n",
    "        name_hints = []\n",
    "        ann = run_opt_pass(mod.body, transform.ToGraphNormalForm())\n",
    "        mod = tvm.IRModule.from_expr(ann)\n",
    "        for param in mod['main'].params:\n",
    "            name_hints.append(param.name_hint)\n",
    "        return name_hints\n",
    "\n",
    "    def setting_outputs(anf, name_hints, outputs):\n",
    "        # Get last element in snode_dep : current node's dependency\n",
    "        # If function -> decouple\n",
    "        if isinstance(anf, tvm.relay.Function):\n",
    "            return tvm.relay.Function(\n",
    "                anf.params,\n",
    "                setting_outputs(anf.body, name_hints, outputs),\n",
    "                anf.ret_type,\n",
    "                anf.type_params,\n",
    "                anf.attrs,\n",
    "            )\n",
    "        # Function of Let\n",
    "        if isinstance(anf, tvm.relay.expr.Let):\n",
    "            value = anf.value\n",
    "            # print(anf.var.name_hint)\n",
    "            if anf.var.name_hint in name_hints:\n",
    "                outputs.append(anf)\n",
    "            # value, snode_dep, new_input_idx = parse_dependency(value, snode_dep, new_input_idx)\n",
    "            return tvm.relay.expr.Let(\n",
    "                anf.var,\n",
    "                value,\n",
    "                setting_outputs(anf.body, name_hints, outputs),\n",
    "            )\n",
    "        # Or End\n",
    "        else:\n",
    "            # new_map = \n",
    "            return anf\n",
    "\n",
    "    snode_dep = [{\"nodes\": {}, \"ref_nodes\": {}}]\n",
    "    pipeline_mods = []\n",
    "    operator_index_map = {}\n",
    "    # Used to tracking new input which caused by graph splitting.\n",
    "    new_input_idx = 0\n",
    "    constant_expr = None\n",
    "    subgraph_split_conf = split_conf.copy()\n",
    "    # Binding the parameters.\n",
    "    if params:\n",
    "        expr = build_module.bind_params_by_name(expr, params)\n",
    "    anf = run_opt_pass(expr, transform.ToANormalForm())\n",
    "    anf = run_opt_pass(anf, transform.InferType())\n",
    "    ann = _recursion(\n",
    "        anf,\n",
    "        pipeline_mods,\n",
    "        subgraph_split_conf,\n",
    "        constant_expr,\n",
    "    )\n",
    "    # ann = run_opt_pass(ann.body, transform.ToGraphNormalForm())\n",
    "    # mod = tvm.IRModule.from_expr(ann)\n",
    "    pipeline_mods.insert(0, ann.body)\n",
    "    inputs = []\n",
    "    for mod in pipeline_mods:\n",
    "        inputs.extend(getting_inputs(mod))\n",
    "    print(inputs)\n",
    "    total_outputs = []\n",
    "    for mod in pipeline_mods:\n",
    "        outputs = []\n",
    "        setting_outputs(mod, inputs, outputs)\n",
    "        total_outputs.append(outputs)\n",
    "    return pipeline_mods, total_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(expr, split_conf, params=None):\n",
    "    \"\"\"Splitting the graph into a list of subgraphs\"\"\"\n",
    "\n",
    "    def get_dep_var(sub_var_dep):\n",
    "        return [var for var in sub_var_dep[len(sub_var_dep) - 1][\"ref_nodes\"]]\n",
    "\n",
    "    def parse_dependency(value, snode_dep, new_input_idx):\n",
    "        new_args = []\n",
    "        need_update = False\n",
    "        for var in value.args:\n",
    "            is_free_var = False\n",
    "            for dep in snode_dep[:-1]:\n",
    "                if var in dep[\"nodes\"]:\n",
    "                    # Mark the previous subgraph node as a dependency.\n",
    "                    dep[\"nodes\"][var] += 1\n",
    "                    dep[\"ref_nodes\"][var] = dep[\"nodes\"][var]\n",
    "                    # The var of this call is a free_var\n",
    "                    is_free_var = True\n",
    "            # if the var of this call is a free_var, recreate it and give it a fixed input name.\n",
    "            if is_free_var:\n",
    "                need_update = True\n",
    "                new_args.append(relay.var(f\"data_n_{new_input_idx}\", var.checked_type))\n",
    "                new_input_idx += 1\n",
    "            else:\n",
    "                new_args.append(var)\n",
    "        # if the 'tvm.relay.expr.Call' has a free_var, recreate it with new name as 'data_n_*'.\n",
    "        if need_update:\n",
    "            value = tvm.relay.expr.Call(\n",
    "                value.op, new_args, value.attrs, value.type_args, value.span\n",
    "            )\n",
    "        return value, snode_dep, new_input_idx\n",
    "\n",
    "    def merge_constant_expr(constant_expr, expr):\n",
    "        # merge constant express with a express\n",
    "        if not isinstance(constant_expr.body, tvm.relay.expr.Let):\n",
    "            return tvm.relay.expr.Let(constant_expr.var, constant_expr.value, expr)\n",
    "\n",
    "        return tvm.relay.expr.Let(\n",
    "            constant_expr.var, constant_expr.value, merge_constant_expr(constant_expr.body, expr)\n",
    "        )\n",
    "\n",
    "    def _recursion(anf, pipeline_mods, split_conf, constant_expr):\n",
    "        # Enumurate all operators of compute graph, then split the compute graph into a group of\n",
    "        # subgraph.\n",
    "        nonlocal operator_index_map\n",
    "        nonlocal new_input_idx\n",
    "        nonlocal snode_dep\n",
    "        # Get last element in snode_dep : current node's dependency\n",
    "        cur_node_dep = snode_dep[len(snode_dep) - 1]\n",
    "        # If function -> decouple\n",
    "        if isinstance(anf, tvm.relay.Function):\n",
    "            return tvm.relay.Function(\n",
    "                anf.params,\n",
    "                _recursion(anf.body, pipeline_mods, split_conf, constant_expr),\n",
    "                anf.ret_type,\n",
    "                anf.type_params,\n",
    "                anf.attrs,\n",
    "            )\n",
    "        # Function of Let\n",
    "        if isinstance(anf, tvm.relay.expr.Let):\n",
    "            value = anf.value\n",
    "            # record the constant expr to make sure all sugraphs can find correct constant.\n",
    "            if isinstance(value, tvm.relay.expr.Constant):\n",
    "                # cosntant_expr is initally None\n",
    "                if not constant_expr:\n",
    "                    constant_expr = tvm.relay.expr.Let(anf.var, value, anf.var)\n",
    "                else:\n",
    "                    constant_expr = tvm.relay.expr.Let(anf.var, value, constant_expr)\n",
    "            if isinstance(value, tvm.relay.expr.Call):\n",
    "                print(anf.var.name_hint)\n",
    "                print(anf.var)\n",
    "                new_args = []\n",
    "                # build current var list\n",
    "                cur_node_dep[\"nodes\"][anf.var] = 0\n",
    "                # Get the dependency information of the nodes.\n",
    "                value, snode_dep, new_input_idx = parse_dependency(value, snode_dep, new_input_idx)\n",
    "                if isinstance(value.op, tvm.ir.Op):\n",
    "                    if value.op.name in operator_index_map:\n",
    "                        operator_index_map[value.op.name] += 1\n",
    "                    else:\n",
    "                        operator_index_map[value.op.name] = 0\n",
    "                    # split_operator_name = split_conf[0][\"op_name\"] if split_conf else \"\"\n",
    "                    # split_operator_index = split_conf[0][\"op_index\"] if split_conf else \"\"\n",
    "                    # if a operator name and repeating count in the network match with the values\n",
    "                    # of the 'split configuration', then this place is where we should do the\n",
    "                    # graph splitting.\n",
    "                    # if (\n",
    "                    #     split_conf\n",
    "                    #     and split_operator_name in operator_index_map\n",
    "                    #     and operator_index_map[split_operator_name] >= split_operator_index\n",
    "                    # ):\n",
    "                    #     # Do graph splitting.\n",
    "                    #     split_conf.pop(0)\n",
    "                    #     snode_dep.append({\"nodes\": {}, \"ref_nodes\": {}})\n",
    "                    #     ann = _recursion(\n",
    "                    #         anf.body,\n",
    "                    #         pipeline_mods,\n",
    "                    #         split_conf,\n",
    "                    #         constant_expr,\n",
    "                    #     )\n",
    "                    #     snode_dep.pop()\n",
    "                    #     dep_vars = get_dep_var(snode_dep)\n",
    "                    #     # When the nodes of the current subgraph are the depedency node of another\n",
    "                    #     # subgraph, we need to set them as the output of current subgraph.\n",
    "                    #     body = relay.Tuple(dep_vars) if len(dep_vars) > 1 else anf.var\n",
    "                    #     # when the operator of current subgraph uses previous subgraph constant\n",
    "                    #     # as the argument of a \"relay.expr.call\", such constant may become a free\n",
    "                    #     # varaible if the constant does not exist in the current subgraph.\n",
    "                    #     # merge the previous constant with current subgraph to avoid such issue.\n",
    "                    #     if constant_expr:\n",
    "                    #         ann = merge_constant_expr(constant_expr, ann)\n",
    "                    #     ann = run_opt_pass(ann, transform.ToGraphNormalForm())\n",
    "                    #     mod = tvm.IRModule.from_expr(ann)\n",
    "                    #     pipeline_mods.insert(0, mod)\n",
    "                    #     # Return the last node of the current subgraph.\n",
    "                        # return tvm.relay.expr.Let(anf.var, value, body)\n",
    "            return tvm.relay.expr.Let(\n",
    "                anf.var,\n",
    "                value,\n",
    "                _recursion(anf.body, pipeline_mods, split_conf, constant_expr),\n",
    "            )\n",
    "        # Or End\n",
    "        else:\n",
    "            return anf\n",
    "\n",
    "    snode_dep = [{\"nodes\": {}, \"ref_nodes\": {}}]\n",
    "    pipeline_mods = []\n",
    "    operator_index_map = {}\n",
    "    # Used to tracking new input which caused by graph splitting.\n",
    "    new_input_idx = 0\n",
    "    constant_expr = None\n",
    "    subgraph_split_conf = split_conf.copy()\n",
    "    # Binding the parameters.\n",
    "    if params:\n",
    "        expr = build_module.bind_params_by_name(expr, params)\n",
    "    anf = run_opt_pass(expr, transform.ToANormalForm())\n",
    "    anf = run_opt_pass(anf, transform.InferType())\n",
    "    ann = _recursion(\n",
    "        anf,\n",
    "        pipeline_mods,\n",
    "        subgraph_split_conf,\n",
    "        constant_expr,\n",
    "    )\n",
    "    ann = run_opt_pass(ann.body, transform.ToGraphNormalForm())\n",
    "    mod = tvm.IRModule.from_expr(ann)\n",
    "    pipeline_mods.insert(0, mod)\n",
    "    return pipeline_mods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_outputs(anf, outputs):\n",
    "    # Get last element in snode_dep : current node's dependency\n",
    "    # If function -> decouple\n",
    "    if isinstance(anf, tvm.relay.Function):\n",
    "        return tvm.relay.Function(\n",
    "            anf.params,\n",
    "            setting_outputs(anf.body, outputs),\n",
    "            anf.ret_type,\n",
    "            anf.type_params,\n",
    "            anf.attrs,\n",
    "        )\n",
    "    # Function of Let\n",
    "    if isinstance(anf, tvm.relay.expr.Let):\n",
    "        value = anf.value\n",
    "        # print(anf.var.name_hint)\n",
    "        # if anf.var.name_hint in name_hints:\n",
    "            # outputs.append(anf)\n",
    "        # value, snode_dep, new_input_idx = parse_dependency(value, snode_dep, new_input_idx)\n",
    "        return tvm.relay.expr.Let(\n",
    "            anf.var,\n",
    "            value,\n",
    "            setting_outputs(anf.body, outputs),\n",
    "        )\n",
    "    # Or End\n",
    "    else:\n",
    "        new_outputs = []\n",
    "        for o in outputs:\n",
    "            new_outputs.append(o.var)\n",
    "        # for o in outputs:\n",
    "        #     new_outputs.append(tvm.relay.expr.Let(\n",
    "        #             o.var,\n",
    "        #             o.value,\n",
    "        #             o.body,\n",
    "        #     ))\n",
    "        new_map = tvm.relay.expr.Tuple(new_outputs)\n",
    "        return new_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.dataflow_pattern import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetOutputCallback(DFPatternCallback):\n",
    "    def __init__(self, name_hints=[],require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        self.pattern = wildcard()\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        try:\n",
    "            print(type(pre))\n",
    "            print(pre.name_hint)\n",
    "        except:\n",
    "            pass\n",
    "        return pre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./simple_model.h5\"\n",
    "input_data = np.random.normal(0,1,(1,256,256,3)).astype(np.float32)\n",
    "model_keras = tf.keras.models.load_model(base_path)\n",
    "# tvm result\n",
    "input_data = input_data.transpose([0, 3, 1, 2])\n",
    "shape_dict = {\"input_1\": input_data.shape}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_keras(model_keras, shape_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(32, 16, 3, 3), float32], %v_param_4: Tensor[(32), float32], %v_param_5: Tensor[(64, 32, 3, 3), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 32, 3, 3), float32], %v_param_8: Tensor[(32), float32], %v_param_9: Tensor[(96, 16, 3, 3), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(48, 1, 3, 3), float32], %v_param_12: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %3 = nn.conv2d(%2, %v_param_3, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]);\n",
       "  %4 = nn.bias_add(%3, %v_param_4);\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %6 = nn.conv2d(%5, %v_param_5, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);\n",
       "  %7 = nn.bias_add(%6, %v_param_6);\n",
       "  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %9 = nn.conv2d_transpose(%8, %v_param_7, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %10 = nn.bias_add(%9, %v_param_8);\n",
       "  %11 = (%10, %7);\n",
       "  %12 = concatenate(%11, axis=1);\n",
       "  %13 = nn.conv2d_transpose(%12, %v_param_9, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %14 = nn.bias_add(%13, %v_param_10);\n",
       "  %15 = (%14, %4);\n",
       "  %16 = concatenate(%15, axis=1);\n",
       "  %17 = nn.conv2d_transpose(%16, %v_param_11, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  nn.bias_add(%17, %v_param_12)\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.expr.Call"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(upc0.match_node[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = upc0.match_node[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nn.bias_add'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nn.conv2d'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.args[0].op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetCallback(DFPatternCallback):\n",
    "    \"\"\"\n",
    "    A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    \"\"\"\n",
    "    def __init__(self, match_node, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "        # self.x = wildcard()\n",
    "        # self.tuple_get_item_node = is_tuple([wildcard(), self.x])\n",
    "        # self.pattern_1 = self.tuple\n",
    "\n",
    "        self.pattern = is_op(match_node[0].op.name)(wildcard(), wildcard())\n",
    "        # self.pattern = is_op(match_node[0].op.name)\n",
    "        self.match_node = match_node\n",
    "        self.tmp = []\n",
    "\n",
    "    def quant(self, node):\n",
    "        # cast_to_int8 = relay.cast(\n",
    "        #     relay.clip(\n",
    "        #         relay.round(\n",
    "        #             relay.multiply(node, relay.const(8.0))\n",
    "        #         ), \n",
    "        #         a_min=-127.0, a_max=127.0\n",
    "        #     ),\n",
    "        #     dtype=\"int8\"\n",
    "        # )\n",
    "\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(\n",
    "                        relay.subtract(node, relay.const(18.0))\n",
    "                        , relay.const(7.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        result_node = relay.annotation.stop_fusion(cast_to_int8)\n",
    "        self.tmp.append(result_node)\n",
    "        return result_node\n",
    "\n",
    "    def dequant(self, node):\n",
    "        # cast_to_float32 = relay.divide(\n",
    "        #     relay.cast(node, dtype='float32'), relay.const(8.0)\n",
    "        # )\n",
    "        cast_to_float32 = relay.add(\n",
    "                relay.divide(\n",
    "                relay.cast(node, dtype='float32'), relay.const(7.0))\n",
    "            , relay.const(18.0)\n",
    "        )\n",
    "        return cast_to_float32\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        if self.pattern.match(pre):\n",
    "            # print(type(post))\n",
    "            # # return post\n",
    "            if pre in self.match_node:\n",
    "                print(\"sd\")\n",
    "                return self.dequant(self.quant(post))\n",
    "        return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(32, 16, 3, 3), float32], %v_param_4: Tensor[(32), float32], %v_param_5: Tensor[(64, 32, 3, 3), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 32, 3, 3), float32], %v_param_8: Tensor[(32), float32], %v_param_9: Tensor[(96, 16, 3, 3), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(48, 1, 3, 3), float32], %v_param_12: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %3 = nn.conv2d(%2, %v_param_3, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]);\n",
       "  %4 = nn.bias_add(%3, %v_param_4);\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %6 = nn.conv2d(%5, %v_param_5, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);\n",
       "  %7 = nn.bias_add(%6, %v_param_6);\n",
       "  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %9 = nn.conv2d_transpose(%8, %v_param_7, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %10 = nn.bias_add(%9, %v_param_8);\n",
       "  %11 = (%10, %7);\n",
       "  %12 = concatenate(%11, axis=1);\n",
       "  %13 = nn.conv2d_transpose(%12, %v_param_9, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %14 = nn.bias_add(%13, %v_param_10);\n",
       "  %15 = (%14, %4);\n",
       "  %16 = concatenate(%15, axis=1);\n",
       "  %17 = nn.conv2d_transpose(%16, %v_param_11, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  nn.bias_add(%17, %v_param_12)\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upc0 = mozer.slicer.Quantize.UnetPreProcessCallback()\n",
    "rewrite(upc0, mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd\n",
      "sd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(32, 16, 3, 3), float32], %v_param_4: Tensor[(32), float32], %v_param_5: Tensor[(64, 32, 3, 3), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 32, 3, 3), float32], %v_param_8: Tensor[(32), float32], %v_param_9: Tensor[(96, 16, 3, 3), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(48, 1, 3, 3), float32], %v_param_12: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %3 = nn.conv2d(%2, %v_param_3, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]);\n",
       "  %4 = nn.bias_add(%3, %v_param_4);\n",
       "  %5 = subtract(%4, 18f);\n",
       "  %6 = multiply(%5, 7f);\n",
       "  %7 = round(%6);\n",
       "  %8 = clip(%7, a_min=-127f, a_max=127f);\n",
       "  %9 = cast(%8, dtype=\"int8\");\n",
       "  %10 = annotation.stop_fusion(%9);\n",
       "  %11 = cast(%10, dtype=\"float32\");\n",
       "  %12 = divide(%11, 7f);\n",
       "  %13 = add(%12, 18f);\n",
       "  %14 = nn.max_pool2d(%13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %15 = nn.conv2d(%14, %v_param_5, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);\n",
       "  %16 = nn.bias_add(%15, %v_param_6);\n",
       "  %17 = subtract(%16, 18f);\n",
       "  %18 = multiply(%17, 7f);\n",
       "  %19 = round(%18);\n",
       "  %20 = clip(%19, a_min=-127f, a_max=127f);\n",
       "  %21 = cast(%20, dtype=\"int8\");\n",
       "  %22 = annotation.stop_fusion(%21);\n",
       "  %23 = cast(%22, dtype=\"float32\");\n",
       "  %24 = divide(%23, 7f);\n",
       "  %25 = add(%24, 18f);\n",
       "  %26 = nn.max_pool2d(%25, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %27 = nn.conv2d_transpose(%26, %v_param_7, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %28 = nn.bias_add(%27, %v_param_8);\n",
       "  %29 = (%28, %25);\n",
       "  %30 = concatenate(%29, axis=1);\n",
       "  %31 = nn.conv2d_transpose(%30, %v_param_9, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %32 = nn.bias_add(%31, %v_param_10);\n",
       "  %33 = (%32, %13);\n",
       "  %34 = concatenate(%33, axis=1);\n",
       "  %35 = nn.conv2d_transpose(%34, %v_param_11, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  nn.bias_add(%35, %v_param_12)\n",
       "}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upc1 = UnetCallback(upc0.match_node)\n",
    "rewrite(upc1, mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nn.bias_add'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upc0.match_node[0].op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31c760d8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x31c733c8), [])], relay.attrs.MaxPool2DAttrs(0x4244f28), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31caee98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x4623bb8), [])], relay.attrs.MaxPool2DAttrs(0x45ffa08), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31caf398), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31caa5b8), [])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_expr(upc0.match_node[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "[CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x318520d8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x31825598), [])], relay.attrs.MaxPool2DAttrs(0x41d28c8), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31825698), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x419fa08), [])], relay.attrs.MaxPool2DAttrs(0x31858fb8), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31843a18), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31875428), [])], relay.attrs.MaxPool2DAttrs(0x3183c1c8), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x4181988), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x4182038), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x318520d8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x31825598), [])], relay.attrs.MaxPool2DAttrs(0x41d28c8), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31825698), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x419fa08), [])], relay.attrs.MaxPool2DAttrs(0x31858fb8), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31843a18), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31875428), [])])], relay.attrs.ConcatenateAttrs(0x30bf60d8), []), CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x318520d8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x31825598), [])], relay.attrs.MaxPool2DAttrs(0x41d28c8), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31825698), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x419fa08), [])], relay.attrs.MaxPool2DAttrs(0x31858fb8), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31843a18), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31875428), [])], relay.attrs.MaxPool2DAttrs(0x3183c1c8), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x4181988), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x4182038), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x318520d8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x31825598), [])], relay.attrs.MaxPool2DAttrs(0x41d28c8), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31825698), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x419fa08), [])], relay.attrs.MaxPool2DAttrs(0x31858fb8), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31843a18), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31875428), [])])], relay.attrs.ConcatenateAttrs(0x30bf60d8), []), Var(_param_9, ty=TensorType([96, 16, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x31854618), []), Var(_param_10, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x3181ee08), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x318520d8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x31825598), [])], relay.attrs.MaxPool2DAttrs(0x41d28c8), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31825698), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x419fa08), [])])], relay.attrs.ConcatenateAttrs(0x318452c8), [])]\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(32, 16, 3, 3), float32], %v_param_4: Tensor[(32), float32], %v_param_5: Tensor[(64, 32, 3, 3), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 32, 3, 3), float32], %v_param_8: Tensor[(32), float32], %v_param_9: Tensor[(96, 16, 3, 3), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(48, 1, 3, 3), float32], %v_param_12: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %3 = nn.conv2d(%2, %v_param_3, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]);\n",
       "  %4 = nn.bias_add(%3, %v_param_4);\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %6 = nn.conv2d(%5, %v_param_5, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);\n",
       "  %7 = nn.bias_add(%6, %v_param_6);\n",
       "  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %9 = nn.conv2d_transpose(%8, %v_param_7, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %10 = nn.bias_add(%9, %v_param_8);\n",
       "  %11 = (%10, %7);\n",
       "  %12 = concatenate(%11, axis=1);\n",
       "  %13 = nn.conv2d_transpose(%12, %v_param_9, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %14 = nn.bias_add(%13, %v_param_10);\n",
       "  %15 = (%14, %4);\n",
       "  %16 = concatenate(%15, axis=1);\n",
       "  %17 = nn.conv2d_transpose(%16, %v_param_11, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %18 = nn.bias_add(%17, %v_param_12);\n",
       "  (%18,)\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantize(mod, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upc = mozer.slicer.Quantize.UnetPreProcessCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rewrite(upc, mod['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), []),\n",
       " CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upc.match_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upc.match_node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_nodes = []\n",
    "parent_nodes = []\n",
    "\n",
    "def collector(mod):\n",
    "    \"\"\"Count the number of occurrences of each operator in the module\"\"\"\n",
    "    ret = {}\n",
    "    concatenate_nodes = []\n",
    "    parent_nodes = []\n",
    "    def visit(node):\n",
    "        global node2\n",
    "\n",
    "        var2 = wildcard()\n",
    "        tuple_node = is_tuple([wildcard(),var2])\n",
    "        concat_node = is_op('concatenate')(tuple_node)\n",
    "        pattern = concat_node\n",
    "        if pattern.match(node):\n",
    "            concatenate_nodes.append(node)\n",
    "            parent_nodes.append(node.args[0].fields[1])\n",
    "            print(type(node))\n",
    "            print(node.op.name)\n",
    "            # op_name = node.op.name\n",
    "\n",
    "    relay.analysis.post_order_visit(mod[\"main\"], visit)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.expr.Call'>\n",
      "concatenate\n",
      "<class 'tvm.relay.expr.Call'>\n",
      "concatenate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collector(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_nodes == upc.match_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_nodes == upc.match_node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])], relay.attrs.MaxPool2DAttrs(0x4692c28), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x4effb78), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x325436b8), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])])], relay.attrs.ConcatenateAttrs(0x3253c498), [])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upc.match_node2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_nodes == upc.match_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])], relay.attrs.MaxPool2DAttrs(0x4692c28), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x4effb78), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x325436b8), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])])], relay.attrs.ConcatenateAttrs(0x3253c498), []), Var(_param_9, ty=TensorType([96, 16, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x32552898), []), Var(_param_10, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x7229b68), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])])], relay.attrs.ConcatenateAttrs(0x32594568), [])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Op(concatenate),\n",
       " [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])], relay.attrs.MaxPool2DAttrs(0x4692c28), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x4effb78), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x325436b8), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])])], relay.attrs.ConcatenateAttrs(0x3253c498), []), Var(_param_9, ty=TensorType([96, 16, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x32552898), []), Var(_param_10, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x7229b68), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])])])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2.op, node2.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu = node2.args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu.fields[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])], relay.attrs.MaxPool2DAttrs(0x4692c28), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x4effb78), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x325436b8), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4eeded8), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x325a3be8), [])], relay.attrs.MaxPool2DAttrs(0x4effe88), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3254c718), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x3261bd58), [])], relay.attrs.MaxPool2DAttrs(0x325adf68), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x4f00318), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x325a33c8), [])])], relay.attrs.ConcatenateAttrs(0x3253c498), []), Var(_param_9, ty=TensorType([96, 16, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x32552898), []), Var(_param_10, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x7229b68), [])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu.fields[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = quantize(mod, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(32, 16, 3, 3), float32], %v_param_4: Tensor[(32), float32], %v_param_5: Tensor[(64, 32, 3, 3), float32], %v_param_6: Tensor[(64), float32], %v_param_7: Tensor[(64, 32, 3, 3), float32], %v_param_8: Tensor[(32), float32], %v_param_9: Tensor[(96, 16, 3, 3), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(48, 1, 3, 3), float32], %v_param_12: Tensor[(1), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %3 = subtract(%2, 18f);\n",
       "  %4 = multiply(%3, 7f);\n",
       "  %5 = round(%4);\n",
       "  %6 = clip(%5, a_min=-127f, a_max=127f);\n",
       "  %7 = cast(%6, dtype=\"int8\");\n",
       "  %8 = annotation.stop_fusion(%7);\n",
       "  %9 = cast(%8, dtype=\"float32\");\n",
       "  %10 = divide(%9, 7f);\n",
       "  %11 = add(%10, 18f);\n",
       "  %12 = nn.conv2d(%11, %v_param_3, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]);\n",
       "  %13 = nn.bias_add(%12, %v_param_4);\n",
       "  %14 = nn.max_pool2d(%13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %15 = subtract(%14, 18f);\n",
       "  %16 = multiply(%15, 7f);\n",
       "  %17 = round(%16);\n",
       "  %18 = clip(%17, a_min=-127f, a_max=127f);\n",
       "  %19 = cast(%18, dtype=\"int8\");\n",
       "  %20 = annotation.stop_fusion(%19);\n",
       "  %21 = cast(%20, dtype=\"float32\");\n",
       "  %22 = divide(%21, 7f);\n",
       "  %23 = add(%22, 18f);\n",
       "  %24 = nn.conv2d(%23, %v_param_5, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]);\n",
       "  %25 = nn.bias_add(%24, %v_param_6);\n",
       "  %26 = nn.max_pool2d(%25, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]);\n",
       "  %27 = subtract(%26, 18f);\n",
       "  %28 = multiply(%27, 7f);\n",
       "  %29 = round(%28);\n",
       "  %30 = clip(%29, a_min=-127f, a_max=127f);\n",
       "  %31 = cast(%30, dtype=\"int8\");\n",
       "  %32 = annotation.stop_fusion(%31);\n",
       "  %33 = cast(%32, dtype=\"float32\");\n",
       "  %34 = divide(%33, 7f);\n",
       "  %35 = add(%34, 18f);\n",
       "  %36 = nn.conv2d_transpose(%35, %v_param_7, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %37 = nn.bias_add(%36, %v_param_8);\n",
       "  %38 = (%37, %25);\n",
       "  %39 = concatenate(%38, axis=1);\n",
       "  %40 = subtract(%39, 18f);\n",
       "  %41 = multiply(%40, 7f);\n",
       "  %42 = round(%41);\n",
       "  %43 = clip(%42, a_min=-127f, a_max=127f);\n",
       "  %44 = cast(%43, dtype=\"int8\");\n",
       "  %45 = annotation.stop_fusion(%44);\n",
       "  %46 = cast(%45, dtype=\"float32\");\n",
       "  %47 = divide(%46, 7f);\n",
       "  %48 = add(%47, 18f);\n",
       "  %49 = nn.conv2d_transpose(%48, %v_param_9, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %50 = nn.bias_add(%49, %v_param_10);\n",
       "  %51 = (%50, %13);\n",
       "  %52 = concatenate(%51, axis=1);\n",
       "  %53 = subtract(%52, 18f);\n",
       "  %54 = multiply(%53, 7f);\n",
       "  %55 = round(%54);\n",
       "  %56 = clip(%55, a_min=-127f, a_max=127f);\n",
       "  %57 = cast(%56, dtype=\"int8\");\n",
       "  %58 = annotation.stop_fusion(%57);\n",
       "  %59 = cast(%58, dtype=\"float32\");\n",
       "  %60 = divide(%59, 7f);\n",
       "  %61 = add(%60, 18f);\n",
       "  %62 = nn.conv2d_transpose(%61, %v_param_11, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\");\n",
       "  %63 = nn.bias_add(%62, %v_param_12);\n",
       "  (%63, %57, %44, %31, %19, %7)\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_1', 'x_0', 'data_n_0', 'x_8']\n"
     ]
    }
   ],
   "source": [
    "split_config = [{\"op_name\": \"annotation.stop_fusion\", \"op_index\": 0}]\n",
    "# print(mod['main'])\n",
    "subgraphs, outputs = graph_split2(out, split_config, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n",
      "let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n",
      "let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n",
      "let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_21: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_22: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = subtract(%x_20, %x_21) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_23: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_24: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = multiply(%x_22, %x_23) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_25: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = round(%x_24) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_26: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = clip(%x_25, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_27: Tensor[(1, 96, 64, 64), int8] /* ty=Tensor[(1, 96, 64, 64), int8] */ = cast(%x_26, dtype=\"int8\") /* ty=Tensor[(1, 96, 64, 64), int8] */;\n",
      "let %x_28: Tensor[(1, 96, 64, 64), int8] /* ty=Tensor[(1, 96, 64, 64), int8] */ = annotation.stop_fusion(%x_27) /* ty=Tensor[(1, 96, 64, 64), int8] */;\n",
      "%x_28\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[0].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_23: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_21: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(32), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(32), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(16), float32] */;\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "free_var %data_n_0: Tensor[(1, 96, 64, 64), int8];\n",
      "let %x_29: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = cast(%data_n_0, dtype=\"float32\");\n",
      "let %x_30: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_31: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = divide(%x_29, %x_30) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_32: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_33: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = add(%x_31, %x_32) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_34: Tensor[(96, 16, 3, 3), float32] /* ty=Tensor[(96, 16, 3, 3), float32] */ = meta[relay.Constant][8] /* ty=Tensor[(96, 16, 3, 3), float32] */;\n",
      "let %x_35: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.conv2d_transpose(%x_33, %x_34, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "let %x_36: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][9] /* ty=Tensor[(16), float32] */;\n",
      "let %x_37: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.bias_add(%x_35, %x_36) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "free_var %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_38: (Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */ = (%x_37, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
      "let %x_39: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = concatenate(%x_38, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_40: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_41: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = subtract(%x_39, %x_40) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_42: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_43: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = multiply(%x_41, %x_42) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_44: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = round(%x_43) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_45: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = clip(%x_44, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_46: Tensor[(1, 48, 128, 128), int8] /* ty=Tensor[(1, 48, 128, 128), int8] */ = cast(%x_45, dtype=\"int8\") /* ty=Tensor[(1, 48, 128, 128), int8] */;\n",
      "let %x_47: Tensor[(1, 48, 128, 128), int8] /* ty=Tensor[(1, 48, 128, 128), int8] */ = annotation.stop_fusion(%x_46) /* ty=Tensor[(1, 48, 128, 128), int8] */;\n",
      "let %x_48: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = cast(%x_47, dtype=\"float32\") /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_49: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_50: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = divide(%x_48, %x_49) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_51: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_52: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = add(%x_50, %x_51) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_53: Tensor[(48, 1, 3, 3), float32] /* ty=Tensor[(48, 1, 3, 3), float32] */ = meta[relay.Constant][10] /* ty=Tensor[(48, 1, 3, 3), float32] */;\n",
      "let %x_54: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.conv2d_transpose(%x_52, %x_53, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_55: Tensor[(1), float32] /* ty=Tensor[(1), float32] */ = meta[relay.Constant][11] /* ty=Tensor[(1), float32] */;\n",
      "let %x_56: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.bias_add(%x_54, %x_55) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_57: (Tensor[(1, 1, 256, 256), float32],) /* ty=(Tensor[(1, 1, 256, 256), float32],) */ = (%x_56,) /* ty=(Tensor[(1, 1, 256, 256), float32],) */;\n",
      "%x_57\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[1].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = subgraphs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "<class 'tvm.relay.expr.Let'> has no attribute free_vars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aa\u001b[39m.\u001b[39;49mfree_vars()\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/runtime/object.py:67\u001b[0m, in \u001b[0;36mObject.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_node_api\u001b[39m.\u001b[39mNodeGetAttr(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)), name)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: <class 'tvm.relay.expr.Let'> has no attribute free_vars"
     ]
    }
   ],
   "source": [
    "aa.free_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(32), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(32), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(16), float32] */;\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "let %x_21: Tensor[(96, 16, 3, 3), float32] /* ty=Tensor[(96, 16, 3, 3), float32] */ = meta[relay.Constant][8] /* ty=Tensor[(96, 16, 3, 3), float32] */;\n",
      "free_var %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_22: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.conv2d_transpose(%x_20, %x_21, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "let %x_23: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][9] /* ty=Tensor[(16), float32] */;\n",
      "let %x_24: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.bias_add(%x_22, %x_23) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "free_var %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_25: (Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */ = (%x_24, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
      "let %x_26: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = concatenate(%x_25, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_27: Tensor[(48, 1, 3, 3), float32] /* ty=Tensor[(48, 1, 3, 3), float32] */ = meta[relay.Constant][10] /* ty=Tensor[(48, 1, 3, 3), float32] */;\n",
      "let %x_28: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.conv2d_transpose(%x_26, %x_27, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_29: Tensor[(1), float32] /* ty=Tensor[(1), float32] */ = meta[relay.Constant][11] /* ty=Tensor[(1), float32] */;\n",
      "let %x_30: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.bias_add(%x_28, %x_29) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "%x_30\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[1].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.var.name_hint for o in outputs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][0].var.name_hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n",
      "let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n",
      "let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n",
      "let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "%x_20\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[0].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = [outputs[0][1:]]\n",
    "len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modmod = setting_outputs(subgraphs[0], outputs[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetNode(Var(x_0, ty=TensorType([16, 3, 3, 3], float32)), Constant([[[[ 3.23163867e-02 -8.54633600e-02  5.41195720e-02]\n",
       "   [-1.10573828e-01  1.81553543e-01 -1.22144818e-04]\n",
       "   [ 2.55260766e-02  7.36784637e-02  1.07363641e-01]]\n",
       "\n",
       "  [[ 2.55233049e-02 -4.54409420e-02  1.67028517e-01]\n",
       "   [ 1.45357460e-01 -1.00949802e-01  7.94526637e-02]\n",
       "   [-1.49513945e-01  1.69569105e-02 -5.45993596e-02]]\n",
       "\n",
       "  [[-1.71270907e-01 -1.04798146e-01 -7.64890388e-02]\n",
       "   [-3.08729708e-03  8.45972598e-02 -3.27159166e-02]\n",
       "   [-1.12808652e-01 -7.80549943e-02  1.27093047e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.79601535e-01 -3.15128714e-02  3.91178727e-02]\n",
       "   [ 1.68302536e-01 -1.86983153e-01 -1.29431516e-01]\n",
       "   [ 7.07907379e-02 -5.24235666e-02 -2.14526057e-02]]\n",
       "\n",
       "  [[-1.49425566e-01  1.06974870e-01  1.21452183e-01]\n",
       "   [-3.09053659e-02  1.61907017e-01  1.01942331e-01]\n",
       "   [-1.82749078e-01 -1.50260255e-01 -9.02489349e-02]]\n",
       "\n",
       "  [[ 1.36263520e-02  5.32492995e-03  6.63298666e-02]\n",
       "   [-7.51340613e-02 -1.39353558e-01  7.36561418e-02]\n",
       "   [ 9.17883217e-02 -9.86345112e-03  1.52955800e-01]]]\n",
       "\n",
       "\n",
       " [[[ 2.13009864e-02  1.97265893e-02 -9.45521891e-03]\n",
       "   [ 2.66401619e-02  6.64318204e-02 -5.04366457e-02]\n",
       "   [-3.13195288e-02  8.30757916e-02 -1.36988997e-01]]\n",
       "\n",
       "  [[ 1.63736790e-01 -3.15981656e-02  7.50636458e-02]\n",
       "   [-1.42437190e-01 -1.23402961e-01  2.17434764e-02]\n",
       "   [ 9.64652300e-02 -8.68084654e-02 -9.02800262e-03]]\n",
       "\n",
       "  [[-1.01768948e-01  6.33873343e-02  7.77019560e-03]\n",
       "   [ 9.59634781e-02  1.81303084e-01  1.68824941e-01]\n",
       "   [-5.29856980e-02  4.81943637e-02 -7.51121342e-03]]]\n",
       "\n",
       "\n",
       " [[[ 1.85624272e-01  1.26410723e-02 -4.69885021e-02]\n",
       "   [ 1.31377161e-01  1.20458394e-01 -1.76296934e-01]\n",
       "   [ 1.14306152e-01  2.60501653e-02  1.43022805e-01]]\n",
       "\n",
       "  [[-8.49472657e-02  1.73936397e-01  1.66811049e-01]\n",
       "   [-8.02976787e-02 -8.55044872e-02 -5.39514422e-03]\n",
       "   [-8.56521353e-02  4.48296368e-02 -1.34362057e-01]]\n",
       "\n",
       "  [[-5.33646792e-02  1.81859225e-01 -9.99502242e-02]\n",
       "   [-5.50511777e-02 -3.37825716e-03 -9.55829322e-02]\n",
       "   [ 1.68427318e-01 -1.84786871e-01  1.06600076e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.75437063e-01  1.41930699e-01  1.37000918e-01]\n",
       "   [ 6.71393573e-02 -1.15836464e-01 -9.71407145e-02]\n",
       "   [ 1.50851011e-01 -3.45225483e-02  1.65536791e-01]]\n",
       "\n",
       "  [[-4.98251617e-02  1.47754252e-01 -1.81763440e-01]\n",
       "   [ 1.70889974e-01 -7.70533159e-02 -2.05524266e-03]\n",
       "   [-1.60784572e-02  1.16744578e-01 -4.57684845e-02]]\n",
       "\n",
       "  [[-7.69499764e-02  9.30011570e-02 -5.64735085e-02]\n",
       "   [-8.08795094e-02  1.17174089e-02 -5.56611419e-02]\n",
       "   [-5.66836745e-02  1.47822499e-02 -1.33246005e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.71122193e-01  3.56646329e-02 -7.18362629e-03]\n",
       "   [ 6.42065704e-03  1.79284960e-01  1.59637779e-01]\n",
       "   [-1.06569447e-01  5.86483926e-02  6.74238503e-02]]\n",
       "\n",
       "  [[ 1.18319780e-01  1.49352461e-01 -1.70189336e-01]\n",
       "   [ 4.89703715e-02  1.70334429e-01 -2.83747464e-02]\n",
       "   [-3.65189314e-02 -1.74321979e-01  4.83857393e-02]]\n",
       "\n",
       "  [[ 4.79186773e-02  1.62188262e-02 -1.42041743e-02]\n",
       "   [ 7.07059503e-02  2.94080526e-02  9.45008695e-02]\n",
       "   [-2.93372124e-02 -8.44715536e-02  1.11722261e-01]]]\n",
       "\n",
       "\n",
       " [[[ 6.59125447e-02  5.05997986e-02 -1.31376177e-01]\n",
       "   [-9.17568803e-03  1.57728881e-01 -6.72450662e-02]\n",
       "   [-3.25924158e-03 -3.25219631e-02  4.23832238e-02]]\n",
       "\n",
       "  [[-4.13824767e-02 -1.04881883e-01 -1.65507108e-01]\n",
       "   [-1.14712775e-01  1.10556185e-01  5.17856032e-02]\n",
       "   [-9.48744491e-02 -1.15556352e-01  9.75914598e-02]]\n",
       "\n",
       "  [[ 8.82167220e-02 -2.77179331e-02 -3.64471674e-02]\n",
       "   [ 2.04866976e-02 -6.29722327e-02  3.90434265e-03]\n",
       "   [ 2.56852508e-02 -1.07079864e-01 -8.07872415e-02]]]\n",
       "\n",
       "\n",
       " [[[ 8.50502849e-02  1.25303149e-01  7.59867430e-02]\n",
       "   [-1.54287726e-01  4.52778041e-02 -5.96313626e-02]\n",
       "   [ 5.43416589e-02 -1.00669265e-02 -1.40474871e-01]]\n",
       "\n",
       "  [[ 3.14332843e-02 -5.33489138e-02 -3.00983042e-02]\n",
       "   [ 1.26370758e-01  5.00690490e-02  1.12040311e-01]\n",
       "   [-5.11839390e-02 -1.82937905e-01 -1.06594406e-01]]\n",
       "\n",
       "  [[-1.42154887e-01  8.92073810e-02 -1.30964056e-01]\n",
       "   [ 1.28677249e-01  1.05378956e-01  4.53693122e-02]\n",
       "   [-1.27703100e-02  1.56475574e-01 -1.67467445e-02]]]\n",
       "\n",
       "\n",
       " [[[ 7.65839517e-02 -1.85384154e-01 -2.13601142e-02]\n",
       "   [-4.05054986e-02  1.53220505e-01  9.14503336e-02]\n",
       "   [-1.40803486e-01  4.95741814e-02  3.72883677e-02]]\n",
       "\n",
       "  [[ 1.58338219e-01 -1.36269480e-01 -4.22914475e-02]\n",
       "   [ 1.85696721e-01 -1.55060485e-01 -1.26205191e-01]\n",
       "   [-2.01228559e-02 -1.64159402e-01  1.78344548e-01]]\n",
       "\n",
       "  [[-1.76763535e-01  1.70058161e-02 -1.20139621e-01]\n",
       "   [ 2.70547420e-02 -1.33638024e-01  9.50823426e-02]\n",
       "   [ 2.79787928e-02 -1.27352461e-01  3.58471274e-03]]]\n",
       "\n",
       "\n",
       " [[[-9.39827263e-02  6.04519397e-02  1.08013481e-01]\n",
       "   [-1.16645962e-01 -1.65460393e-01 -6.18870556e-03]\n",
       "   [ 7.21707344e-02  8.47104788e-02 -2.81144679e-02]]\n",
       "\n",
       "  [[-1.20700903e-01  4.26964164e-02 -1.13219075e-01]\n",
       "   [ 5.60186058e-02  8.44514072e-02  5.24652749e-02]\n",
       "   [ 1.08808339e-01  8.52264762e-02 -9.50941294e-02]]\n",
       "\n",
       "  [[-1.44704074e-01  9.54670906e-02  1.66977674e-01]\n",
       "   [ 6.69571757e-03 -1.29601046e-01  7.80875385e-02]\n",
       "   [ 1.46477878e-01  4.82615829e-02  2.14048624e-02]]]\n",
       "\n",
       "\n",
       " [[[-5.59447259e-02 -1.32235035e-01 -9.86072123e-02]\n",
       "   [-1.27232820e-01  1.65347815e-01  1.15593970e-01]\n",
       "   [-1.39994696e-01 -9.94724035e-02  1.91435516e-02]]\n",
       "\n",
       "  [[ 9.60350335e-02  3.54774594e-02  4.69578207e-02]\n",
       "   [ 2.16355771e-02 -1.40012741e-01 -9.27861929e-02]\n",
       "   [ 1.38035059e-01  2.14290172e-02  2.97155827e-02]]\n",
       "\n",
       "  [[ 1.68305576e-01 -9.06663686e-02 -1.77400529e-01]\n",
       "   [ 1.37210518e-01 -1.66981682e-01 -1.75825059e-01]\n",
       "   [-1.13700926e-02 -1.71770379e-01 -1.80754349e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.17342532e-01 -1.25246122e-01  4.36568260e-02]\n",
       "   [-1.28248915e-01  1.09156132e-01  1.21462047e-01]\n",
       "   [ 1.39765799e-01  5.97490370e-02 -1.55793935e-01]]\n",
       "\n",
       "  [[ 1.29585981e-01 -1.67708784e-01 -1.40104204e-01]\n",
       "   [ 6.32902682e-02  1.34064347e-01  5.54828346e-03]\n",
       "   [-1.66599661e-01  8.09417665e-02  8.66871774e-02]]\n",
       "\n",
       "  [[ 1.37407273e-01  1.36265099e-01 -7.03882799e-02]\n",
       "   [-4.30146158e-02  1.12596929e-01  1.58761173e-01]\n",
       "   [-1.42925531e-02  9.43056047e-02  2.91520506e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.78751215e-01 -2.92624533e-03 -1.51681826e-01]\n",
       "   [-3.31627429e-02 -9.16357115e-02  1.09045208e-01]\n",
       "   [-6.47970811e-02  6.99364543e-02 -1.76437169e-01]]\n",
       "\n",
       "  [[ 5.80471456e-02 -4.29060906e-02  1.38128102e-02]\n",
       "   [-1.13552198e-01  9.72878337e-02 -6.52008951e-02]\n",
       "   [-3.40867937e-02 -1.28898978e-01  1.00027204e-01]]\n",
       "\n",
       "  [[-3.12890708e-02  1.11474395e-01 -4.54277247e-02]\n",
       "   [ 1.28747046e-01 -1.07698761e-01 -1.71826348e-01]\n",
       "   [ 4.67600226e-02  2.13909745e-02  3.19145769e-02]]]\n",
       "\n",
       "\n",
       " [[[ 6.09795153e-02  6.53798580e-02  1.58851147e-02]\n",
       "   [ 1.31815821e-01  9.09388959e-02 -1.17675558e-01]\n",
       "   [ 9.71961319e-02 -1.42025158e-01 -1.18488498e-01]]\n",
       "\n",
       "  [[-9.83842239e-02 -1.17170766e-01 -7.77797997e-02]\n",
       "   [-6.83522299e-02 -1.33498281e-01 -2.27994174e-02]\n",
       "   [-1.75565094e-01 -1.99733377e-02  1.10118210e-01]]\n",
       "\n",
       "  [[ 1.71729535e-01  3.86021286e-02 -4.06473279e-02]\n",
       "   [ 1.09524578e-01 -6.97095841e-02  1.28281116e-02]\n",
       "   [ 5.41785210e-02  2.32059956e-02 -1.25439763e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.80582225e-01  3.25351954e-04 -7.91747496e-02]\n",
       "   [ 1.14499122e-01  1.40993237e-01  1.48832351e-01]\n",
       "   [-5.41790575e-02 -1.05926991e-02 -1.46621108e-01]]\n",
       "\n",
       "  [[-2.73419023e-02 -1.11192904e-01  7.39906430e-02]\n",
       "   [-6.18950874e-02 -1.24993175e-02 -1.74652562e-01]\n",
       "   [-1.69832543e-01  1.49268806e-01 -2.92789787e-02]]\n",
       "\n",
       "  [[-4.84194010e-02  1.83304638e-01 -5.65462112e-02]\n",
       "   [ 6.40254021e-02  1.04462624e-01  1.26508564e-01]\n",
       "   [-1.16557315e-01 -1.24532729e-02 -1.73336715e-02]]]\n",
       "\n",
       "\n",
       " [[[ 4.83467877e-02 -1.24434516e-01  1.19152457e-01]\n",
       "   [ 1.22755438e-01 -1.31298661e-01  5.54364175e-02]\n",
       "   [-1.76441446e-01  5.25495410e-03 -4.09110039e-02]]\n",
       "\n",
       "  [[ 8.47310126e-02  1.60800517e-01  1.48474276e-01]\n",
       "   [ 6.86119199e-02  1.36019379e-01 -1.44075453e-01]\n",
       "   [ 5.23838252e-02 -1.54542968e-01  1.18324161e-01]]\n",
       "\n",
       "  [[-1.41257003e-01  1.13560587e-01 -8.10354948e-04]\n",
       "   [-1.70496285e-01 -3.00478041e-02 -1.24494001e-01]\n",
       "   [-2.46627033e-02  2.51647830e-02  1.82791203e-01]]]]), LetNode(Var(x_1, ty=TensorType([1, 16, 256, 256], float32)), CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(x_0, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3258c68), [TensorType([1, 3, 256, 256], float32), TensorType([16, 3, 3, 3], float32)]), LetNode(Var(x_2, ty=TensorType([16], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_3, ty=TensorType([1, 16, 256, 256], float32)), CallNode(Op(nn.bias_add), [Var(x_1, ty=TensorType([1, 16, 256, 256], float32)), Var(x_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x3070f198), [TensorType([1, 16, 256, 256], float32), TensorType([16], float32)]), LetNode(Var(x_4, ty=TensorType([1, 16, (int64)128, (int64)128], float32)), CallNode(Op(nn.max_pool2d), [Var(x_3, ty=TensorType([1, 16, 256, 256], float32))], relay.attrs.MaxPool2DAttrs(0x306cf728), [TensorType([1, 16, 256, 256], float32)]), LetNode(Var(x_5, ty=TensorType([32, 16, 3, 3], float32)), Constant([[[[-0.05230885 -0.0552981   0.11728252]\n",
       "   [ 0.08455608  0.10542003  0.04579628]\n",
       "   [-0.09307583  0.05534854 -0.01750716]]\n",
       "\n",
       "  [[ 0.04393943 -0.06029916 -0.01250177]\n",
       "   [ 0.07909112  0.06802806  0.11071744]\n",
       "   [ 0.0185835   0.03467863 -0.0656544 ]]\n",
       "\n",
       "  [[-0.06746837 -0.06010815  0.09041516]\n",
       "   [ 0.09943489  0.11015844 -0.09712255]\n",
       "   [-0.08474152 -0.04466622 -0.00359616]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.11497544  0.06267113 -0.03177162]\n",
       "   [ 0.06944317  0.10755137  0.03901506]\n",
       "   [ 0.07950256  0.10187579 -0.11717492]]\n",
       "\n",
       "  [[-0.08834244  0.10430969  0.11274465]\n",
       "   [ 0.00843327  0.02345195  0.02834205]\n",
       "   [-0.01871318  0.02506819  0.07203812]]\n",
       "\n",
       "  [[ 0.03502864  0.07529881  0.09674402]\n",
       "   [ 0.07443257 -0.07731336 -0.00925865]\n",
       "   [ 0.03505863 -0.06346579  0.10876042]]]\n",
       "\n",
       "\n",
       " [[[ 0.09483296 -0.08411033  0.02065786]\n",
       "   [-0.04375537 -0.04547243  0.01218746]\n",
       "   [-0.01966642 -0.04684217 -0.01652437]]\n",
       "\n",
       "  [[-0.02192305 -0.10731293 -0.00440802]\n",
       "   [ 0.10163368  0.07662707  0.0321778 ]\n",
       "   [-0.01564635  0.08551753  0.02628522]]\n",
       "\n",
       "  [[ 0.10481966 -0.0304717  -0.08486979]\n",
       "   [-0.02855957  0.01816257 -0.10232589]\n",
       "   [ 0.11503667  0.09423494  0.1027649 ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.01420354  0.06906321 -0.02200597]\n",
       "   [-0.11723958  0.11678685 -0.01455109]\n",
       "   [ 0.03668139 -0.00778399 -0.11751148]]\n",
       "\n",
       "  [[ 0.00466588 -0.07041381 -0.04968228]\n",
       "   [ 0.04027871  0.10334843  0.11501909]\n",
       "   [-0.05539501 -0.04927304  0.01133548]]\n",
       "\n",
       "  [[ 0.10833482 -0.10027345  0.06273947]\n",
       "   [ 0.06040571  0.05947142 -0.07104565]\n",
       "   [-0.11337631  0.01624221 -0.08089186]]]\n",
       "\n",
       "\n",
       " [[[-0.07835841 -0.03311843  0.09948593]\n",
       "   [-0.05609833  0.09349469 -0.06139599]\n",
       "   [-0.06181434 -0.08554602 -0.1053581 ]]\n",
       "\n",
       "  [[ 0.08503192  0.05499079  0.05056188]\n",
       "   [-0.04506305 -0.10509247  0.06253643]\n",
       "   [ 0.01259098 -0.09399475 -0.00249332]]\n",
       "\n",
       "  [[ 0.01039549  0.11259469  0.11580513]\n",
       "   [ 0.06672735 -0.00530761 -0.09737875]\n",
       "   [-0.02119978 -0.10293067  0.11692385]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.07186478 -0.03072449 -0.0870213 ]\n",
       "   [-0.04209402  0.09946404  0.02351499]\n",
       "   [-0.07072626  0.04365916  0.05129435]]\n",
       "\n",
       "  [[ 0.00765935 -0.01586042 -0.01249991]\n",
       "   [-0.00079244 -0.01467744  0.10067401]\n",
       "   [-0.04039896 -0.02005445 -0.00711605]]\n",
       "\n",
       "  [[-0.10328984 -0.0535966  -0.03392352]\n",
       "   [ 0.02976998  0.07230691  0.06908812]\n",
       "   [-0.04546015 -0.05153897 -0.06480247]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.0070868   0.00938178 -0.00544529]\n",
       "   [-0.09389155  0.01959044  0.04377877]\n",
       "   [-0.06762378 -0.0329773   0.06007441]]\n",
       "\n",
       "  [[ 0.02986882 -0.11019504 -0.11619313]\n",
       "   [ 0.09995156  0.10913319 -0.10641829]\n",
       "   [-0.06335922  0.00646426  0.10509921]]\n",
       "\n",
       "  [[ 0.08675022  0.08664448 -0.1098199 ]\n",
       "   [ 0.00331356 -0.00187818 -0.07079825]\n",
       "   [ 0.0577076   0.02413637 -0.01189044]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.04778593  0.08398881  0.03136829]\n",
       "   [-0.07407292  0.05938094 -0.02747986]\n",
       "   [ 0.06026339 -0.08766058 -0.11293681]]\n",
       "\n",
       "  [[ 0.04645235 -0.09875906 -0.08499317]\n",
       "   [-0.04851406  0.034994    0.04832434]\n",
       "   [-0.04298678 -0.09601339 -0.10151485]]\n",
       "\n",
       "  [[ 0.07464734 -0.03293914 -0.06233732]\n",
       "   [ 0.02458305  0.10398766  0.04098863]\n",
       "   [ 0.02308751  0.06816975 -0.11231747]]]\n",
       "\n",
       "\n",
       " [[[-0.02933128 -0.06860529 -0.10139706]\n",
       "   [ 0.02435719 -0.10953418  0.01431978]\n",
       "   [ 0.04437434  0.01846709  0.03312323]]\n",
       "\n",
       "  [[ 0.05368101 -0.08317094 -0.08957916]\n",
       "   [ 0.03789932  0.09433054  0.0816843 ]\n",
       "   [-0.02192013  0.11146647 -0.03398576]]\n",
       "\n",
       "  [[-0.00226191  0.10830023 -0.11369399]\n",
       "   [-0.03664935  0.05322992 -0.01288033]\n",
       "   [ 0.08504245 -0.10482323 -0.01505179]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.05494811  0.02482646 -0.10490188]\n",
       "   [ 0.01156456 -0.08555114 -0.06266444]\n",
       "   [ 0.10471573  0.05411824 -0.10698368]]\n",
       "\n",
       "  [[ 0.11158954  0.0869856   0.07516759]\n",
       "   [ 0.11528201 -0.09075028  0.08242213]\n",
       "   [-0.05142607 -0.00498561 -0.04510528]]\n",
       "\n",
       "  [[-0.02594128  0.04859742  0.08633048]\n",
       "   [-0.08991379  0.01653565 -0.01028105]\n",
       "   [ 0.10650278  0.04709851  0.04210464]]]\n",
       "\n",
       "\n",
       " [[[-0.00932021 -0.11301627  0.04408962]\n",
       "   [-0.01989694  0.06719355 -0.0565851 ]\n",
       "   [ 0.06009115 -0.00729082 -0.02609874]]\n",
       "\n",
       "  [[ 0.01176082  0.11522078 -0.00057384]\n",
       "   [-0.0349285   0.05100989  0.05695517]\n",
       "   [-0.0210886  -0.10224926 -0.03217258]]\n",
       "\n",
       "  [[ 0.07885333 -0.04289071 -0.11050623]\n",
       "   [ 0.0116862   0.1011362   0.01308129]\n",
       "   [ 0.09525668 -0.00123814  0.00275118]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00897247  0.10901894  0.03509771]\n",
       "   [-0.11319994  0.03147358 -0.03104576]\n",
       "   [-0.02268737  0.05590992  0.11742789]]\n",
       "\n",
       "  [[-0.09170699  0.09731416  0.1078024 ]\n",
       "   [ 0.03355918  0.01081809 -0.05249008]\n",
       "   [-0.00724667  0.01866774  0.02748851]]\n",
       "\n",
       "  [[-0.00050731 -0.06097165 -0.05974628]\n",
       "   [-0.11410346 -0.04882569  0.01884864]\n",
       "   [ 0.01119485  0.04000121 -0.07791477]]]]), LetNode(Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.conv2d), [Var(x_4, ty=TensorType([1, 16, (int64)128, (int64)128], float32)), Var(x_5, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x306f4508), [TensorType([1, 16, (int64)128, (int64)128], float32), TensorType([32, 16, 3, 3], float32)]), LetNode(Var(x_7, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_8, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.bias_add), [Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), Var(x_7, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x30744298), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)]), LetNode(Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), CallNode(Op(nn.max_pool2d), [Var(x_8, ty=TensorType([1, 32, 128, 128], float32))], relay.attrs.MaxPool2DAttrs(0x306dce38), [TensorType([1, 32, 128, 128], float32)]), LetNode(Var(x_10, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "   [-0.03190579 -0.01584832  0.02670189]\n",
       "   [ 0.01921258 -0.07818282  0.03479443]]\n",
       "\n",
       "  [[-0.00130421 -0.01830789  0.05642799]\n",
       "   [-0.0170652  -0.02210277  0.04254849]\n",
       "   [ 0.01875039 -0.08010064 -0.08040661]]\n",
       "\n",
       "  [[ 0.02165145  0.0240651  -0.04487719]\n",
       "   [-0.02167934 -0.00768209  0.0794398 ]\n",
       "   [-0.02068903  0.06871933  0.07726983]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.03205558  0.00290275 -0.02926568]\n",
       "   [ 0.04182967  0.04922665 -0.06711974]\n",
       "   [-0.02741003  0.05309341  0.01915387]]\n",
       "\n",
       "  [[-0.04150633  0.08178725  0.03009626]\n",
       "   [ 0.05355413  0.03888881 -0.05639726]\n",
       "   [ 0.04942527 -0.00437707  0.00632731]]\n",
       "\n",
       "  [[-0.02561722  0.05984905 -0.05160853]\n",
       "   [-0.07984905 -0.05768615  0.07380161]\n",
       "   [-0.07858952 -0.07737446  0.01850816]]]\n",
       "\n",
       "\n",
       " [[[-0.03143118  0.0695676  -0.04244177]\n",
       "   [ 0.04627309 -0.03359256 -0.06305707]\n",
       "   [ 0.01931474  0.06957508 -0.04066815]]\n",
       "\n",
       "  [[-0.05282148  0.07525725 -0.06407903]\n",
       "   [ 0.05680341  0.03004328 -0.07779044]\n",
       "   [-0.04317856 -0.04223323  0.04984415]]\n",
       "\n",
       "  [[-0.05401897 -0.03738686 -0.04842353]\n",
       "   [ 0.02915064 -0.01600464  0.07291468]\n",
       "   [-0.03190204 -0.0579984   0.04465697]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "   [ 0.00072628 -0.05233977 -0.03741848]\n",
       "   [ 0.07280735 -0.03233246  0.01515931]]\n",
       "\n",
       "  [[-0.05387771 -0.07664208  0.03958815]\n",
       "   [-0.06479758 -0.02311367 -0.05349527]\n",
       "   [-0.03774371 -0.00293905 -0.01947474]]\n",
       "\n",
       "  [[-0.06706224 -0.0475895  -0.03024844]\n",
       "   [-0.06104823 -0.05882414  0.03911529]\n",
       "   [-0.03023565  0.0054945   0.03267833]]]\n",
       "\n",
       "\n",
       " [[[-0.05496893  0.04519042 -0.04979972]\n",
       "   [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "   [ 0.06344249  0.04820261 -0.01685154]]\n",
       "\n",
       "  [[-0.07507978 -0.0369214   0.01589892]\n",
       "   [ 0.07496265 -0.03811238  0.07452969]\n",
       "   [-0.05802975  0.06737594 -0.02538034]]\n",
       "\n",
       "  [[-0.06388503 -0.06834688 -0.02203981]\n",
       "   [ 0.00349629 -0.03683617 -0.07054752]\n",
       "   [ 0.00112883 -0.06129277 -0.03130053]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.03836095  0.0297214   0.07942633]\n",
       "   [-0.01441041  0.00916564  0.06147317]\n",
       "   [ 0.08268154  0.01616826  0.08289457]]\n",
       "\n",
       "  [[ 0.03203704  0.01688347 -0.03459275]\n",
       "   [ 0.00918504 -0.00689121 -0.04055142]\n",
       "   [-0.08139901  0.06464074  0.02731381]]\n",
       "\n",
       "  [[-0.0072248  -0.07411295 -0.05513853]\n",
       "   [-0.02443562  0.03619969 -0.01066486]\n",
       "   [-0.0525009  -0.04152107 -0.04262205]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "   [-0.03333757  0.02255654  0.01452807]\n",
       "   [ 0.07274816  0.04599313 -0.00011758]]\n",
       "\n",
       "  [[ 0.07283399  0.05451591 -0.04420283]\n",
       "   [ 0.07164187  0.08015741  0.06468589]\n",
       "   [-0.03062155 -0.05015038  0.02159031]]\n",
       "\n",
       "  [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "   [-0.00470024  0.00760442 -0.00532582]\n",
       "   [-0.02140979  0.03761176  0.07121743]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "   [ 0.08175186 -0.01663043  0.01697671]\n",
       "   [-0.04998031 -0.00914244  0.02868303]]\n",
       "\n",
       "  [[-0.00251392 -0.02931277 -0.01294055]\n",
       "   [ 0.07991172 -0.0130088  -0.05366091]\n",
       "   [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       "\n",
       "  [[-0.004662   -0.04977087  0.04939119]\n",
       "   [-0.01845763 -0.06482323  0.02449331]\n",
       "   [-0.01165619  0.06523957  0.03770921]]]\n",
       "\n",
       "\n",
       " [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "   [-0.05209206  0.03204753  0.02439884]\n",
       "   [-0.0282647   0.03098512  0.07474277]]\n",
       "\n",
       "  [[-0.05827966  0.00631046 -0.04896474]\n",
       "   [ 0.00211457  0.03935728  0.01188233]\n",
       "   [ 0.0395141  -0.0487875  -0.05219557]]\n",
       "\n",
       "  [[ 0.01199625  0.01175252 -0.08195679]\n",
       "   [-0.04492062 -0.07222724  0.08265557]\n",
       "   [ 0.00680294 -0.06261617 -0.04109164]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.02842131  0.04017299 -0.06411938]\n",
       "   [-0.03479248 -0.00351638  0.04439355]\n",
       "   [-0.00836619 -0.00725466 -0.07700257]]\n",
       "\n",
       "  [[ 0.00681683  0.06109884 -0.03970103]\n",
       "   [-0.07532208  0.02519193  0.03664758]\n",
       "   [ 0.02089242  0.03030465 -0.04797888]]\n",
       "\n",
       "  [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "   [-0.00750206 -0.06763705  0.05190892]\n",
       "   [ 0.02197877  0.07384106  0.04836109]]]\n",
       "\n",
       "\n",
       " [[[-0.03292805  0.05048368  0.05959893]\n",
       "   [-0.00935958  0.07049897  0.07671262]\n",
       "   [-0.0200305   0.02493731 -0.05899358]]\n",
       "\n",
       "  [[-0.06843758  0.01676033  0.07503303]\n",
       "   [-0.00159057  0.07050664 -0.06662065]\n",
       "   [-0.07063043 -0.00717596 -0.07401031]]\n",
       "\n",
       "  [[-0.05164689  0.01307825  0.0358992 ]\n",
       "   [ 0.07245863  0.0667781   0.00989082]\n",
       "   [ 0.02502123 -0.00115818  0.06598707]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "   [ 0.06617681  0.03855822  0.08260872]\n",
       "   [ 0.0201846   0.02270871  0.0820188 ]]\n",
       "\n",
       "  [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "   [ 0.05576969 -0.03805411 -0.05533451]\n",
       "   [ 0.08203562 -0.04242806 -0.03506017]]\n",
       "\n",
       "  [[ 0.03055421 -0.0600045   0.01011878]\n",
       "   [ 0.07702617  0.05981912  0.04538635]\n",
       "   [-0.0253101  -0.06463408 -0.07805812]]]]), LetNode(Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.conv2d), [Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), Var(x_10, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x32515d8), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_12, ty=TensorType([64], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_13, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), Var(x_12, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x306fdee8), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)]), LetNode(Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), CallNode(Op(nn.max_pool2d), [Var(x_13, ty=TensorType([1, 64, 64, 64], float32))], relay.attrs.MaxPool2DAttrs(0x29f2868), [TensorType([1, 64, 64, 64], float32)]), LetNode(Var(x_15, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00667036  0.07674357  0.02048975]\n",
       "   [-0.0005337   0.06994274 -0.0409746 ]\n",
       "   [-0.01644263  0.02424868 -0.08242689]]\n",
       "\n",
       "  [[-0.0279611   0.02216059 -0.04442815]\n",
       "   [-0.00076614 -0.00510069  0.00525645]\n",
       "   [ 0.05821113  0.01974467  0.01869611]]\n",
       "\n",
       "  [[-0.01291529 -0.04766705 -0.04010829]\n",
       "   [-0.06574585 -0.06930234 -0.07820863]\n",
       "   [ 0.05632005 -0.01981469  0.03960329]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00203542 -0.01508743 -0.05518967]\n",
       "   [ 0.0098869  -0.02211016 -0.05686476]\n",
       "   [ 0.04343555  0.04212476 -0.04262485]]\n",
       "\n",
       "  [[ 0.04512688 -0.01977579 -0.03921237]\n",
       "   [ 0.05846582 -0.01097473 -0.08292767]\n",
       "   [ 0.02642258 -0.05865683  0.00781246]]\n",
       "\n",
       "  [[ 0.00868873  0.01789419 -0.05306506]\n",
       "   [ 0.03495514  0.00849197 -0.03360848]\n",
       "   [ 0.05213998 -0.05043467  0.02092493]]]\n",
       "\n",
       "\n",
       " [[[-0.05225816 -0.03435542  0.06766681]\n",
       "   [-0.00570095 -0.07121497  0.04150715]\n",
       "   [ 0.03178158  0.0278095  -0.03169968]]\n",
       "\n",
       "  [[ 0.08237877  0.00820927  0.07866023]\n",
       "   [ 0.06363843  0.00969597 -0.07367277]\n",
       "   [-0.07699051 -0.07091855 -0.04057622]]\n",
       "\n",
       "  [[ 0.03507438  0.06507566 -0.07537719]\n",
       "   [-0.02447435 -0.06244735 -0.06095092]\n",
       "   [ 0.01566204  0.02181033  0.05003274]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.0431037   0.0482654   0.08321209]\n",
       "   [-0.05071964 -0.05884733 -0.0633956 ]\n",
       "   [ 0.06844861 -0.05180594 -0.0485846 ]]\n",
       "\n",
       "  [[-0.03323257  0.02323034  0.00272747]\n",
       "   [ 0.05667796 -0.0002616  -0.00519013]\n",
       "   [ 0.01162627  0.02526001  0.06600187]]\n",
       "\n",
       "  [[ 0.07655057  0.02485903 -0.05985588]\n",
       "   [ 0.04408409 -0.0380648  -0.00562543]\n",
       "   [-0.03243604 -0.03266114  0.02271339]]]\n",
       "\n",
       "\n",
       " [[[ 0.02307111 -0.07447599  0.00114187]\n",
       "   [ 0.0209925  -0.03011368 -0.04503453]\n",
       "   [-0.01692474  0.06745539 -0.02362834]]\n",
       "\n",
       "  [[ 0.06450888 -0.01736359 -0.02165564]\n",
       "   [-0.0565699   0.01656731  0.02207325]\n",
       "   [-0.03282728 -0.07110369 -0.05474281]]\n",
       "\n",
       "  [[-0.00164378  0.07526512  0.07337628]\n",
       "   [ 0.01917853 -0.02339783  0.00305605]\n",
       "   [-0.05832756 -0.04507156 -0.02815646]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.06093149 -0.06571921 -0.0378267 ]\n",
       "   [-0.05794454  0.02385507  0.04264715]\n",
       "   [ 0.0108671   0.05971035 -0.07129908]]\n",
       "\n",
       "  [[-0.08070076  0.06473055 -0.0824315 ]\n",
       "   [ 0.02900531 -0.03235545 -0.03446659]\n",
       "   [-0.0361414  -0.0720194  -0.06739503]]\n",
       "\n",
       "  [[ 0.06519654  0.05091707 -0.03405452]\n",
       "   [ 0.01338766  0.07065854 -0.01776394]\n",
       "   [ 0.03464925  0.03024761  0.03585237]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.03777675 -0.03727138  0.01838966]\n",
       "   [-0.08274333 -0.064996    0.07656416]\n",
       "   [ 0.00311184  0.00922922  0.08024732]]\n",
       "\n",
       "  [[-0.04885089  0.00447249  0.076678  ]\n",
       "   [-0.06130725 -0.08112308  0.01622806]\n",
       "   [ 0.00925171  0.07307453  0.00239494]]\n",
       "\n",
       "  [[ 0.06266668 -0.07882553 -0.02372478]\n",
       "   [-0.00127685 -0.05542324  0.01506688]\n",
       "   [-0.04899919 -0.02099749 -0.04583566]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.01963693 -0.01299276 -0.00876871]\n",
       "   [ 0.03455848  0.01813295 -0.01817822]\n",
       "   [ 0.00511507  0.01796635  0.03721446]]\n",
       "\n",
       "  [[ 0.02849569 -0.0781398   0.06691042]\n",
       "   [ 0.08145543 -0.06311989 -0.06119695]\n",
       "   [-0.08139144 -0.04604743 -0.03518212]]\n",
       "\n",
       "  [[-0.04671299  0.06773625 -0.05673073]\n",
       "   [-0.06609975  0.01549089  0.02074935]\n",
       "   [ 0.07406517 -0.04903018 -0.04878726]]]\n",
       "\n",
       "\n",
       " [[[-0.02131156  0.06878123  0.02314601]\n",
       "   [ 0.07108916  0.04008206  0.02196169]\n",
       "   [-0.07365716 -0.03871602  0.04667952]]\n",
       "\n",
       "  [[ 0.02348771  0.02149502  0.02541289]\n",
       "   [-0.01793929  0.06772844  0.02993079]\n",
       "   [-0.07476664  0.01974591 -0.07887741]]\n",
       "\n",
       "  [[ 0.05220968  0.00943748  0.03035134]\n",
       "   [ 0.03464494 -0.02933544 -0.04283194]\n",
       "   [ 0.06609956  0.06831052 -0.05975342]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00016204  0.0783995   0.07785139]\n",
       "   [ 0.03268198 -0.01940602  0.05926634]\n",
       "   [-0.05186518 -0.06860392  0.07977588]]\n",
       "\n",
       "  [[ 0.06457258  0.077715   -0.05051591]\n",
       "   [-0.07378592 -0.07513899 -0.02788895]\n",
       "   [-0.06781612 -0.02720525  0.08009199]]\n",
       "\n",
       "  [[-0.00609747 -0.00378752  0.06699146]\n",
       "   [-0.00971287 -0.05465307 -0.02018831]\n",
       "   [ 0.08092386 -0.01566859 -0.06308937]]]\n",
       "\n",
       "\n",
       " [[[-0.01809273 -0.05052249  0.00830408]\n",
       "   [ 0.00651675  0.02668866 -0.02696224]\n",
       "   [ 0.06081321  0.03202073 -0.04717416]]\n",
       "\n",
       "  [[ 0.0587954   0.06785775  0.06052122]\n",
       "   [ 0.00263701 -0.01710707 -0.00749189]\n",
       "   [ 0.02028066 -0.00381591  0.05403914]]\n",
       "\n",
       "  [[-0.06002963  0.00170328  0.01363794]\n",
       "   [ 0.02595466  0.02344725 -0.03352585]\n",
       "   [ 0.06551506  0.0296605   0.06894781]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.04791441  0.06846394  0.05488243]\n",
       "   [-0.04654666 -0.07713521  0.08156196]\n",
       "   [ 0.03400215  0.06116603 -0.02428303]]\n",
       "\n",
       "  [[ 0.06481076  0.04652277 -0.04640434]\n",
       "   [-0.02026961  0.07876632  0.04329368]\n",
       "   [-0.06511961 -0.05031322 -0.04249084]]\n",
       "\n",
       "  [[-0.05632734 -0.02485887 -0.06702858]\n",
       "   [-0.0249401  -0.0442156   0.00897348]\n",
       "   [ 0.06168193  0.00339633  0.07160915]]]]), LetNode(Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.conv2d_transpose), [Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), Var(x_15, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x322a008), [TensorType([1, 64, (int64)32, (int64)32], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_17, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), Var(x_17, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x30793838), [TensorType([1, 32, 64, 64], float32), TensorType([32], float32)]), LetNode(Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])), Tuple([Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), Var(x_13, ty=TensorType([1, 64, 64, 64], float32))]), LetNode(Var(x_20, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x3075ccb8), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Tuple([Var(x_8, ty=TensorType([1, 32, 128, 128], float32)), Var(x_20, ty=TensorType([1, 96, 64, 64], float32))]))))))))))))))))))))))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = run_opt_pass(modmod, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n",
      "let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n",
      "let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n",
      "let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "(%x_8, %x_20)\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(modmod.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n",
      "let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n",
      "let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n",
      "let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "%x_20\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[0].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n",
       "  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
       "  %3 = nn.conv2d(%2, meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "  %4 = nn.bias_add(%3, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
       "  %6 = nn.conv2d(%5, meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "  %7 = nn.bias_add(%6, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
       "  %9 = nn.conv2d_transpose(%8, meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "  %10 = nn.bias_add(%9, meta[relay.Constant][7] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "  %11 = (%10, %7) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
       "  %12 = concatenate(%11, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
       "  (%4, %12) /* ty=(Tensor[(1, 32, 128, 128), float32], Tensor[(1, 96, 64, 64), float32]) */\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Var(x_0, ty=TensorType([16, 3, 3, 3], float32)), Var(x_8, ty=TensorType([1, 32, 128, 128], float32)), Var(x_20, ty=TensorType([1, 96, 64, 64], float32))]\n"
     ]
    }
   ],
   "source": [
    "print([o.var for o in outputs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = subgraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n",
      "let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n",
      "let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n",
      "let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "%x_20\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[0].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.expr.Let'> free_var %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "%x_1\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "%x_2\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "%x_3\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "%x_4\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "%x_5\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "%x_6\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n",
      "%x_7\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "%x_8\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "%x_9\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "%x_10\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "%x_11\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "%x_12\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "%x_13\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "%x_14\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "%x_15\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "%x_16\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n",
      "%x_17\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "%x_18\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "%x_19\n",
      "<class 'tvm.relay.expr.Let'> free_var %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "%x_20\n",
      "<class 'tvm.relay.expr.Var'> free_var %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "%x_20\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        prev = prev.body\n",
    "        print(type(prev), prev.var)\n",
    "    except:\n",
    "        print(type(prev), prev)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var(x_20, ty=TensorType([1, 96, 64, 64], float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var(x_8, ty=TensorType([1, 32, 128, 128], float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][1].var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = relay.Tuple([outputs[0][1], subgraphs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple([LetNode(Var(x_8, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.bias_add), [Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), Var(x_7, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31851c78), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)]), LetNode(Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), CallNode(Op(nn.max_pool2d), [Var(x_8, ty=TensorType([1, 32, 128, 128], float32))], relay.attrs.MaxPool2DAttrs(0x31814f48), [TensorType([1, 32, 128, 128], float32)]), LetNode(Var(x_10, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "   [-0.03190579 -0.01584832  0.02670189]\n",
       "   [ 0.01921258 -0.07818282  0.03479443]]\n",
       "\n",
       "  [[-0.00130421 -0.01830789  0.05642799]\n",
       "   [-0.0170652  -0.02210277  0.04254849]\n",
       "   [ 0.01875039 -0.08010064 -0.08040661]]\n",
       "\n",
       "  [[ 0.02165145  0.0240651  -0.04487719]\n",
       "   [-0.02167934 -0.00768209  0.0794398 ]\n",
       "   [-0.02068903  0.06871933  0.07726983]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.03205558  0.00290275 -0.02926568]\n",
       "   [ 0.04182967  0.04922665 -0.06711974]\n",
       "   [-0.02741003  0.05309341  0.01915387]]\n",
       "\n",
       "  [[-0.04150633  0.08178725  0.03009626]\n",
       "   [ 0.05355413  0.03888881 -0.05639726]\n",
       "   [ 0.04942527 -0.00437707  0.00632731]]\n",
       "\n",
       "  [[-0.02561722  0.05984905 -0.05160853]\n",
       "   [-0.07984905 -0.05768615  0.07380161]\n",
       "   [-0.07858952 -0.07737446  0.01850816]]]\n",
       "\n",
       "\n",
       " [[[-0.03143118  0.0695676  -0.04244177]\n",
       "   [ 0.04627309 -0.03359256 -0.06305707]\n",
       "   [ 0.01931474  0.06957508 -0.04066815]]\n",
       "\n",
       "  [[-0.05282148  0.07525725 -0.06407903]\n",
       "   [ 0.05680341  0.03004328 -0.07779044]\n",
       "   [-0.04317856 -0.04223323  0.04984415]]\n",
       "\n",
       "  [[-0.05401897 -0.03738686 -0.04842353]\n",
       "   [ 0.02915064 -0.01600464  0.07291468]\n",
       "   [-0.03190204 -0.0579984   0.04465697]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "   [ 0.00072628 -0.05233977 -0.03741848]\n",
       "   [ 0.07280735 -0.03233246  0.01515931]]\n",
       "\n",
       "  [[-0.05387771 -0.07664208  0.03958815]\n",
       "   [-0.06479758 -0.02311367 -0.05349527]\n",
       "   [-0.03774371 -0.00293905 -0.01947474]]\n",
       "\n",
       "  [[-0.06706224 -0.0475895  -0.03024844]\n",
       "   [-0.06104823 -0.05882414  0.03911529]\n",
       "   [-0.03023565  0.0054945   0.03267833]]]\n",
       "\n",
       "\n",
       " [[[-0.05496893  0.04519042 -0.04979972]\n",
       "   [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "   [ 0.06344249  0.04820261 -0.01685154]]\n",
       "\n",
       "  [[-0.07507978 -0.0369214   0.01589892]\n",
       "   [ 0.07496265 -0.03811238  0.07452969]\n",
       "   [-0.05802975  0.06737594 -0.02538034]]\n",
       "\n",
       "  [[-0.06388503 -0.06834688 -0.02203981]\n",
       "   [ 0.00349629 -0.03683617 -0.07054752]\n",
       "   [ 0.00112883 -0.06129277 -0.03130053]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.03836095  0.0297214   0.07942633]\n",
       "   [-0.01441041  0.00916564  0.06147317]\n",
       "   [ 0.08268154  0.01616826  0.08289457]]\n",
       "\n",
       "  [[ 0.03203704  0.01688347 -0.03459275]\n",
       "   [ 0.00918504 -0.00689121 -0.04055142]\n",
       "   [-0.08139901  0.06464074  0.02731381]]\n",
       "\n",
       "  [[-0.0072248  -0.07411295 -0.05513853]\n",
       "   [-0.02443562  0.03619969 -0.01066486]\n",
       "   [-0.0525009  -0.04152107 -0.04262205]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "   [-0.03333757  0.02255654  0.01452807]\n",
       "   [ 0.07274816  0.04599313 -0.00011758]]\n",
       "\n",
       "  [[ 0.07283399  0.05451591 -0.04420283]\n",
       "   [ 0.07164187  0.08015741  0.06468589]\n",
       "   [-0.03062155 -0.05015038  0.02159031]]\n",
       "\n",
       "  [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "   [-0.00470024  0.00760442 -0.00532582]\n",
       "   [-0.02140979  0.03761176  0.07121743]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "   [ 0.08175186 -0.01663043  0.01697671]\n",
       "   [-0.04998031 -0.00914244  0.02868303]]\n",
       "\n",
       "  [[-0.00251392 -0.02931277 -0.01294055]\n",
       "   [ 0.07991172 -0.0130088  -0.05366091]\n",
       "   [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       "\n",
       "  [[-0.004662   -0.04977087  0.04939119]\n",
       "   [-0.01845763 -0.06482323  0.02449331]\n",
       "   [-0.01165619  0.06523957  0.03770921]]]\n",
       "\n",
       "\n",
       " [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "   [-0.05209206  0.03204753  0.02439884]\n",
       "   [-0.0282647   0.03098512  0.07474277]]\n",
       "\n",
       "  [[-0.05827966  0.00631046 -0.04896474]\n",
       "   [ 0.00211457  0.03935728  0.01188233]\n",
       "   [ 0.0395141  -0.0487875  -0.05219557]]\n",
       "\n",
       "  [[ 0.01199625  0.01175252 -0.08195679]\n",
       "   [-0.04492062 -0.07222724  0.08265557]\n",
       "   [ 0.00680294 -0.06261617 -0.04109164]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.02842131  0.04017299 -0.06411938]\n",
       "   [-0.03479248 -0.00351638  0.04439355]\n",
       "   [-0.00836619 -0.00725466 -0.07700257]]\n",
       "\n",
       "  [[ 0.00681683  0.06109884 -0.03970103]\n",
       "   [-0.07532208  0.02519193  0.03664758]\n",
       "   [ 0.02089242  0.03030465 -0.04797888]]\n",
       "\n",
       "  [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "   [-0.00750206 -0.06763705  0.05190892]\n",
       "   [ 0.02197877  0.07384106  0.04836109]]]\n",
       "\n",
       "\n",
       " [[[-0.03292805  0.05048368  0.05959893]\n",
       "   [-0.00935958  0.07049897  0.07671262]\n",
       "   [-0.0200305   0.02493731 -0.05899358]]\n",
       "\n",
       "  [[-0.06843758  0.01676033  0.07503303]\n",
       "   [-0.00159057  0.07050664 -0.06662065]\n",
       "   [-0.07063043 -0.00717596 -0.07401031]]\n",
       "\n",
       "  [[-0.05164689  0.01307825  0.0358992 ]\n",
       "   [ 0.07245863  0.0667781   0.00989082]\n",
       "   [ 0.02502123 -0.00115818  0.06598707]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "   [ 0.06617681  0.03855822  0.08260872]\n",
       "   [ 0.0201846   0.02270871  0.0820188 ]]\n",
       "\n",
       "  [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "   [ 0.05576969 -0.03805411 -0.05533451]\n",
       "   [ 0.08203562 -0.04242806 -0.03506017]]\n",
       "\n",
       "  [[ 0.03055421 -0.0600045   0.01011878]\n",
       "   [ 0.07702617  0.05981912  0.04538635]\n",
       "   [-0.0253101  -0.06463408 -0.07805812]]]]), LetNode(Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.conv2d), [Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), Var(x_10, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x54ef238), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_12, ty=TensorType([64], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_13, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), Var(x_12, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x3181d6a8), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)]), LetNode(Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), CallNode(Op(nn.max_pool2d), [Var(x_13, ty=TensorType([1, 64, 64, 64], float32))], relay.attrs.MaxPool2DAttrs(0x31832b38), [TensorType([1, 64, 64, 64], float32)]), LetNode(Var(x_15, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00667036  0.07674357  0.02048975]\n",
       "   [-0.0005337   0.06994274 -0.0409746 ]\n",
       "   [-0.01644263  0.02424868 -0.08242689]]\n",
       "\n",
       "  [[-0.0279611   0.02216059 -0.04442815]\n",
       "   [-0.00076614 -0.00510069  0.00525645]\n",
       "   [ 0.05821113  0.01974467  0.01869611]]\n",
       "\n",
       "  [[-0.01291529 -0.04766705 -0.04010829]\n",
       "   [-0.06574585 -0.06930234 -0.07820863]\n",
       "   [ 0.05632005 -0.01981469  0.03960329]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00203542 -0.01508743 -0.05518967]\n",
       "   [ 0.0098869  -0.02211016 -0.05686476]\n",
       "   [ 0.04343555  0.04212476 -0.04262485]]\n",
       "\n",
       "  [[ 0.04512688 -0.01977579 -0.03921237]\n",
       "   [ 0.05846582 -0.01097473 -0.08292767]\n",
       "   [ 0.02642258 -0.05865683  0.00781246]]\n",
       "\n",
       "  [[ 0.00868873  0.01789419 -0.05306506]\n",
       "   [ 0.03495514  0.00849197 -0.03360848]\n",
       "   [ 0.05213998 -0.05043467  0.02092493]]]\n",
       "\n",
       "\n",
       " [[[-0.05225816 -0.03435542  0.06766681]\n",
       "   [-0.00570095 -0.07121497  0.04150715]\n",
       "   [ 0.03178158  0.0278095  -0.03169968]]\n",
       "\n",
       "  [[ 0.08237877  0.00820927  0.07866023]\n",
       "   [ 0.06363843  0.00969597 -0.07367277]\n",
       "   [-0.07699051 -0.07091855 -0.04057622]]\n",
       "\n",
       "  [[ 0.03507438  0.06507566 -0.07537719]\n",
       "   [-0.02447435 -0.06244735 -0.06095092]\n",
       "   [ 0.01566204  0.02181033  0.05003274]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.0431037   0.0482654   0.08321209]\n",
       "   [-0.05071964 -0.05884733 -0.0633956 ]\n",
       "   [ 0.06844861 -0.05180594 -0.0485846 ]]\n",
       "\n",
       "  [[-0.03323257  0.02323034  0.00272747]\n",
       "   [ 0.05667796 -0.0002616  -0.00519013]\n",
       "   [ 0.01162627  0.02526001  0.06600187]]\n",
       "\n",
       "  [[ 0.07655057  0.02485903 -0.05985588]\n",
       "   [ 0.04408409 -0.0380648  -0.00562543]\n",
       "   [-0.03243604 -0.03266114  0.02271339]]]\n",
       "\n",
       "\n",
       " [[[ 0.02307111 -0.07447599  0.00114187]\n",
       "   [ 0.0209925  -0.03011368 -0.04503453]\n",
       "   [-0.01692474  0.06745539 -0.02362834]]\n",
       "\n",
       "  [[ 0.06450888 -0.01736359 -0.02165564]\n",
       "   [-0.0565699   0.01656731  0.02207325]\n",
       "   [-0.03282728 -0.07110369 -0.05474281]]\n",
       "\n",
       "  [[-0.00164378  0.07526512  0.07337628]\n",
       "   [ 0.01917853 -0.02339783  0.00305605]\n",
       "   [-0.05832756 -0.04507156 -0.02815646]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.06093149 -0.06571921 -0.0378267 ]\n",
       "   [-0.05794454  0.02385507  0.04264715]\n",
       "   [ 0.0108671   0.05971035 -0.07129908]]\n",
       "\n",
       "  [[-0.08070076  0.06473055 -0.0824315 ]\n",
       "   [ 0.02900531 -0.03235545 -0.03446659]\n",
       "   [-0.0361414  -0.0720194  -0.06739503]]\n",
       "\n",
       "  [[ 0.06519654  0.05091707 -0.03405452]\n",
       "   [ 0.01338766  0.07065854 -0.01776394]\n",
       "   [ 0.03464925  0.03024761  0.03585237]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.03777675 -0.03727138  0.01838966]\n",
       "   [-0.08274333 -0.064996    0.07656416]\n",
       "   [ 0.00311184  0.00922922  0.08024732]]\n",
       "\n",
       "  [[-0.04885089  0.00447249  0.076678  ]\n",
       "   [-0.06130725 -0.08112308  0.01622806]\n",
       "   [ 0.00925171  0.07307453  0.00239494]]\n",
       "\n",
       "  [[ 0.06266668 -0.07882553 -0.02372478]\n",
       "   [-0.00127685 -0.05542324  0.01506688]\n",
       "   [-0.04899919 -0.02099749 -0.04583566]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.01963693 -0.01299276 -0.00876871]\n",
       "   [ 0.03455848  0.01813295 -0.01817822]\n",
       "   [ 0.00511507  0.01796635  0.03721446]]\n",
       "\n",
       "  [[ 0.02849569 -0.0781398   0.06691042]\n",
       "   [ 0.08145543 -0.06311989 -0.06119695]\n",
       "   [-0.08139144 -0.04604743 -0.03518212]]\n",
       "\n",
       "  [[-0.04671299  0.06773625 -0.05673073]\n",
       "   [-0.06609975  0.01549089  0.02074935]\n",
       "   [ 0.07406517 -0.04903018 -0.04878726]]]\n",
       "\n",
       "\n",
       " [[[-0.02131156  0.06878123  0.02314601]\n",
       "   [ 0.07108916  0.04008206  0.02196169]\n",
       "   [-0.07365716 -0.03871602  0.04667952]]\n",
       "\n",
       "  [[ 0.02348771  0.02149502  0.02541289]\n",
       "   [-0.01793929  0.06772844  0.02993079]\n",
       "   [-0.07476664  0.01974591 -0.07887741]]\n",
       "\n",
       "  [[ 0.05220968  0.00943748  0.03035134]\n",
       "   [ 0.03464494 -0.02933544 -0.04283194]\n",
       "   [ 0.06609956  0.06831052 -0.05975342]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00016204  0.0783995   0.07785139]\n",
       "   [ 0.03268198 -0.01940602  0.05926634]\n",
       "   [-0.05186518 -0.06860392  0.07977588]]\n",
       "\n",
       "  [[ 0.06457258  0.077715   -0.05051591]\n",
       "   [-0.07378592 -0.07513899 -0.02788895]\n",
       "   [-0.06781612 -0.02720525  0.08009199]]\n",
       "\n",
       "  [[-0.00609747 -0.00378752  0.06699146]\n",
       "   [-0.00971287 -0.05465307 -0.02018831]\n",
       "   [ 0.08092386 -0.01566859 -0.06308937]]]\n",
       "\n",
       "\n",
       " [[[-0.01809273 -0.05052249  0.00830408]\n",
       "   [ 0.00651675  0.02668866 -0.02696224]\n",
       "   [ 0.06081321  0.03202073 -0.04717416]]\n",
       "\n",
       "  [[ 0.0587954   0.06785775  0.06052122]\n",
       "   [ 0.00263701 -0.01710707 -0.00749189]\n",
       "   [ 0.02028066 -0.00381591  0.05403914]]\n",
       "\n",
       "  [[-0.06002963  0.00170328  0.01363794]\n",
       "   [ 0.02595466  0.02344725 -0.03352585]\n",
       "   [ 0.06551506  0.0296605   0.06894781]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.04791441  0.06846394  0.05488243]\n",
       "   [-0.04654666 -0.07713521  0.08156196]\n",
       "   [ 0.03400215  0.06116603 -0.02428303]]\n",
       "\n",
       "  [[ 0.06481076  0.04652277 -0.04640434]\n",
       "   [-0.02026961  0.07876632  0.04329368]\n",
       "   [-0.06511961 -0.05031322 -0.04249084]]\n",
       "\n",
       "  [[-0.05632734 -0.02485887 -0.06702858]\n",
       "   [-0.0249401  -0.0442156   0.00897348]\n",
       "   [ 0.06168193  0.00339633  0.07160915]]]]), LetNode(Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.conv2d_transpose), [Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), Var(x_15, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x68056e8), [TensorType([1, 64, (int64)32, (int64)32], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_17, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), Var(x_17, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x396c968), [TensorType([1, 32, 64, 64], float32), TensorType([32], float32)]), LetNode(Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])), Tuple([Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), Var(x_13, ty=TensorType([1, 64, 64, 64], float32))]), LetNode(Var(x_20, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x318388b8), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Var(x_20, ty=TensorType([1, 96, 64, 64], float32))))))))))))))), LetNode(Var(x_0, ty=TensorType([16, 3, 3, 3], float32)), Constant([[[[ 3.23163867e-02 -8.54633600e-02  5.41195720e-02]\n",
       "   [-1.10573828e-01  1.81553543e-01 -1.22144818e-04]\n",
       "   [ 2.55260766e-02  7.36784637e-02  1.07363641e-01]]\n",
       "\n",
       "  [[ 2.55233049e-02 -4.54409420e-02  1.67028517e-01]\n",
       "   [ 1.45357460e-01 -1.00949802e-01  7.94526637e-02]\n",
       "   [-1.49513945e-01  1.69569105e-02 -5.45993596e-02]]\n",
       "\n",
       "  [[-1.71270907e-01 -1.04798146e-01 -7.64890388e-02]\n",
       "   [-3.08729708e-03  8.45972598e-02 -3.27159166e-02]\n",
       "   [-1.12808652e-01 -7.80549943e-02  1.27093047e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.79601535e-01 -3.15128714e-02  3.91178727e-02]\n",
       "   [ 1.68302536e-01 -1.86983153e-01 -1.29431516e-01]\n",
       "   [ 7.07907379e-02 -5.24235666e-02 -2.14526057e-02]]\n",
       "\n",
       "  [[-1.49425566e-01  1.06974870e-01  1.21452183e-01]\n",
       "   [-3.09053659e-02  1.61907017e-01  1.01942331e-01]\n",
       "   [-1.82749078e-01 -1.50260255e-01 -9.02489349e-02]]\n",
       "\n",
       "  [[ 1.36263520e-02  5.32492995e-03  6.63298666e-02]\n",
       "   [-7.51340613e-02 -1.39353558e-01  7.36561418e-02]\n",
       "   [ 9.17883217e-02 -9.86345112e-03  1.52955800e-01]]]\n",
       "\n",
       "\n",
       " [[[ 2.13009864e-02  1.97265893e-02 -9.45521891e-03]\n",
       "   [ 2.66401619e-02  6.64318204e-02 -5.04366457e-02]\n",
       "   [-3.13195288e-02  8.30757916e-02 -1.36988997e-01]]\n",
       "\n",
       "  [[ 1.63736790e-01 -3.15981656e-02  7.50636458e-02]\n",
       "   [-1.42437190e-01 -1.23402961e-01  2.17434764e-02]\n",
       "   [ 9.64652300e-02 -8.68084654e-02 -9.02800262e-03]]\n",
       "\n",
       "  [[-1.01768948e-01  6.33873343e-02  7.77019560e-03]\n",
       "   [ 9.59634781e-02  1.81303084e-01  1.68824941e-01]\n",
       "   [-5.29856980e-02  4.81943637e-02 -7.51121342e-03]]]\n",
       "\n",
       "\n",
       " [[[ 1.85624272e-01  1.26410723e-02 -4.69885021e-02]\n",
       "   [ 1.31377161e-01  1.20458394e-01 -1.76296934e-01]\n",
       "   [ 1.14306152e-01  2.60501653e-02  1.43022805e-01]]\n",
       "\n",
       "  [[-8.49472657e-02  1.73936397e-01  1.66811049e-01]\n",
       "   [-8.02976787e-02 -8.55044872e-02 -5.39514422e-03]\n",
       "   [-8.56521353e-02  4.48296368e-02 -1.34362057e-01]]\n",
       "\n",
       "  [[-5.33646792e-02  1.81859225e-01 -9.99502242e-02]\n",
       "   [-5.50511777e-02 -3.37825716e-03 -9.55829322e-02]\n",
       "   [ 1.68427318e-01 -1.84786871e-01  1.06600076e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.75437063e-01  1.41930699e-01  1.37000918e-01]\n",
       "   [ 6.71393573e-02 -1.15836464e-01 -9.71407145e-02]\n",
       "   [ 1.50851011e-01 -3.45225483e-02  1.65536791e-01]]\n",
       "\n",
       "  [[-4.98251617e-02  1.47754252e-01 -1.81763440e-01]\n",
       "   [ 1.70889974e-01 -7.70533159e-02 -2.05524266e-03]\n",
       "   [-1.60784572e-02  1.16744578e-01 -4.57684845e-02]]\n",
       "\n",
       "  [[-7.69499764e-02  9.30011570e-02 -5.64735085e-02]\n",
       "   [-8.08795094e-02  1.17174089e-02 -5.56611419e-02]\n",
       "   [-5.66836745e-02  1.47822499e-02 -1.33246005e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.71122193e-01  3.56646329e-02 -7.18362629e-03]\n",
       "   [ 6.42065704e-03  1.79284960e-01  1.59637779e-01]\n",
       "   [-1.06569447e-01  5.86483926e-02  6.74238503e-02]]\n",
       "\n",
       "  [[ 1.18319780e-01  1.49352461e-01 -1.70189336e-01]\n",
       "   [ 4.89703715e-02  1.70334429e-01 -2.83747464e-02]\n",
       "   [-3.65189314e-02 -1.74321979e-01  4.83857393e-02]]\n",
       "\n",
       "  [[ 4.79186773e-02  1.62188262e-02 -1.42041743e-02]\n",
       "   [ 7.07059503e-02  2.94080526e-02  9.45008695e-02]\n",
       "   [-2.93372124e-02 -8.44715536e-02  1.11722261e-01]]]\n",
       "\n",
       "\n",
       " [[[ 6.59125447e-02  5.05997986e-02 -1.31376177e-01]\n",
       "   [-9.17568803e-03  1.57728881e-01 -6.72450662e-02]\n",
       "   [-3.25924158e-03 -3.25219631e-02  4.23832238e-02]]\n",
       "\n",
       "  [[-4.13824767e-02 -1.04881883e-01 -1.65507108e-01]\n",
       "   [-1.14712775e-01  1.10556185e-01  5.17856032e-02]\n",
       "   [-9.48744491e-02 -1.15556352e-01  9.75914598e-02]]\n",
       "\n",
       "  [[ 8.82167220e-02 -2.77179331e-02 -3.64471674e-02]\n",
       "   [ 2.04866976e-02 -6.29722327e-02  3.90434265e-03]\n",
       "   [ 2.56852508e-02 -1.07079864e-01 -8.07872415e-02]]]\n",
       "\n",
       "\n",
       " [[[ 8.50502849e-02  1.25303149e-01  7.59867430e-02]\n",
       "   [-1.54287726e-01  4.52778041e-02 -5.96313626e-02]\n",
       "   [ 5.43416589e-02 -1.00669265e-02 -1.40474871e-01]]\n",
       "\n",
       "  [[ 3.14332843e-02 -5.33489138e-02 -3.00983042e-02]\n",
       "   [ 1.26370758e-01  5.00690490e-02  1.12040311e-01]\n",
       "   [-5.11839390e-02 -1.82937905e-01 -1.06594406e-01]]\n",
       "\n",
       "  [[-1.42154887e-01  8.92073810e-02 -1.30964056e-01]\n",
       "   [ 1.28677249e-01  1.05378956e-01  4.53693122e-02]\n",
       "   [-1.27703100e-02  1.56475574e-01 -1.67467445e-02]]]\n",
       "\n",
       "\n",
       " [[[ 7.65839517e-02 -1.85384154e-01 -2.13601142e-02]\n",
       "   [-4.05054986e-02  1.53220505e-01  9.14503336e-02]\n",
       "   [-1.40803486e-01  4.95741814e-02  3.72883677e-02]]\n",
       "\n",
       "  [[ 1.58338219e-01 -1.36269480e-01 -4.22914475e-02]\n",
       "   [ 1.85696721e-01 -1.55060485e-01 -1.26205191e-01]\n",
       "   [-2.01228559e-02 -1.64159402e-01  1.78344548e-01]]\n",
       "\n",
       "  [[-1.76763535e-01  1.70058161e-02 -1.20139621e-01]\n",
       "   [ 2.70547420e-02 -1.33638024e-01  9.50823426e-02]\n",
       "   [ 2.79787928e-02 -1.27352461e-01  3.58471274e-03]]]\n",
       "\n",
       "\n",
       " [[[-9.39827263e-02  6.04519397e-02  1.08013481e-01]\n",
       "   [-1.16645962e-01 -1.65460393e-01 -6.18870556e-03]\n",
       "   [ 7.21707344e-02  8.47104788e-02 -2.81144679e-02]]\n",
       "\n",
       "  [[-1.20700903e-01  4.26964164e-02 -1.13219075e-01]\n",
       "   [ 5.60186058e-02  8.44514072e-02  5.24652749e-02]\n",
       "   [ 1.08808339e-01  8.52264762e-02 -9.50941294e-02]]\n",
       "\n",
       "  [[-1.44704074e-01  9.54670906e-02  1.66977674e-01]\n",
       "   [ 6.69571757e-03 -1.29601046e-01  7.80875385e-02]\n",
       "   [ 1.46477878e-01  4.82615829e-02  2.14048624e-02]]]\n",
       "\n",
       "\n",
       " [[[-5.59447259e-02 -1.32235035e-01 -9.86072123e-02]\n",
       "   [-1.27232820e-01  1.65347815e-01  1.15593970e-01]\n",
       "   [-1.39994696e-01 -9.94724035e-02  1.91435516e-02]]\n",
       "\n",
       "  [[ 9.60350335e-02  3.54774594e-02  4.69578207e-02]\n",
       "   [ 2.16355771e-02 -1.40012741e-01 -9.27861929e-02]\n",
       "   [ 1.38035059e-01  2.14290172e-02  2.97155827e-02]]\n",
       "\n",
       "  [[ 1.68305576e-01 -9.06663686e-02 -1.77400529e-01]\n",
       "   [ 1.37210518e-01 -1.66981682e-01 -1.75825059e-01]\n",
       "   [-1.13700926e-02 -1.71770379e-01 -1.80754349e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.17342532e-01 -1.25246122e-01  4.36568260e-02]\n",
       "   [-1.28248915e-01  1.09156132e-01  1.21462047e-01]\n",
       "   [ 1.39765799e-01  5.97490370e-02 -1.55793935e-01]]\n",
       "\n",
       "  [[ 1.29585981e-01 -1.67708784e-01 -1.40104204e-01]\n",
       "   [ 6.32902682e-02  1.34064347e-01  5.54828346e-03]\n",
       "   [-1.66599661e-01  8.09417665e-02  8.66871774e-02]]\n",
       "\n",
       "  [[ 1.37407273e-01  1.36265099e-01 -7.03882799e-02]\n",
       "   [-4.30146158e-02  1.12596929e-01  1.58761173e-01]\n",
       "   [-1.42925531e-02  9.43056047e-02  2.91520506e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.78751215e-01 -2.92624533e-03 -1.51681826e-01]\n",
       "   [-3.31627429e-02 -9.16357115e-02  1.09045208e-01]\n",
       "   [-6.47970811e-02  6.99364543e-02 -1.76437169e-01]]\n",
       "\n",
       "  [[ 5.80471456e-02 -4.29060906e-02  1.38128102e-02]\n",
       "   [-1.13552198e-01  9.72878337e-02 -6.52008951e-02]\n",
       "   [-3.40867937e-02 -1.28898978e-01  1.00027204e-01]]\n",
       "\n",
       "  [[-3.12890708e-02  1.11474395e-01 -4.54277247e-02]\n",
       "   [ 1.28747046e-01 -1.07698761e-01 -1.71826348e-01]\n",
       "   [ 4.67600226e-02  2.13909745e-02  3.19145769e-02]]]\n",
       "\n",
       "\n",
       " [[[ 6.09795153e-02  6.53798580e-02  1.58851147e-02]\n",
       "   [ 1.31815821e-01  9.09388959e-02 -1.17675558e-01]\n",
       "   [ 9.71961319e-02 -1.42025158e-01 -1.18488498e-01]]\n",
       "\n",
       "  [[-9.83842239e-02 -1.17170766e-01 -7.77797997e-02]\n",
       "   [-6.83522299e-02 -1.33498281e-01 -2.27994174e-02]\n",
       "   [-1.75565094e-01 -1.99733377e-02  1.10118210e-01]]\n",
       "\n",
       "  [[ 1.71729535e-01  3.86021286e-02 -4.06473279e-02]\n",
       "   [ 1.09524578e-01 -6.97095841e-02  1.28281116e-02]\n",
       "   [ 5.41785210e-02  2.32059956e-02 -1.25439763e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.80582225e-01  3.25351954e-04 -7.91747496e-02]\n",
       "   [ 1.14499122e-01  1.40993237e-01  1.48832351e-01]\n",
       "   [-5.41790575e-02 -1.05926991e-02 -1.46621108e-01]]\n",
       "\n",
       "  [[-2.73419023e-02 -1.11192904e-01  7.39906430e-02]\n",
       "   [-6.18950874e-02 -1.24993175e-02 -1.74652562e-01]\n",
       "   [-1.69832543e-01  1.49268806e-01 -2.92789787e-02]]\n",
       "\n",
       "  [[-4.84194010e-02  1.83304638e-01 -5.65462112e-02]\n",
       "   [ 6.40254021e-02  1.04462624e-01  1.26508564e-01]\n",
       "   [-1.16557315e-01 -1.24532729e-02 -1.73336715e-02]]]\n",
       "\n",
       "\n",
       " [[[ 4.83467877e-02 -1.24434516e-01  1.19152457e-01]\n",
       "   [ 1.22755438e-01 -1.31298661e-01  5.54364175e-02]\n",
       "   [-1.76441446e-01  5.25495410e-03 -4.09110039e-02]]\n",
       "\n",
       "  [[ 8.47310126e-02  1.60800517e-01  1.48474276e-01]\n",
       "   [ 6.86119199e-02  1.36019379e-01 -1.44075453e-01]\n",
       "   [ 5.23838252e-02 -1.54542968e-01  1.18324161e-01]]\n",
       "\n",
       "  [[-1.41257003e-01  1.13560587e-01 -8.10354948e-04]\n",
       "   [-1.70496285e-01 -3.00478041e-02 -1.24494001e-01]\n",
       "   [-2.46627033e-02  2.51647830e-02  1.82791203e-01]]]]), LetNode(Var(x_1, ty=TensorType([1, 16, 256, 256], float32)), CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(x_0, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31825fa8), [TensorType([1, 3, 256, 256], float32), TensorType([16, 3, 3, 3], float32)]), LetNode(Var(x_2, ty=TensorType([16], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_3, ty=TensorType([1, 16, 256, 256], float32)), CallNode(Op(nn.bias_add), [Var(x_1, ty=TensorType([1, 16, 256, 256], float32)), Var(x_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x396d5d8), [TensorType([1, 16, 256, 256], float32), TensorType([16], float32)]), LetNode(Var(x_4, ty=TensorType([1, 16, (int64)128, (int64)128], float32)), CallNode(Op(nn.max_pool2d), [Var(x_3, ty=TensorType([1, 16, 256, 256], float32))], relay.attrs.MaxPool2DAttrs(0x41b2fa8), [TensorType([1, 16, 256, 256], float32)]), LetNode(Var(x_5, ty=TensorType([32, 16, 3, 3], float32)), Constant([[[[-0.05230885 -0.0552981   0.11728252]\n",
       "   [ 0.08455608  0.10542003  0.04579628]\n",
       "   [-0.09307583  0.05534854 -0.01750716]]\n",
       "\n",
       "  [[ 0.04393943 -0.06029916 -0.01250177]\n",
       "   [ 0.07909112  0.06802806  0.11071744]\n",
       "   [ 0.0185835   0.03467863 -0.0656544 ]]\n",
       "\n",
       "  [[-0.06746837 -0.06010815  0.09041516]\n",
       "   [ 0.09943489  0.11015844 -0.09712255]\n",
       "   [-0.08474152 -0.04466622 -0.00359616]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.11497544  0.06267113 -0.03177162]\n",
       "   [ 0.06944317  0.10755137  0.03901506]\n",
       "   [ 0.07950256  0.10187579 -0.11717492]]\n",
       "\n",
       "  [[-0.08834244  0.10430969  0.11274465]\n",
       "   [ 0.00843327  0.02345195  0.02834205]\n",
       "   [-0.01871318  0.02506819  0.07203812]]\n",
       "\n",
       "  [[ 0.03502864  0.07529881  0.09674402]\n",
       "   [ 0.07443257 -0.07731336 -0.00925865]\n",
       "   [ 0.03505863 -0.06346579  0.10876042]]]\n",
       "\n",
       "\n",
       " [[[ 0.09483296 -0.08411033  0.02065786]\n",
       "   [-0.04375537 -0.04547243  0.01218746]\n",
       "   [-0.01966642 -0.04684217 -0.01652437]]\n",
       "\n",
       "  [[-0.02192305 -0.10731293 -0.00440802]\n",
       "   [ 0.10163368  0.07662707  0.0321778 ]\n",
       "   [-0.01564635  0.08551753  0.02628522]]\n",
       "\n",
       "  [[ 0.10481966 -0.0304717  -0.08486979]\n",
       "   [-0.02855957  0.01816257 -0.10232589]\n",
       "   [ 0.11503667  0.09423494  0.1027649 ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.01420354  0.06906321 -0.02200597]\n",
       "   [-0.11723958  0.11678685 -0.01455109]\n",
       "   [ 0.03668139 -0.00778399 -0.11751148]]\n",
       "\n",
       "  [[ 0.00466588 -0.07041381 -0.04968228]\n",
       "   [ 0.04027871  0.10334843  0.11501909]\n",
       "   [-0.05539501 -0.04927304  0.01133548]]\n",
       "\n",
       "  [[ 0.10833482 -0.10027345  0.06273947]\n",
       "   [ 0.06040571  0.05947142 -0.07104565]\n",
       "   [-0.11337631  0.01624221 -0.08089186]]]\n",
       "\n",
       "\n",
       " [[[-0.07835841 -0.03311843  0.09948593]\n",
       "   [-0.05609833  0.09349469 -0.06139599]\n",
       "   [-0.06181434 -0.08554602 -0.1053581 ]]\n",
       "\n",
       "  [[ 0.08503192  0.05499079  0.05056188]\n",
       "   [-0.04506305 -0.10509247  0.06253643]\n",
       "   [ 0.01259098 -0.09399475 -0.00249332]]\n",
       "\n",
       "  [[ 0.01039549  0.11259469  0.11580513]\n",
       "   [ 0.06672735 -0.00530761 -0.09737875]\n",
       "   [-0.02119978 -0.10293067  0.11692385]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.07186478 -0.03072449 -0.0870213 ]\n",
       "   [-0.04209402  0.09946404  0.02351499]\n",
       "   [-0.07072626  0.04365916  0.05129435]]\n",
       "\n",
       "  [[ 0.00765935 -0.01586042 -0.01249991]\n",
       "   [-0.00079244 -0.01467744  0.10067401]\n",
       "   [-0.04039896 -0.02005445 -0.00711605]]\n",
       "\n",
       "  [[-0.10328984 -0.0535966  -0.03392352]\n",
       "   [ 0.02976998  0.07230691  0.06908812]\n",
       "   [-0.04546015 -0.05153897 -0.06480247]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.0070868   0.00938178 -0.00544529]\n",
       "   [-0.09389155  0.01959044  0.04377877]\n",
       "   [-0.06762378 -0.0329773   0.06007441]]\n",
       "\n",
       "  [[ 0.02986882 -0.11019504 -0.11619313]\n",
       "   [ 0.09995156  0.10913319 -0.10641829]\n",
       "   [-0.06335922  0.00646426  0.10509921]]\n",
       "\n",
       "  [[ 0.08675022  0.08664448 -0.1098199 ]\n",
       "   [ 0.00331356 -0.00187818 -0.07079825]\n",
       "   [ 0.0577076   0.02413637 -0.01189044]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.04778593  0.08398881  0.03136829]\n",
       "   [-0.07407292  0.05938094 -0.02747986]\n",
       "   [ 0.06026339 -0.08766058 -0.11293681]]\n",
       "\n",
       "  [[ 0.04645235 -0.09875906 -0.08499317]\n",
       "   [-0.04851406  0.034994    0.04832434]\n",
       "   [-0.04298678 -0.09601339 -0.10151485]]\n",
       "\n",
       "  [[ 0.07464734 -0.03293914 -0.06233732]\n",
       "   [ 0.02458305  0.10398766  0.04098863]\n",
       "   [ 0.02308751  0.06816975 -0.11231747]]]\n",
       "\n",
       "\n",
       " [[[-0.02933128 -0.06860529 -0.10139706]\n",
       "   [ 0.02435719 -0.10953418  0.01431978]\n",
       "   [ 0.04437434  0.01846709  0.03312323]]\n",
       "\n",
       "  [[ 0.05368101 -0.08317094 -0.08957916]\n",
       "   [ 0.03789932  0.09433054  0.0816843 ]\n",
       "   [-0.02192013  0.11146647 -0.03398576]]\n",
       "\n",
       "  [[-0.00226191  0.10830023 -0.11369399]\n",
       "   [-0.03664935  0.05322992 -0.01288033]\n",
       "   [ 0.08504245 -0.10482323 -0.01505179]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.05494811  0.02482646 -0.10490188]\n",
       "   [ 0.01156456 -0.08555114 -0.06266444]\n",
       "   [ 0.10471573  0.05411824 -0.10698368]]\n",
       "\n",
       "  [[ 0.11158954  0.0869856   0.07516759]\n",
       "   [ 0.11528201 -0.09075028  0.08242213]\n",
       "   [-0.05142607 -0.00498561 -0.04510528]]\n",
       "\n",
       "  [[-0.02594128  0.04859742  0.08633048]\n",
       "   [-0.08991379  0.01653565 -0.01028105]\n",
       "   [ 0.10650278  0.04709851  0.04210464]]]\n",
       "\n",
       "\n",
       " [[[-0.00932021 -0.11301627  0.04408962]\n",
       "   [-0.01989694  0.06719355 -0.0565851 ]\n",
       "   [ 0.06009115 -0.00729082 -0.02609874]]\n",
       "\n",
       "  [[ 0.01176082  0.11522078 -0.00057384]\n",
       "   [-0.0349285   0.05100989  0.05695517]\n",
       "   [-0.0210886  -0.10224926 -0.03217258]]\n",
       "\n",
       "  [[ 0.07885333 -0.04289071 -0.11050623]\n",
       "   [ 0.0116862   0.1011362   0.01308129]\n",
       "   [ 0.09525668 -0.00123814  0.00275118]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00897247  0.10901894  0.03509771]\n",
       "   [-0.11319994  0.03147358 -0.03104576]\n",
       "   [-0.02268737  0.05590992  0.11742789]]\n",
       "\n",
       "  [[-0.09170699  0.09731416  0.1078024 ]\n",
       "   [ 0.03355918  0.01081809 -0.05249008]\n",
       "   [-0.00724667  0.01866774  0.02748851]]\n",
       "\n",
       "  [[-0.00050731 -0.06097165 -0.05974628]\n",
       "   [-0.11410346 -0.04882569  0.01884864]\n",
       "   [ 0.01119485  0.04000121 -0.07791477]]]]), LetNode(Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.conv2d), [Var(x_4, ty=TensorType([1, 16, (int64)128, (int64)128], float32)), Var(x_5, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x3185d338), [TensorType([1, 16, (int64)128, (int64)128], float32), TensorType([32, 16, 3, 3], float32)]), LetNode(Var(x_7, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_8, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.bias_add), [Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), Var(x_7, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31851c78), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)]), LetNode(Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), CallNode(Op(nn.max_pool2d), [Var(x_8, ty=TensorType([1, 32, 128, 128], float32))], relay.attrs.MaxPool2DAttrs(0x31814f48), [TensorType([1, 32, 128, 128], float32)]), LetNode(Var(x_10, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "   [-0.03190579 -0.01584832  0.02670189]\n",
       "   [ 0.01921258 -0.07818282  0.03479443]]\n",
       "\n",
       "  [[-0.00130421 -0.01830789  0.05642799]\n",
       "   [-0.0170652  -0.02210277  0.04254849]\n",
       "   [ 0.01875039 -0.08010064 -0.08040661]]\n",
       "\n",
       "  [[ 0.02165145  0.0240651  -0.04487719]\n",
       "   [-0.02167934 -0.00768209  0.0794398 ]\n",
       "   [-0.02068903  0.06871933  0.07726983]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.03205558  0.00290275 -0.02926568]\n",
       "   [ 0.04182967  0.04922665 -0.06711974]\n",
       "   [-0.02741003  0.05309341  0.01915387]]\n",
       "\n",
       "  [[-0.04150633  0.08178725  0.03009626]\n",
       "   [ 0.05355413  0.03888881 -0.05639726]\n",
       "   [ 0.04942527 -0.00437707  0.00632731]]\n",
       "\n",
       "  [[-0.02561722  0.05984905 -0.05160853]\n",
       "   [-0.07984905 -0.05768615  0.07380161]\n",
       "   [-0.07858952 -0.07737446  0.01850816]]]\n",
       "\n",
       "\n",
       " [[[-0.03143118  0.0695676  -0.04244177]\n",
       "   [ 0.04627309 -0.03359256 -0.06305707]\n",
       "   [ 0.01931474  0.06957508 -0.04066815]]\n",
       "\n",
       "  [[-0.05282148  0.07525725 -0.06407903]\n",
       "   [ 0.05680341  0.03004328 -0.07779044]\n",
       "   [-0.04317856 -0.04223323  0.04984415]]\n",
       "\n",
       "  [[-0.05401897 -0.03738686 -0.04842353]\n",
       "   [ 0.02915064 -0.01600464  0.07291468]\n",
       "   [-0.03190204 -0.0579984   0.04465697]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "   [ 0.00072628 -0.05233977 -0.03741848]\n",
       "   [ 0.07280735 -0.03233246  0.01515931]]\n",
       "\n",
       "  [[-0.05387771 -0.07664208  0.03958815]\n",
       "   [-0.06479758 -0.02311367 -0.05349527]\n",
       "   [-0.03774371 -0.00293905 -0.01947474]]\n",
       "\n",
       "  [[-0.06706224 -0.0475895  -0.03024844]\n",
       "   [-0.06104823 -0.05882414  0.03911529]\n",
       "   [-0.03023565  0.0054945   0.03267833]]]\n",
       "\n",
       "\n",
       " [[[-0.05496893  0.04519042 -0.04979972]\n",
       "   [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "   [ 0.06344249  0.04820261 -0.01685154]]\n",
       "\n",
       "  [[-0.07507978 -0.0369214   0.01589892]\n",
       "   [ 0.07496265 -0.03811238  0.07452969]\n",
       "   [-0.05802975  0.06737594 -0.02538034]]\n",
       "\n",
       "  [[-0.06388503 -0.06834688 -0.02203981]\n",
       "   [ 0.00349629 -0.03683617 -0.07054752]\n",
       "   [ 0.00112883 -0.06129277 -0.03130053]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.03836095  0.0297214   0.07942633]\n",
       "   [-0.01441041  0.00916564  0.06147317]\n",
       "   [ 0.08268154  0.01616826  0.08289457]]\n",
       "\n",
       "  [[ 0.03203704  0.01688347 -0.03459275]\n",
       "   [ 0.00918504 -0.00689121 -0.04055142]\n",
       "   [-0.08139901  0.06464074  0.02731381]]\n",
       "\n",
       "  [[-0.0072248  -0.07411295 -0.05513853]\n",
       "   [-0.02443562  0.03619969 -0.01066486]\n",
       "   [-0.0525009  -0.04152107 -0.04262205]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "   [-0.03333757  0.02255654  0.01452807]\n",
       "   [ 0.07274816  0.04599313 -0.00011758]]\n",
       "\n",
       "  [[ 0.07283399  0.05451591 -0.04420283]\n",
       "   [ 0.07164187  0.08015741  0.06468589]\n",
       "   [-0.03062155 -0.05015038  0.02159031]]\n",
       "\n",
       "  [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "   [-0.00470024  0.00760442 -0.00532582]\n",
       "   [-0.02140979  0.03761176  0.07121743]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "   [ 0.08175186 -0.01663043  0.01697671]\n",
       "   [-0.04998031 -0.00914244  0.02868303]]\n",
       "\n",
       "  [[-0.00251392 -0.02931277 -0.01294055]\n",
       "   [ 0.07991172 -0.0130088  -0.05366091]\n",
       "   [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       "\n",
       "  [[-0.004662   -0.04977087  0.04939119]\n",
       "   [-0.01845763 -0.06482323  0.02449331]\n",
       "   [-0.01165619  0.06523957  0.03770921]]]\n",
       "\n",
       "\n",
       " [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "   [-0.05209206  0.03204753  0.02439884]\n",
       "   [-0.0282647   0.03098512  0.07474277]]\n",
       "\n",
       "  [[-0.05827966  0.00631046 -0.04896474]\n",
       "   [ 0.00211457  0.03935728  0.01188233]\n",
       "   [ 0.0395141  -0.0487875  -0.05219557]]\n",
       "\n",
       "  [[ 0.01199625  0.01175252 -0.08195679]\n",
       "   [-0.04492062 -0.07222724  0.08265557]\n",
       "   [ 0.00680294 -0.06261617 -0.04109164]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.02842131  0.04017299 -0.06411938]\n",
       "   [-0.03479248 -0.00351638  0.04439355]\n",
       "   [-0.00836619 -0.00725466 -0.07700257]]\n",
       "\n",
       "  [[ 0.00681683  0.06109884 -0.03970103]\n",
       "   [-0.07532208  0.02519193  0.03664758]\n",
       "   [ 0.02089242  0.03030465 -0.04797888]]\n",
       "\n",
       "  [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "   [-0.00750206 -0.06763705  0.05190892]\n",
       "   [ 0.02197877  0.07384106  0.04836109]]]\n",
       "\n",
       "\n",
       " [[[-0.03292805  0.05048368  0.05959893]\n",
       "   [-0.00935958  0.07049897  0.07671262]\n",
       "   [-0.0200305   0.02493731 -0.05899358]]\n",
       "\n",
       "  [[-0.06843758  0.01676033  0.07503303]\n",
       "   [-0.00159057  0.07050664 -0.06662065]\n",
       "   [-0.07063043 -0.00717596 -0.07401031]]\n",
       "\n",
       "  [[-0.05164689  0.01307825  0.0358992 ]\n",
       "   [ 0.07245863  0.0667781   0.00989082]\n",
       "   [ 0.02502123 -0.00115818  0.06598707]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "   [ 0.06617681  0.03855822  0.08260872]\n",
       "   [ 0.0201846   0.02270871  0.0820188 ]]\n",
       "\n",
       "  [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "   [ 0.05576969 -0.03805411 -0.05533451]\n",
       "   [ 0.08203562 -0.04242806 -0.03506017]]\n",
       "\n",
       "  [[ 0.03055421 -0.0600045   0.01011878]\n",
       "   [ 0.07702617  0.05981912  0.04538635]\n",
       "   [-0.0253101  -0.06463408 -0.07805812]]]]), LetNode(Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.conv2d), [Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), Var(x_10, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x54ef238), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_12, ty=TensorType([64], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_13, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), Var(x_12, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x3181d6a8), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)]), LetNode(Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), CallNode(Op(nn.max_pool2d), [Var(x_13, ty=TensorType([1, 64, 64, 64], float32))], relay.attrs.MaxPool2DAttrs(0x31832b38), [TensorType([1, 64, 64, 64], float32)]), LetNode(Var(x_15, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00667036  0.07674357  0.02048975]\n",
       "   [-0.0005337   0.06994274 -0.0409746 ]\n",
       "   [-0.01644263  0.02424868 -0.08242689]]\n",
       "\n",
       "  [[-0.0279611   0.02216059 -0.04442815]\n",
       "   [-0.00076614 -0.00510069  0.00525645]\n",
       "   [ 0.05821113  0.01974467  0.01869611]]\n",
       "\n",
       "  [[-0.01291529 -0.04766705 -0.04010829]\n",
       "   [-0.06574585 -0.06930234 -0.07820863]\n",
       "   [ 0.05632005 -0.01981469  0.03960329]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00203542 -0.01508743 -0.05518967]\n",
       "   [ 0.0098869  -0.02211016 -0.05686476]\n",
       "   [ 0.04343555  0.04212476 -0.04262485]]\n",
       "\n",
       "  [[ 0.04512688 -0.01977579 -0.03921237]\n",
       "   [ 0.05846582 -0.01097473 -0.08292767]\n",
       "   [ 0.02642258 -0.05865683  0.00781246]]\n",
       "\n",
       "  [[ 0.00868873  0.01789419 -0.05306506]\n",
       "   [ 0.03495514  0.00849197 -0.03360848]\n",
       "   [ 0.05213998 -0.05043467  0.02092493]]]\n",
       "\n",
       "\n",
       " [[[-0.05225816 -0.03435542  0.06766681]\n",
       "   [-0.00570095 -0.07121497  0.04150715]\n",
       "   [ 0.03178158  0.0278095  -0.03169968]]\n",
       "\n",
       "  [[ 0.08237877  0.00820927  0.07866023]\n",
       "   [ 0.06363843  0.00969597 -0.07367277]\n",
       "   [-0.07699051 -0.07091855 -0.04057622]]\n",
       "\n",
       "  [[ 0.03507438  0.06507566 -0.07537719]\n",
       "   [-0.02447435 -0.06244735 -0.06095092]\n",
       "   [ 0.01566204  0.02181033  0.05003274]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.0431037   0.0482654   0.08321209]\n",
       "   [-0.05071964 -0.05884733 -0.0633956 ]\n",
       "   [ 0.06844861 -0.05180594 -0.0485846 ]]\n",
       "\n",
       "  [[-0.03323257  0.02323034  0.00272747]\n",
       "   [ 0.05667796 -0.0002616  -0.00519013]\n",
       "   [ 0.01162627  0.02526001  0.06600187]]\n",
       "\n",
       "  [[ 0.07655057  0.02485903 -0.05985588]\n",
       "   [ 0.04408409 -0.0380648  -0.00562543]\n",
       "   [-0.03243604 -0.03266114  0.02271339]]]\n",
       "\n",
       "\n",
       " [[[ 0.02307111 -0.07447599  0.00114187]\n",
       "   [ 0.0209925  -0.03011368 -0.04503453]\n",
       "   [-0.01692474  0.06745539 -0.02362834]]\n",
       "\n",
       "  [[ 0.06450888 -0.01736359 -0.02165564]\n",
       "   [-0.0565699   0.01656731  0.02207325]\n",
       "   [-0.03282728 -0.07110369 -0.05474281]]\n",
       "\n",
       "  [[-0.00164378  0.07526512  0.07337628]\n",
       "   [ 0.01917853 -0.02339783  0.00305605]\n",
       "   [-0.05832756 -0.04507156 -0.02815646]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.06093149 -0.06571921 -0.0378267 ]\n",
       "   [-0.05794454  0.02385507  0.04264715]\n",
       "   [ 0.0108671   0.05971035 -0.07129908]]\n",
       "\n",
       "  [[-0.08070076  0.06473055 -0.0824315 ]\n",
       "   [ 0.02900531 -0.03235545 -0.03446659]\n",
       "   [-0.0361414  -0.0720194  -0.06739503]]\n",
       "\n",
       "  [[ 0.06519654  0.05091707 -0.03405452]\n",
       "   [ 0.01338766  0.07065854 -0.01776394]\n",
       "   [ 0.03464925  0.03024761  0.03585237]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.03777675 -0.03727138  0.01838966]\n",
       "   [-0.08274333 -0.064996    0.07656416]\n",
       "   [ 0.00311184  0.00922922  0.08024732]]\n",
       "\n",
       "  [[-0.04885089  0.00447249  0.076678  ]\n",
       "   [-0.06130725 -0.08112308  0.01622806]\n",
       "   [ 0.00925171  0.07307453  0.00239494]]\n",
       "\n",
       "  [[ 0.06266668 -0.07882553 -0.02372478]\n",
       "   [-0.00127685 -0.05542324  0.01506688]\n",
       "   [-0.04899919 -0.02099749 -0.04583566]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.01963693 -0.01299276 -0.00876871]\n",
       "   [ 0.03455848  0.01813295 -0.01817822]\n",
       "   [ 0.00511507  0.01796635  0.03721446]]\n",
       "\n",
       "  [[ 0.02849569 -0.0781398   0.06691042]\n",
       "   [ 0.08145543 -0.06311989 -0.06119695]\n",
       "   [-0.08139144 -0.04604743 -0.03518212]]\n",
       "\n",
       "  [[-0.04671299  0.06773625 -0.05673073]\n",
       "   [-0.06609975  0.01549089  0.02074935]\n",
       "   [ 0.07406517 -0.04903018 -0.04878726]]]\n",
       "\n",
       "\n",
       " [[[-0.02131156  0.06878123  0.02314601]\n",
       "   [ 0.07108916  0.04008206  0.02196169]\n",
       "   [-0.07365716 -0.03871602  0.04667952]]\n",
       "\n",
       "  [[ 0.02348771  0.02149502  0.02541289]\n",
       "   [-0.01793929  0.06772844  0.02993079]\n",
       "   [-0.07476664  0.01974591 -0.07887741]]\n",
       "\n",
       "  [[ 0.05220968  0.00943748  0.03035134]\n",
       "   [ 0.03464494 -0.02933544 -0.04283194]\n",
       "   [ 0.06609956  0.06831052 -0.05975342]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00016204  0.0783995   0.07785139]\n",
       "   [ 0.03268198 -0.01940602  0.05926634]\n",
       "   [-0.05186518 -0.06860392  0.07977588]]\n",
       "\n",
       "  [[ 0.06457258  0.077715   -0.05051591]\n",
       "   [-0.07378592 -0.07513899 -0.02788895]\n",
       "   [-0.06781612 -0.02720525  0.08009199]]\n",
       "\n",
       "  [[-0.00609747 -0.00378752  0.06699146]\n",
       "   [-0.00971287 -0.05465307 -0.02018831]\n",
       "   [ 0.08092386 -0.01566859 -0.06308937]]]\n",
       "\n",
       "\n",
       " [[[-0.01809273 -0.05052249  0.00830408]\n",
       "   [ 0.00651675  0.02668866 -0.02696224]\n",
       "   [ 0.06081321  0.03202073 -0.04717416]]\n",
       "\n",
       "  [[ 0.0587954   0.06785775  0.06052122]\n",
       "   [ 0.00263701 -0.01710707 -0.00749189]\n",
       "   [ 0.02028066 -0.00381591  0.05403914]]\n",
       "\n",
       "  [[-0.06002963  0.00170328  0.01363794]\n",
       "   [ 0.02595466  0.02344725 -0.03352585]\n",
       "   [ 0.06551506  0.0296605   0.06894781]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.04791441  0.06846394  0.05488243]\n",
       "   [-0.04654666 -0.07713521  0.08156196]\n",
       "   [ 0.03400215  0.06116603 -0.02428303]]\n",
       "\n",
       "  [[ 0.06481076  0.04652277 -0.04640434]\n",
       "   [-0.02026961  0.07876632  0.04329368]\n",
       "   [-0.06511961 -0.05031322 -0.04249084]]\n",
       "\n",
       "  [[-0.05632734 -0.02485887 -0.06702858]\n",
       "   [-0.0249401  -0.0442156   0.00897348]\n",
       "   [ 0.06168193  0.00339633  0.07160915]]]]), LetNode(Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.conv2d_transpose), [Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), Var(x_15, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x68056e8), [TensorType([1, 64, (int64)32, (int64)32], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_17, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), Var(x_17, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x396c968), [TensorType([1, 32, 64, 64], float32), TensorType([32], float32)]), LetNode(Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])), Tuple([Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), Var(x_13, ty=TensorType([1, 64, 64, 64], float32))]), LetNode(Var(x_20, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x318388b8), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Var(x_20, ty=TensorType([1, 96, 64, 64], float32)))))))))))))))))))))))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(32), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(32), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(16), float32] */;\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "let %x_21: Tensor[(96, 16, 3, 3), float32] /* ty=Tensor[(96, 16, 3, 3), float32] */ = meta[relay.Constant][8] /* ty=Tensor[(96, 16, 3, 3), float32] */;\n",
      "free_var %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_22: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.conv2d_transpose(%x_20, %x_21, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "let %x_23: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][9] /* ty=Tensor[(16), float32] */;\n",
      "let %x_24: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.bias_add(%x_22, %x_23) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "free_var %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_25: (Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */ = (%x_24, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
      "let %x_26: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = concatenate(%x_25, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_27: Tensor[(48, 1, 3, 3), float32] /* ty=Tensor[(48, 1, 3, 3), float32] */ = meta[relay.Constant][10] /* ty=Tensor[(48, 1, 3, 3), float32] */;\n",
      "let %x_28: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.conv2d_transpose(%x_26, %x_27, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_29: Tensor[(1), float32] /* ty=Tensor[(1), float32] */ = meta[relay.Constant][11] /* ty=Tensor[(1), float32] */;\n",
      "let %x_30: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.bias_add(%x_28, %x_29) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "%x_30\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[1].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "%x_15\n",
      "free_var %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "%x_12\n",
      "free_var %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "%x_10\n",
      "free_var %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n",
      "%x_7\n",
      "free_var %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "%x_5\n",
      "free_var %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "%x_2\n",
      "free_var %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "%x_0\n",
      "free_var %x_21: Tensor[(96, 16, 3, 3), float32] /* ty=Tensor[(96, 16, 3, 3), float32] */;\n",
      "%x_21\n",
      "free_var %x_22: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "%x_22\n",
      "free_var %x_23: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "%x_23\n",
      "free_var %x_24: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "%x_24\n",
      "free_var %x_25: (Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
      "%x_25\n"
     ]
    }
   ],
   "source": [
    "prev = subgraphs[1]\n",
    "for i in range(12):\n",
    "    print(prev.body.var)\n",
    "    prev = prev.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(32), float32] */;\n",
      "let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(64), float32] */;\n",
      "let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n",
      "let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(32), float32] */;\n",
      "let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n",
      "let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(16), float32] */;\n",
      "let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "let %x_21: Tensor[(96, 16, 3, 3), float32] /* ty=Tensor[(96, 16, 3, 3), float32] */ = meta[relay.Constant][8] /* ty=Tensor[(96, 16, 3, 3), float32] */;\n",
      "free_var %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "let %x_22: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.conv2d_transpose(%x_20, %x_21, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "let %x_23: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][9] /* ty=Tensor[(16), float32] */;\n",
      "let %x_24: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */ = nn.bias_add(%x_22, %x_23) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "free_var %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_25: (Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */ = (%x_24, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
      "let %x_26: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = concatenate(%x_25, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_27: Tensor[(48, 1, 3, 3), float32] /* ty=Tensor[(48, 1, 3, 3), float32] */ = meta[relay.Constant][10] /* ty=Tensor[(48, 1, 3, 3), float32] */;\n",
      "let %x_28: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.conv2d_transpose(%x_26, %x_27, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_29: Tensor[(1), float32] /* ty=Tensor[(1), float32] */ = meta[relay.Constant][11] /* ty=Tensor[(1), float32] */;\n",
      "let %x_30: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.bias_add(%x_28, %x_29) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "%x_30\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(subgraphs[1].astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_6 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_7 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_8 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_9 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_10 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_11 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_12 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_13 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_14 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_15 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_16 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_17 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_18 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_19 is bound more than once, this is not valid IR\n",
      "[13:46:51] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_20 is bound more than once, this is not valid IR\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  6: TVMFuncCall\n  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  4: tvm::IRModule::FromExpr(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)\n  3: tvm::IRModule::FromExprInContext(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >)\n  2: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  1: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  0: tvm::relay::DeDup(tvm::RelayExpr const&)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/relay/transforms/de_duplicate.cc\", line 113\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (WellFormed(e)) is false: #[version = \"0.0.5\"]\nfn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n  free_var %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  free_var %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n  %0 = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %9 = (\n    let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = %0;\n    %1 = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n    let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = %1;\n    let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    %2 = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = %2;\n    let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(64), float32] */;\n    %3 = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = %3;\n    %4 = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n    let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = %4;\n    let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    %5 = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = %5;\n    let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n    %6 = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = %6;\n    %7 = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n    let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = %7;\n    %8 = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = %8;\n    %x_20\n  );\n  %10 = (\n    let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n    let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(16), float32] */;\n    let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n    let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n    let %x_6-malformed-ir = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_7-malformed-ir = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n    let %x_8-malformed-ir = %0;\n    let %x_9-malformed-ir = %1;\n    let %x_10-malformed-ir = meta[relay.Constant][0] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_11-malformed-ir = %2;\n    let %x_12-malformed-ir = meta[relay.Constant][1] /* ty=Tensor[(64), float32] */;\n    let %x_13-malformed-ir = %3;\n    let %x_14-malformed-ir = %4;\n    let %x_15-malformed-ir = meta[relay.Constant][2] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_16-malformed-ir = %5;\n    let %x_17-malformed-ir = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n    let %x_18-malformed-ir = %6;\n    let %x_19-malformed-ir = %7;\n    let %x_20-malformed-ir = %8;\n    %x_20\n  );\n  (%9, %10)\n}\n/* For debugging purposes the metadata section has been omitted.\n * If you would like to see the full metadata section you can set the \n * option to `True` when invoking `astext`. \n */",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ann \u001b[39m=\u001b[39m run_opt_pass(a, transform\u001b[39m.\u001b[39;49mToGraphNormalForm())\n\u001b[1;32m      2\u001b[0m out \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mIRModule\u001b[39m.\u001b[39mfrom_expr(ann)[\u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/testing/__init__.py:53\u001b[0m, in \u001b[0;36mrun_opt_pass\u001b[0;34m(expr, opt_pass, import_prelude)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_opt_pass\u001b[39m(expr, opt_pass, import_prelude\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     52\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(opt_pass, tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPass)\n\u001b[0;32m---> 53\u001b[0m     mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39;49mIRModule\u001b[39m.\u001b[39;49mfrom_expr(expr)\n\u001b[1;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m import_prelude:\n\u001b[1;32m     55\u001b[0m         Prelude(mod)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:243\u001b[0m, in \u001b[0;36mIRModule.from_expr\u001b[0;34m(expr, functions, type_defs)\u001b[0m\n\u001b[1;32m    241\u001b[0m funcs \u001b[39m=\u001b[39m functions \u001b[39mif\u001b[39;00m functions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    242\u001b[0m defs \u001b[39m=\u001b[39m type_defs \u001b[39mif\u001b[39;00m type_defs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39;49mModule_FromExpr(expr, funcs, defs)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  6: TVMFuncCall\n  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  4: tvm::IRModule::FromExpr(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)\n  3: tvm::IRModule::FromExprInContext(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >)\n  2: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  1: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  0: tvm::relay::DeDup(tvm::RelayExpr const&)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/relay/transforms/de_duplicate.cc\", line 113\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (WellFormed(e)) is false: #[version = \"0.0.5\"]\nfn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n  free_var %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  free_var %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n  %0 = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %9 = (\n    let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = %0;\n    %1 = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n    let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = %1;\n    let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    %2 = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = %2;\n    let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(64), float32] */;\n    %3 = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = %3;\n    %4 = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n    let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = %4;\n    let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    %5 = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = %5;\n    let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n    %6 = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = %6;\n    %7 = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n    let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = %7;\n    %8 = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = %8;\n    %x_20\n  );\n  %10 = (\n    let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n    let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(16), float32] */;\n    let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n    let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n    let %x_6-malformed-ir = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_7-malformed-ir = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n    let %x_8-malformed-ir = %0;\n    let %x_9-malformed-ir = %1;\n    let %x_10-malformed-ir = meta[relay.Constant][0] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_11-malformed-ir = %2;\n    let %x_12-malformed-ir = meta[relay.Constant][1] /* ty=Tensor[(64), float32] */;\n    let %x_13-malformed-ir = %3;\n    let %x_14-malformed-ir = %4;\n    let %x_15-malformed-ir = meta[relay.Constant][2] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_16-malformed-ir = %5;\n    let %x_17-malformed-ir = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n    let %x_18-malformed-ir = %6;\n    let %x_19-malformed-ir = %7;\n    let %x_20-malformed-ir = %8;\n    %x_20\n  );\n  (%9, %10)\n}\n/* For debugging purposes the metadata section has been omitted.\n * If you would like to see the full metadata section you can set the \n * option to `True` when invoking `astext`. \n */"
     ]
    }
   ],
   "source": [
    "ann = run_opt_pass(a, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = run_opt_pass(subgraphs[1], transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */, %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */) {\n",
       "  %0 = nn.conv2d_transpose(%x_20, meta[relay.Constant][0] /* ty=Tensor[(96, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
       "  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
       "  %2 = (%1, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
       "  %3 = concatenate(%2, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
       "  %4 = nn.conv2d_transpose(%3, meta[relay.Constant][2] /* ty=Tensor[(48, 1, 3, 3), float32] */, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
       "  nn.bias_add(%4, meta[relay.Constant][3] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 256, 256), float32] */\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %x_24: Tensor[(1, 16, 128, 128), float32] /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
      "free_var %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "let %x_25: (Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */ = (%x_24, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
      "let %x_26: Tensor[(1, 48, 128, 128), float32] /* ty=Tensor[(1, 48, 128, 128), float32] */ = concatenate(%x_25, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
      "let %x_27: Tensor[(48, 1, 3, 3), float32] /* ty=Tensor[(48, 1, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(48, 1, 3, 3), float32] */;\n",
      "let %x_28: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.conv2d_transpose(%x_26, %x_27, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_29: Tensor[(1), float32] /* ty=Tensor[(1), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(1), float32] */;\n",
      "let %x_30: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.bias_add(%x_28, %x_29) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "%x_30\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(prev.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = subgraphs[0]\n",
    "ann = run_opt_pass(out, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n",
       "  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
       "  %3 = nn.conv2d(%2, meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "  %4 = nn.bias_add(%3, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
       "  %6 = nn.conv2d(%5, meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "  %7 = nn.bias_add(%6, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
       "  %9 = nn.conv2d_transpose(%8, meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "  %10 = nn.bias_add(%9, meta[relay.Constant][7] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "  %11 = (%10, %7) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
       "  concatenate(%11, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm.IRModule.from_expr(run_opt_pass(subgraphs[0], transform.ToGraphNormalForm()))['main']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */, %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */) {\n",
       "  %0 = nn.conv2d_transpose(%x_20, meta[relay.Constant][0] /* ty=Tensor[(96, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
       "  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
       "  %2 = (%1, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
       "  %3 = concatenate(%2, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
       "  %4 = nn.conv2d_transpose(%3, meta[relay.Constant][2] /* ty=Tensor[(48, 1, 3, 3), float32] */, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
       "  nn.bias_add(%4, meta[relay.Constant][3] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 256, 256), float32] */\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm.IRModule.from_expr(run_opt_pass(subgraphs[1], transform.ToGraphNormalForm()))['main']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = subgraphs[0]\n",
    "ann = run_opt_pass(out, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']\n",
    "# outs = outputs[0][1]\n",
    "outs = run_opt_pass(outputs[0][1], transform.ToGraphNormalForm())\n",
    "outs = tvm.IRModule.from_expr(outs)['main']\n",
    "\n",
    "# outnew = run_opt_pass(out_1, transform.ToGraphNormalForm())\n",
    "# outnew = tvm.IRModule.from_expr(outnew)['main']\n",
    "\n",
    "# out1 = relay.Function(params, relay.Tuple([outs, out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  1: TVMFuncCall\n  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  2: TVMFuncCall\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::RelayExpr tvm::runtime::TVMPODValue_::AsObjectRef<tvm::RelayExpr>() const\n  File \"/home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h\", line 777\nTVMError: In function ir.Module_FromExpr(0: RelayExpr&, 1: Map<GlobalVar, BaseFunc>&, 2: Map<GlobalTypeVar, relay.TypeData>&) -> IRModule: error while converting argument 0: [16:06:33] /home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h:1863: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected RelayExpr, but got Array\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tvm\u001b[39m.\u001b[39;49mIRModule\u001b[39m.\u001b[39;49mfrom_expr([out, outs])\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:243\u001b[0m, in \u001b[0;36mIRModule.from_expr\u001b[0;34m(expr, functions, type_defs)\u001b[0m\n\u001b[1;32m    241\u001b[0m funcs \u001b[39m=\u001b[39m functions \u001b[39mif\u001b[39;00m functions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    242\u001b[0m defs \u001b[39m=\u001b[39m type_defs \u001b[39mif\u001b[39;00m type_defs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39;49mModule_FromExpr(expr, funcs, defs)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  1: TVMFuncCall\n  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  2: TVMFuncCall\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  0: tvm::RelayExpr tvm::runtime::TVMPODValue_::AsObjectRef<tvm::RelayExpr>() const\n  File \"/home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h\", line 777\nTVMError: In function ir.Module_FromExpr(0: RelayExpr&, 1: Map<GlobalVar, BaseFunc>&, 2: Map<GlobalTypeVar, relay.TypeData>&) -> IRModule: error while converting argument 0: [16:06:33] /home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h:1863: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected RelayExpr, but got Array\n"
     ]
    }
   ],
   "source": [
    "tvm.IRModule.from_expr([out, outs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */, %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) {\n",
       "  %0 = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "  %1 = nn.max_pool2d(%0, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
       "  %2 = nn.conv2d(%1, meta[relay.Constant][0] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "  %3 = nn.bias_add(%2, meta[relay.Constant][1] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "  %4 = nn.max_pool2d(%3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
       "  %5 = nn.conv2d_transpose(%4, meta[relay.Constant][2] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "  %6 = nn.bias_add(%5, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "  %7 = (%6, %3) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
       "  concatenate(%7, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n",
       "  %20 = fn (%x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */, %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) {\n",
       "    %0 = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "    %1 = nn.max_pool2d(%0, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
       "    %2 = nn.conv2d(%1, meta[relay.Constant][0] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "    %3 = nn.bias_add(%2, meta[relay.Constant][1] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "    %4 = nn.max_pool2d(%3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
       "    %5 = nn.conv2d_transpose(%4, meta[relay.Constant][2] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "    %6 = nn.bias_add(%5, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "    %7 = (%6, %3) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
       "    concatenate(%7, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */\n",
       "  };\n",
       "  %21 = fn (%input_1-malformed-ir) {\n",
       "    %8 = nn.conv2d(%input_1, meta[relay.Constant][4] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "    %9 = nn.bias_add(%8, meta[relay.Constant][5] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "    %10 = nn.max_pool2d(%9, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
       "    %11 = nn.conv2d(%10, meta[relay.Constant][6] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "    %12 = nn.bias_add(%11, meta[relay.Constant][7] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
       "    %13 = nn.max_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
       "    %14 = nn.conv2d(%13, meta[relay.Constant][8] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "    %15 = nn.bias_add(%14, meta[relay.Constant][9] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
       "    %16 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
       "    %17 = nn.conv2d_transpose(%16, meta[relay.Constant][10] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "    %18 = nn.bias_add(%17, meta[relay.Constant][11] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
       "    %19 = (%18, %15) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
       "    concatenate(%19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */\n",
       "  };\n",
       "  (%20, %21)\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LetNode(Var(x_8, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.bias_add), [Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), Var(x_7, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x2e6abf8), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)]), LetNode(Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), CallNode(Op(nn.max_pool2d), [Var(x_8, ty=TensorType([1, 32, 128, 128], float32))], relay.attrs.MaxPool2DAttrs(0x3205c728), [TensorType([1, 32, 128, 128], float32)]), LetNode(Var(x_10, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "    [-0.03190579 -0.01584832  0.02670189]\n",
       "    [ 0.01921258 -0.07818282  0.03479443]]\n",
       " \n",
       "   [[-0.00130421 -0.01830789  0.05642799]\n",
       "    [-0.0170652  -0.02210277  0.04254849]\n",
       "    [ 0.01875039 -0.08010064 -0.08040661]]\n",
       " \n",
       "   [[ 0.02165145  0.0240651  -0.04487719]\n",
       "    [-0.02167934 -0.00768209  0.0794398 ]\n",
       "    [-0.02068903  0.06871933  0.07726983]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[-0.03205558  0.00290275 -0.02926568]\n",
       "    [ 0.04182967  0.04922665 -0.06711974]\n",
       "    [-0.02741003  0.05309341  0.01915387]]\n",
       " \n",
       "   [[-0.04150633  0.08178725  0.03009626]\n",
       "    [ 0.05355413  0.03888881 -0.05639726]\n",
       "    [ 0.04942527 -0.00437707  0.00632731]]\n",
       " \n",
       "   [[-0.02561722  0.05984905 -0.05160853]\n",
       "    [-0.07984905 -0.05768615  0.07380161]\n",
       "    [-0.07858952 -0.07737446  0.01850816]]]\n",
       " \n",
       " \n",
       "  [[[-0.03143118  0.0695676  -0.04244177]\n",
       "    [ 0.04627309 -0.03359256 -0.06305707]\n",
       "    [ 0.01931474  0.06957508 -0.04066815]]\n",
       " \n",
       "   [[-0.05282148  0.07525725 -0.06407903]\n",
       "    [ 0.05680341  0.03004328 -0.07779044]\n",
       "    [-0.04317856 -0.04223323  0.04984415]]\n",
       " \n",
       "   [[-0.05401897 -0.03738686 -0.04842353]\n",
       "    [ 0.02915064 -0.01600464  0.07291468]\n",
       "    [-0.03190204 -0.0579984   0.04465697]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "    [ 0.00072628 -0.05233977 -0.03741848]\n",
       "    [ 0.07280735 -0.03233246  0.01515931]]\n",
       " \n",
       "   [[-0.05387771 -0.07664208  0.03958815]\n",
       "    [-0.06479758 -0.02311367 -0.05349527]\n",
       "    [-0.03774371 -0.00293905 -0.01947474]]\n",
       " \n",
       "   [[-0.06706224 -0.0475895  -0.03024844]\n",
       "    [-0.06104823 -0.05882414  0.03911529]\n",
       "    [-0.03023565  0.0054945   0.03267833]]]\n",
       " \n",
       " \n",
       "  [[[-0.05496893  0.04519042 -0.04979972]\n",
       "    [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "    [ 0.06344249  0.04820261 -0.01685154]]\n",
       " \n",
       "   [[-0.07507978 -0.0369214   0.01589892]\n",
       "    [ 0.07496265 -0.03811238  0.07452969]\n",
       "    [-0.05802975  0.06737594 -0.02538034]]\n",
       " \n",
       "   [[-0.06388503 -0.06834688 -0.02203981]\n",
       "    [ 0.00349629 -0.03683617 -0.07054752]\n",
       "    [ 0.00112883 -0.06129277 -0.03130053]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[ 0.03836095  0.0297214   0.07942633]\n",
       "    [-0.01441041  0.00916564  0.06147317]\n",
       "    [ 0.08268154  0.01616826  0.08289457]]\n",
       " \n",
       "   [[ 0.03203704  0.01688347 -0.03459275]\n",
       "    [ 0.00918504 -0.00689121 -0.04055142]\n",
       "    [-0.08139901  0.06464074  0.02731381]]\n",
       " \n",
       "   [[-0.0072248  -0.07411295 -0.05513853]\n",
       "    [-0.02443562  0.03619969 -0.01066486]\n",
       "    [-0.0525009  -0.04152107 -0.04262205]]]\n",
       " \n",
       " \n",
       "  ...\n",
       " \n",
       " \n",
       "  [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "    [-0.03333757  0.02255654  0.01452807]\n",
       "    [ 0.07274816  0.04599313 -0.00011758]]\n",
       " \n",
       "   [[ 0.07283399  0.05451591 -0.04420283]\n",
       "    [ 0.07164187  0.08015741  0.06468589]\n",
       "    [-0.03062155 -0.05015038  0.02159031]]\n",
       " \n",
       "   [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "    [-0.00470024  0.00760442 -0.00532582]\n",
       "    [-0.02140979  0.03761176  0.07121743]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "    [ 0.08175186 -0.01663043  0.01697671]\n",
       "    [-0.04998031 -0.00914244  0.02868303]]\n",
       " \n",
       "   [[-0.00251392 -0.02931277 -0.01294055]\n",
       "    [ 0.07991172 -0.0130088  -0.05366091]\n",
       "    [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       " \n",
       "   [[-0.004662   -0.04977087  0.04939119]\n",
       "    [-0.01845763 -0.06482323  0.02449331]\n",
       "    [-0.01165619  0.06523957  0.03770921]]]\n",
       " \n",
       " \n",
       "  [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "    [-0.05209206  0.03204753  0.02439884]\n",
       "    [-0.0282647   0.03098512  0.07474277]]\n",
       " \n",
       "   [[-0.05827966  0.00631046 -0.04896474]\n",
       "    [ 0.00211457  0.03935728  0.01188233]\n",
       "    [ 0.0395141  -0.0487875  -0.05219557]]\n",
       " \n",
       "   [[ 0.01199625  0.01175252 -0.08195679]\n",
       "    [-0.04492062 -0.07222724  0.08265557]\n",
       "    [ 0.00680294 -0.06261617 -0.04109164]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[-0.02842131  0.04017299 -0.06411938]\n",
       "    [-0.03479248 -0.00351638  0.04439355]\n",
       "    [-0.00836619 -0.00725466 -0.07700257]]\n",
       " \n",
       "   [[ 0.00681683  0.06109884 -0.03970103]\n",
       "    [-0.07532208  0.02519193  0.03664758]\n",
       "    [ 0.02089242  0.03030465 -0.04797888]]\n",
       " \n",
       "   [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "    [-0.00750206 -0.06763705  0.05190892]\n",
       "    [ 0.02197877  0.07384106  0.04836109]]]\n",
       " \n",
       " \n",
       "  [[[-0.03292805  0.05048368  0.05959893]\n",
       "    [-0.00935958  0.07049897  0.07671262]\n",
       "    [-0.0200305   0.02493731 -0.05899358]]\n",
       " \n",
       "   [[-0.06843758  0.01676033  0.07503303]\n",
       "    [-0.00159057  0.07050664 -0.06662065]\n",
       "    [-0.07063043 -0.00717596 -0.07401031]]\n",
       " \n",
       "   [[-0.05164689  0.01307825  0.0358992 ]\n",
       "    [ 0.07245863  0.0667781   0.00989082]\n",
       "    [ 0.02502123 -0.00115818  0.06598707]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "    [ 0.06617681  0.03855822  0.08260872]\n",
       "    [ 0.0201846   0.02270871  0.0820188 ]]\n",
       " \n",
       "   [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "    [ 0.05576969 -0.03805411 -0.05533451]\n",
       "    [ 0.08203562 -0.04242806 -0.03506017]]\n",
       " \n",
       "   [[ 0.03055421 -0.0600045   0.01011878]\n",
       "    [ 0.07702617  0.05981912  0.04538635]\n",
       "    [-0.0253101  -0.06463408 -0.07805812]]]]), LetNode(Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.conv2d), [Var(x_9, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), Var(x_10, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x32092d48), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_12, ty=TensorType([64], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_13, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_11, ty=TensorType([1, 64, 64, 64], float32)), Var(x_12, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31e4a3a8), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)]), LetNode(Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), CallNode(Op(nn.max_pool2d), [Var(x_13, ty=TensorType([1, 64, 64, 64], float32))], relay.attrs.MaxPool2DAttrs(0x32068458), [TensorType([1, 64, 64, 64], float32)]), LetNode(Var(x_15, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00667036  0.07674357  0.02048975]\n",
       "    [-0.0005337   0.06994274 -0.0409746 ]\n",
       "    [-0.01644263  0.02424868 -0.08242689]]\n",
       " \n",
       "   [[-0.0279611   0.02216059 -0.04442815]\n",
       "    [-0.00076614 -0.00510069  0.00525645]\n",
       "    [ 0.05821113  0.01974467  0.01869611]]\n",
       " \n",
       "   [[-0.01291529 -0.04766705 -0.04010829]\n",
       "    [-0.06574585 -0.06930234 -0.07820863]\n",
       "    [ 0.05632005 -0.01981469  0.03960329]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[-0.00203542 -0.01508743 -0.05518967]\n",
       "    [ 0.0098869  -0.02211016 -0.05686476]\n",
       "    [ 0.04343555  0.04212476 -0.04262485]]\n",
       " \n",
       "   [[ 0.04512688 -0.01977579 -0.03921237]\n",
       "    [ 0.05846582 -0.01097473 -0.08292767]\n",
       "    [ 0.02642258 -0.05865683  0.00781246]]\n",
       " \n",
       "   [[ 0.00868873  0.01789419 -0.05306506]\n",
       "    [ 0.03495514  0.00849197 -0.03360848]\n",
       "    [ 0.05213998 -0.05043467  0.02092493]]]\n",
       " \n",
       " \n",
       "  [[[-0.05225816 -0.03435542  0.06766681]\n",
       "    [-0.00570095 -0.07121497  0.04150715]\n",
       "    [ 0.03178158  0.0278095  -0.03169968]]\n",
       " \n",
       "   [[ 0.08237877  0.00820927  0.07866023]\n",
       "    [ 0.06363843  0.00969597 -0.07367277]\n",
       "    [-0.07699051 -0.07091855 -0.04057622]]\n",
       " \n",
       "   [[ 0.03507438  0.06507566 -0.07537719]\n",
       "    [-0.02447435 -0.06244735 -0.06095092]\n",
       "    [ 0.01566204  0.02181033  0.05003274]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[ 0.0431037   0.0482654   0.08321209]\n",
       "    [-0.05071964 -0.05884733 -0.0633956 ]\n",
       "    [ 0.06844861 -0.05180594 -0.0485846 ]]\n",
       " \n",
       "   [[-0.03323257  0.02323034  0.00272747]\n",
       "    [ 0.05667796 -0.0002616  -0.00519013]\n",
       "    [ 0.01162627  0.02526001  0.06600187]]\n",
       " \n",
       "   [[ 0.07655057  0.02485903 -0.05985588]\n",
       "    [ 0.04408409 -0.0380648  -0.00562543]\n",
       "    [-0.03243604 -0.03266114  0.02271339]]]\n",
       " \n",
       " \n",
       "  [[[ 0.02307111 -0.07447599  0.00114187]\n",
       "    [ 0.0209925  -0.03011368 -0.04503453]\n",
       "    [-0.01692474  0.06745539 -0.02362834]]\n",
       " \n",
       "   [[ 0.06450888 -0.01736359 -0.02165564]\n",
       "    [-0.0565699   0.01656731  0.02207325]\n",
       "    [-0.03282728 -0.07110369 -0.05474281]]\n",
       " \n",
       "   [[-0.00164378  0.07526512  0.07337628]\n",
       "    [ 0.01917853 -0.02339783  0.00305605]\n",
       "    [-0.05832756 -0.04507156 -0.02815646]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[-0.06093149 -0.06571921 -0.0378267 ]\n",
       "    [-0.05794454  0.02385507  0.04264715]\n",
       "    [ 0.0108671   0.05971035 -0.07129908]]\n",
       " \n",
       "   [[-0.08070076  0.06473055 -0.0824315 ]\n",
       "    [ 0.02900531 -0.03235545 -0.03446659]\n",
       "    [-0.0361414  -0.0720194  -0.06739503]]\n",
       " \n",
       "   [[ 0.06519654  0.05091707 -0.03405452]\n",
       "    [ 0.01338766  0.07065854 -0.01776394]\n",
       "    [ 0.03464925  0.03024761  0.03585237]]]\n",
       " \n",
       " \n",
       "  ...\n",
       " \n",
       " \n",
       "  [[[ 0.03777675 -0.03727138  0.01838966]\n",
       "    [-0.08274333 -0.064996    0.07656416]\n",
       "    [ 0.00311184  0.00922922  0.08024732]]\n",
       " \n",
       "   [[-0.04885089  0.00447249  0.076678  ]\n",
       "    [-0.06130725 -0.08112308  0.01622806]\n",
       "    [ 0.00925171  0.07307453  0.00239494]]\n",
       " \n",
       "   [[ 0.06266668 -0.07882553 -0.02372478]\n",
       "    [-0.00127685 -0.05542324  0.01506688]\n",
       "    [-0.04899919 -0.02099749 -0.04583566]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[-0.01963693 -0.01299276 -0.00876871]\n",
       "    [ 0.03455848  0.01813295 -0.01817822]\n",
       "    [ 0.00511507  0.01796635  0.03721446]]\n",
       " \n",
       "   [[ 0.02849569 -0.0781398   0.06691042]\n",
       "    [ 0.08145543 -0.06311989 -0.06119695]\n",
       "    [-0.08139144 -0.04604743 -0.03518212]]\n",
       " \n",
       "   [[-0.04671299  0.06773625 -0.05673073]\n",
       "    [-0.06609975  0.01549089  0.02074935]\n",
       "    [ 0.07406517 -0.04903018 -0.04878726]]]\n",
       " \n",
       " \n",
       "  [[[-0.02131156  0.06878123  0.02314601]\n",
       "    [ 0.07108916  0.04008206  0.02196169]\n",
       "    [-0.07365716 -0.03871602  0.04667952]]\n",
       " \n",
       "   [[ 0.02348771  0.02149502  0.02541289]\n",
       "    [-0.01793929  0.06772844  0.02993079]\n",
       "    [-0.07476664  0.01974591 -0.07887741]]\n",
       " \n",
       "   [[ 0.05220968  0.00943748  0.03035134]\n",
       "    [ 0.03464494 -0.02933544 -0.04283194]\n",
       "    [ 0.06609956  0.06831052 -0.05975342]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[ 0.00016204  0.0783995   0.07785139]\n",
       "    [ 0.03268198 -0.01940602  0.05926634]\n",
       "    [-0.05186518 -0.06860392  0.07977588]]\n",
       " \n",
       "   [[ 0.06457258  0.077715   -0.05051591]\n",
       "    [-0.07378592 -0.07513899 -0.02788895]\n",
       "    [-0.06781612 -0.02720525  0.08009199]]\n",
       " \n",
       "   [[-0.00609747 -0.00378752  0.06699146]\n",
       "    [-0.00971287 -0.05465307 -0.02018831]\n",
       "    [ 0.08092386 -0.01566859 -0.06308937]]]\n",
       " \n",
       " \n",
       "  [[[-0.01809273 -0.05052249  0.00830408]\n",
       "    [ 0.00651675  0.02668866 -0.02696224]\n",
       "    [ 0.06081321  0.03202073 -0.04717416]]\n",
       " \n",
       "   [[ 0.0587954   0.06785775  0.06052122]\n",
       "    [ 0.00263701 -0.01710707 -0.00749189]\n",
       "    [ 0.02028066 -0.00381591  0.05403914]]\n",
       " \n",
       "   [[-0.06002963  0.00170328  0.01363794]\n",
       "    [ 0.02595466  0.02344725 -0.03352585]\n",
       "    [ 0.06551506  0.0296605   0.06894781]]\n",
       " \n",
       "   ...\n",
       " \n",
       "   [[ 0.04791441  0.06846394  0.05488243]\n",
       "    [-0.04654666 -0.07713521  0.08156196]\n",
       "    [ 0.03400215  0.06116603 -0.02428303]]\n",
       " \n",
       "   [[ 0.06481076  0.04652277 -0.04640434]\n",
       "    [-0.02026961  0.07876632  0.04329368]\n",
       "    [-0.06511961 -0.05031322 -0.04249084]]\n",
       " \n",
       "   [[-0.05632734 -0.02485887 -0.06702858]\n",
       "    [-0.0249401  -0.0442156   0.00897348]\n",
       "    [ 0.06168193  0.00339633  0.07160915]]]]), LetNode(Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.conv2d_transpose), [Var(x_14, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), Var(x_15, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x32020528), [TensorType([1, 64, (int64)32, (int64)32], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_17, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_16, ty=TensorType([1, 32, 64, 64], float32)), Var(x_17, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31ddd148), [TensorType([1, 32, 64, 64], float32), TensorType([32], float32)]), LetNode(Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])), Tuple([Var(x_18, ty=TensorType([1, 32, 64, 64], float32)), Var(x_13, ty=TensorType([1, 64, 64, 64], float32))]), LetNode(Var(x_20, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x31e63a58), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Var(x_20, ty=TensorType([1, 96, 64, 64], float32))))))))))))))),\n",
       " LetNode(Var(x_20, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x31e63a58), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Var(x_20, ty=TensorType([1, 96, 64, 64], float32)))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = run_opt_pass(subgraph, transform.ToGraphNormalForm())\n",
    "submod = tvm.IRModule.from_expr(ann)['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = subgraphs[0]\n",
    "ann = run_opt_pass(out, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']\n",
    "outnew = run_opt_pass(out_1, transform.ToGraphNormalForm())\n",
    "outnew = tvm.IRModule.from_expr(outnew)['main']\n",
    "\n",
    "out1 = relay.Function(out.params, relay.Tuple([outnew, out]), out.ret_type, out.type_params, out.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Constant([[[[ 3.23163867e-02 -8.54633600e-02  5.41195720e-02]\n",
       "   [-1.10573828e-01  1.81553543e-01 -1.22144818e-04]\n",
       "   [ 2.55260766e-02  7.36784637e-02  1.07363641e-01]]\n",
       "\n",
       "  [[ 2.55233049e-02 -4.54409420e-02  1.67028517e-01]\n",
       "   [ 1.45357460e-01 -1.00949802e-01  7.94526637e-02]\n",
       "   [-1.49513945e-01  1.69569105e-02 -5.45993596e-02]]\n",
       "\n",
       "  [[-1.71270907e-01 -1.04798146e-01 -7.64890388e-02]\n",
       "   [-3.08729708e-03  8.45972598e-02 -3.27159166e-02]\n",
       "   [-1.12808652e-01 -7.80549943e-02  1.27093047e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.79601535e-01 -3.15128714e-02  3.91178727e-02]\n",
       "   [ 1.68302536e-01 -1.86983153e-01 -1.29431516e-01]\n",
       "   [ 7.07907379e-02 -5.24235666e-02 -2.14526057e-02]]\n",
       "\n",
       "  [[-1.49425566e-01  1.06974870e-01  1.21452183e-01]\n",
       "   [-3.09053659e-02  1.61907017e-01  1.01942331e-01]\n",
       "   [-1.82749078e-01 -1.50260255e-01 -9.02489349e-02]]\n",
       "\n",
       "  [[ 1.36263520e-02  5.32492995e-03  6.63298666e-02]\n",
       "   [-7.51340613e-02 -1.39353558e-01  7.36561418e-02]\n",
       "   [ 9.17883217e-02 -9.86345112e-03  1.52955800e-01]]]\n",
       "\n",
       "\n",
       " [[[ 2.13009864e-02  1.97265893e-02 -9.45521891e-03]\n",
       "   [ 2.66401619e-02  6.64318204e-02 -5.04366457e-02]\n",
       "   [-3.13195288e-02  8.30757916e-02 -1.36988997e-01]]\n",
       "\n",
       "  [[ 1.63736790e-01 -3.15981656e-02  7.50636458e-02]\n",
       "   [-1.42437190e-01 -1.23402961e-01  2.17434764e-02]\n",
       "   [ 9.64652300e-02 -8.68084654e-02 -9.02800262e-03]]\n",
       "\n",
       "  [[-1.01768948e-01  6.33873343e-02  7.77019560e-03]\n",
       "   [ 9.59634781e-02  1.81303084e-01  1.68824941e-01]\n",
       "   [-5.29856980e-02  4.81943637e-02 -7.51121342e-03]]]\n",
       "\n",
       "\n",
       " [[[ 1.85624272e-01  1.26410723e-02 -4.69885021e-02]\n",
       "   [ 1.31377161e-01  1.20458394e-01 -1.76296934e-01]\n",
       "   [ 1.14306152e-01  2.60501653e-02  1.43022805e-01]]\n",
       "\n",
       "  [[-8.49472657e-02  1.73936397e-01  1.66811049e-01]\n",
       "   [-8.02976787e-02 -8.55044872e-02 -5.39514422e-03]\n",
       "   [-8.56521353e-02  4.48296368e-02 -1.34362057e-01]]\n",
       "\n",
       "  [[-5.33646792e-02  1.81859225e-01 -9.99502242e-02]\n",
       "   [-5.50511777e-02 -3.37825716e-03 -9.55829322e-02]\n",
       "   [ 1.68427318e-01 -1.84786871e-01  1.06600076e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.75437063e-01  1.41930699e-01  1.37000918e-01]\n",
       "   [ 6.71393573e-02 -1.15836464e-01 -9.71407145e-02]\n",
       "   [ 1.50851011e-01 -3.45225483e-02  1.65536791e-01]]\n",
       "\n",
       "  [[-4.98251617e-02  1.47754252e-01 -1.81763440e-01]\n",
       "   [ 1.70889974e-01 -7.70533159e-02 -2.05524266e-03]\n",
       "   [-1.60784572e-02  1.16744578e-01 -4.57684845e-02]]\n",
       "\n",
       "  [[-7.69499764e-02  9.30011570e-02 -5.64735085e-02]\n",
       "   [-8.08795094e-02  1.17174089e-02 -5.56611419e-02]\n",
       "   [-5.66836745e-02  1.47822499e-02 -1.33246005e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.71122193e-01  3.56646329e-02 -7.18362629e-03]\n",
       "   [ 6.42065704e-03  1.79284960e-01  1.59637779e-01]\n",
       "   [-1.06569447e-01  5.86483926e-02  6.74238503e-02]]\n",
       "\n",
       "  [[ 1.18319780e-01  1.49352461e-01 -1.70189336e-01]\n",
       "   [ 4.89703715e-02  1.70334429e-01 -2.83747464e-02]\n",
       "   [-3.65189314e-02 -1.74321979e-01  4.83857393e-02]]\n",
       "\n",
       "  [[ 4.79186773e-02  1.62188262e-02 -1.42041743e-02]\n",
       "   [ 7.07059503e-02  2.94080526e-02  9.45008695e-02]\n",
       "   [-2.93372124e-02 -8.44715536e-02  1.11722261e-01]]]\n",
       "\n",
       "\n",
       " [[[ 6.59125447e-02  5.05997986e-02 -1.31376177e-01]\n",
       "   [-9.17568803e-03  1.57728881e-01 -6.72450662e-02]\n",
       "   [-3.25924158e-03 -3.25219631e-02  4.23832238e-02]]\n",
       "\n",
       "  [[-4.13824767e-02 -1.04881883e-01 -1.65507108e-01]\n",
       "   [-1.14712775e-01  1.10556185e-01  5.17856032e-02]\n",
       "   [-9.48744491e-02 -1.15556352e-01  9.75914598e-02]]\n",
       "\n",
       "  [[ 8.82167220e-02 -2.77179331e-02 -3.64471674e-02]\n",
       "   [ 2.04866976e-02 -6.29722327e-02  3.90434265e-03]\n",
       "   [ 2.56852508e-02 -1.07079864e-01 -8.07872415e-02]]]\n",
       "\n",
       "\n",
       " [[[ 8.50502849e-02  1.25303149e-01  7.59867430e-02]\n",
       "   [-1.54287726e-01  4.52778041e-02 -5.96313626e-02]\n",
       "   [ 5.43416589e-02 -1.00669265e-02 -1.40474871e-01]]\n",
       "\n",
       "  [[ 3.14332843e-02 -5.33489138e-02 -3.00983042e-02]\n",
       "   [ 1.26370758e-01  5.00690490e-02  1.12040311e-01]\n",
       "   [-5.11839390e-02 -1.82937905e-01 -1.06594406e-01]]\n",
       "\n",
       "  [[-1.42154887e-01  8.92073810e-02 -1.30964056e-01]\n",
       "   [ 1.28677249e-01  1.05378956e-01  4.53693122e-02]\n",
       "   [-1.27703100e-02  1.56475574e-01 -1.67467445e-02]]]\n",
       "\n",
       "\n",
       " [[[ 7.65839517e-02 -1.85384154e-01 -2.13601142e-02]\n",
       "   [-4.05054986e-02  1.53220505e-01  9.14503336e-02]\n",
       "   [-1.40803486e-01  4.95741814e-02  3.72883677e-02]]\n",
       "\n",
       "  [[ 1.58338219e-01 -1.36269480e-01 -4.22914475e-02]\n",
       "   [ 1.85696721e-01 -1.55060485e-01 -1.26205191e-01]\n",
       "   [-2.01228559e-02 -1.64159402e-01  1.78344548e-01]]\n",
       "\n",
       "  [[-1.76763535e-01  1.70058161e-02 -1.20139621e-01]\n",
       "   [ 2.70547420e-02 -1.33638024e-01  9.50823426e-02]\n",
       "   [ 2.79787928e-02 -1.27352461e-01  3.58471274e-03]]]\n",
       "\n",
       "\n",
       " [[[-9.39827263e-02  6.04519397e-02  1.08013481e-01]\n",
       "   [-1.16645962e-01 -1.65460393e-01 -6.18870556e-03]\n",
       "   [ 7.21707344e-02  8.47104788e-02 -2.81144679e-02]]\n",
       "\n",
       "  [[-1.20700903e-01  4.26964164e-02 -1.13219075e-01]\n",
       "   [ 5.60186058e-02  8.44514072e-02  5.24652749e-02]\n",
       "   [ 1.08808339e-01  8.52264762e-02 -9.50941294e-02]]\n",
       "\n",
       "  [[-1.44704074e-01  9.54670906e-02  1.66977674e-01]\n",
       "   [ 6.69571757e-03 -1.29601046e-01  7.80875385e-02]\n",
       "   [ 1.46477878e-01  4.82615829e-02  2.14048624e-02]]]\n",
       "\n",
       "\n",
       " [[[-5.59447259e-02 -1.32235035e-01 -9.86072123e-02]\n",
       "   [-1.27232820e-01  1.65347815e-01  1.15593970e-01]\n",
       "   [-1.39994696e-01 -9.94724035e-02  1.91435516e-02]]\n",
       "\n",
       "  [[ 9.60350335e-02  3.54774594e-02  4.69578207e-02]\n",
       "   [ 2.16355771e-02 -1.40012741e-01 -9.27861929e-02]\n",
       "   [ 1.38035059e-01  2.14290172e-02  2.97155827e-02]]\n",
       "\n",
       "  [[ 1.68305576e-01 -9.06663686e-02 -1.77400529e-01]\n",
       "   [ 1.37210518e-01 -1.66981682e-01 -1.75825059e-01]\n",
       "   [-1.13700926e-02 -1.71770379e-01 -1.80754349e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.17342532e-01 -1.25246122e-01  4.36568260e-02]\n",
       "   [-1.28248915e-01  1.09156132e-01  1.21462047e-01]\n",
       "   [ 1.39765799e-01  5.97490370e-02 -1.55793935e-01]]\n",
       "\n",
       "  [[ 1.29585981e-01 -1.67708784e-01 -1.40104204e-01]\n",
       "   [ 6.32902682e-02  1.34064347e-01  5.54828346e-03]\n",
       "   [-1.66599661e-01  8.09417665e-02  8.66871774e-02]]\n",
       "\n",
       "  [[ 1.37407273e-01  1.36265099e-01 -7.03882799e-02]\n",
       "   [-4.30146158e-02  1.12596929e-01  1.58761173e-01]\n",
       "   [-1.42925531e-02  9.43056047e-02  2.91520506e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.78751215e-01 -2.92624533e-03 -1.51681826e-01]\n",
       "   [-3.31627429e-02 -9.16357115e-02  1.09045208e-01]\n",
       "   [-6.47970811e-02  6.99364543e-02 -1.76437169e-01]]\n",
       "\n",
       "  [[ 5.80471456e-02 -4.29060906e-02  1.38128102e-02]\n",
       "   [-1.13552198e-01  9.72878337e-02 -6.52008951e-02]\n",
       "   [-3.40867937e-02 -1.28898978e-01  1.00027204e-01]]\n",
       "\n",
       "  [[-3.12890708e-02  1.11474395e-01 -4.54277247e-02]\n",
       "   [ 1.28747046e-01 -1.07698761e-01 -1.71826348e-01]\n",
       "   [ 4.67600226e-02  2.13909745e-02  3.19145769e-02]]]\n",
       "\n",
       "\n",
       " [[[ 6.09795153e-02  6.53798580e-02  1.58851147e-02]\n",
       "   [ 1.31815821e-01  9.09388959e-02 -1.17675558e-01]\n",
       "   [ 9.71961319e-02 -1.42025158e-01 -1.18488498e-01]]\n",
       "\n",
       "  [[-9.83842239e-02 -1.17170766e-01 -7.77797997e-02]\n",
       "   [-6.83522299e-02 -1.33498281e-01 -2.27994174e-02]\n",
       "   [-1.75565094e-01 -1.99733377e-02  1.10118210e-01]]\n",
       "\n",
       "  [[ 1.71729535e-01  3.86021286e-02 -4.06473279e-02]\n",
       "   [ 1.09524578e-01 -6.97095841e-02  1.28281116e-02]\n",
       "   [ 5.41785210e-02  2.32059956e-02 -1.25439763e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.80582225e-01  3.25351954e-04 -7.91747496e-02]\n",
       "   [ 1.14499122e-01  1.40993237e-01  1.48832351e-01]\n",
       "   [-5.41790575e-02 -1.05926991e-02 -1.46621108e-01]]\n",
       "\n",
       "  [[-2.73419023e-02 -1.11192904e-01  7.39906430e-02]\n",
       "   [-6.18950874e-02 -1.24993175e-02 -1.74652562e-01]\n",
       "   [-1.69832543e-01  1.49268806e-01 -2.92789787e-02]]\n",
       "\n",
       "  [[-4.84194010e-02  1.83304638e-01 -5.65462112e-02]\n",
       "   [ 6.40254021e-02  1.04462624e-01  1.26508564e-01]\n",
       "   [-1.16557315e-01 -1.24532729e-02 -1.73336715e-02]]]\n",
       "\n",
       "\n",
       " [[[ 4.83467877e-02 -1.24434516e-01  1.19152457e-01]\n",
       "   [ 1.22755438e-01 -1.31298661e-01  5.54364175e-02]\n",
       "   [-1.76441446e-01  5.25495410e-03 -4.09110039e-02]]\n",
       "\n",
       "  [[ 8.47310126e-02  1.60800517e-01  1.48474276e-01]\n",
       "   [ 6.86119199e-02  1.36019379e-01 -1.44075453e-01]\n",
       "   [ 5.23838252e-02 -1.54542968e-01  1.18324161e-01]]\n",
       "\n",
       "  [[-1.41257003e-01  1.13560587e-01 -8.10354948e-04]\n",
       "   [-1.70496285e-01 -3.00478041e-02 -1.24494001e-01]\n",
       "   [-2.46627033e-02  2.51647830e-02  1.82791203e-01]]]])], relay.attrs.Conv2DAttrs(0x31870ba8), [TensorType([1, 3, 256, 256], float32), TensorType([16, 3, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x64461d8), [TensorType([1, 16, 256, 256], float32), TensorType([16], float32)])], relay.attrs.MaxPool2DAttrs(0x677cfe8), [TensorType([1, 16, 256, 256], float32)]), Constant([[[[-0.05230885 -0.0552981   0.11728252]\n",
       "   [ 0.08455608  0.10542003  0.04579628]\n",
       "   [-0.09307583  0.05534854 -0.01750716]]\n",
       "\n",
       "  [[ 0.04393943 -0.06029916 -0.01250177]\n",
       "   [ 0.07909112  0.06802806  0.11071744]\n",
       "   [ 0.0185835   0.03467863 -0.0656544 ]]\n",
       "\n",
       "  [[-0.06746837 -0.06010815  0.09041516]\n",
       "   [ 0.09943489  0.11015844 -0.09712255]\n",
       "   [-0.08474152 -0.04466622 -0.00359616]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.11497544  0.06267113 -0.03177162]\n",
       "   [ 0.06944317  0.10755137  0.03901506]\n",
       "   [ 0.07950256  0.10187579 -0.11717492]]\n",
       "\n",
       "  [[-0.08834244  0.10430969  0.11274465]\n",
       "   [ 0.00843327  0.02345195  0.02834205]\n",
       "   [-0.01871318  0.02506819  0.07203812]]\n",
       "\n",
       "  [[ 0.03502864  0.07529881  0.09674402]\n",
       "   [ 0.07443257 -0.07731336 -0.00925865]\n",
       "   [ 0.03505863 -0.06346579  0.10876042]]]\n",
       "\n",
       "\n",
       " [[[ 0.09483296 -0.08411033  0.02065786]\n",
       "   [-0.04375537 -0.04547243  0.01218746]\n",
       "   [-0.01966642 -0.04684217 -0.01652437]]\n",
       "\n",
       "  [[-0.02192305 -0.10731293 -0.00440802]\n",
       "   [ 0.10163368  0.07662707  0.0321778 ]\n",
       "   [-0.01564635  0.08551753  0.02628522]]\n",
       "\n",
       "  [[ 0.10481966 -0.0304717  -0.08486979]\n",
       "   [-0.02855957  0.01816257 -0.10232589]\n",
       "   [ 0.11503667  0.09423494  0.1027649 ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.01420354  0.06906321 -0.02200597]\n",
       "   [-0.11723958  0.11678685 -0.01455109]\n",
       "   [ 0.03668139 -0.00778399 -0.11751148]]\n",
       "\n",
       "  [[ 0.00466588 -0.07041381 -0.04968228]\n",
       "   [ 0.04027871  0.10334843  0.11501909]\n",
       "   [-0.05539501 -0.04927304  0.01133548]]\n",
       "\n",
       "  [[ 0.10833482 -0.10027345  0.06273947]\n",
       "   [ 0.06040571  0.05947142 -0.07104565]\n",
       "   [-0.11337631  0.01624221 -0.08089186]]]\n",
       "\n",
       "\n",
       " [[[-0.07835841 -0.03311843  0.09948593]\n",
       "   [-0.05609833  0.09349469 -0.06139599]\n",
       "   [-0.06181434 -0.08554602 -0.1053581 ]]\n",
       "\n",
       "  [[ 0.08503192  0.05499079  0.05056188]\n",
       "   [-0.04506305 -0.10509247  0.06253643]\n",
       "   [ 0.01259098 -0.09399475 -0.00249332]]\n",
       "\n",
       "  [[ 0.01039549  0.11259469  0.11580513]\n",
       "   [ 0.06672735 -0.00530761 -0.09737875]\n",
       "   [-0.02119978 -0.10293067  0.11692385]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.07186478 -0.03072449 -0.0870213 ]\n",
       "   [-0.04209402  0.09946404  0.02351499]\n",
       "   [-0.07072626  0.04365916  0.05129435]]\n",
       "\n",
       "  [[ 0.00765935 -0.01586042 -0.01249991]\n",
       "   [-0.00079244 -0.01467744  0.10067401]\n",
       "   [-0.04039896 -0.02005445 -0.00711605]]\n",
       "\n",
       "  [[-0.10328984 -0.0535966  -0.03392352]\n",
       "   [ 0.02976998  0.07230691  0.06908812]\n",
       "   [-0.04546015 -0.05153897 -0.06480247]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.0070868   0.00938178 -0.00544529]\n",
       "   [-0.09389155  0.01959044  0.04377877]\n",
       "   [-0.06762378 -0.0329773   0.06007441]]\n",
       "\n",
       "  [[ 0.02986882 -0.11019504 -0.11619313]\n",
       "   [ 0.09995156  0.10913319 -0.10641829]\n",
       "   [-0.06335922  0.00646426  0.10509921]]\n",
       "\n",
       "  [[ 0.08675022  0.08664448 -0.1098199 ]\n",
       "   [ 0.00331356 -0.00187818 -0.07079825]\n",
       "   [ 0.0577076   0.02413637 -0.01189044]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.04778593  0.08398881  0.03136829]\n",
       "   [-0.07407292  0.05938094 -0.02747986]\n",
       "   [ 0.06026339 -0.08766058 -0.11293681]]\n",
       "\n",
       "  [[ 0.04645235 -0.09875906 -0.08499317]\n",
       "   [-0.04851406  0.034994    0.04832434]\n",
       "   [-0.04298678 -0.09601339 -0.10151485]]\n",
       "\n",
       "  [[ 0.07464734 -0.03293914 -0.06233732]\n",
       "   [ 0.02458305  0.10398766  0.04098863]\n",
       "   [ 0.02308751  0.06816975 -0.11231747]]]\n",
       "\n",
       "\n",
       " [[[-0.02933128 -0.06860529 -0.10139706]\n",
       "   [ 0.02435719 -0.10953418  0.01431978]\n",
       "   [ 0.04437434  0.01846709  0.03312323]]\n",
       "\n",
       "  [[ 0.05368101 -0.08317094 -0.08957916]\n",
       "   [ 0.03789932  0.09433054  0.0816843 ]\n",
       "   [-0.02192013  0.11146647 -0.03398576]]\n",
       "\n",
       "  [[-0.00226191  0.10830023 -0.11369399]\n",
       "   [-0.03664935  0.05322992 -0.01288033]\n",
       "   [ 0.08504245 -0.10482323 -0.01505179]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.05494811  0.02482646 -0.10490188]\n",
       "   [ 0.01156456 -0.08555114 -0.06266444]\n",
       "   [ 0.10471573  0.05411824 -0.10698368]]\n",
       "\n",
       "  [[ 0.11158954  0.0869856   0.07516759]\n",
       "   [ 0.11528201 -0.09075028  0.08242213]\n",
       "   [-0.05142607 -0.00498561 -0.04510528]]\n",
       "\n",
       "  [[-0.02594128  0.04859742  0.08633048]\n",
       "   [-0.08991379  0.01653565 -0.01028105]\n",
       "   [ 0.10650278  0.04709851  0.04210464]]]\n",
       "\n",
       "\n",
       " [[[-0.00932021 -0.11301627  0.04408962]\n",
       "   [-0.01989694  0.06719355 -0.0565851 ]\n",
       "   [ 0.06009115 -0.00729082 -0.02609874]]\n",
       "\n",
       "  [[ 0.01176082  0.11522078 -0.00057384]\n",
       "   [-0.0349285   0.05100989  0.05695517]\n",
       "   [-0.0210886  -0.10224926 -0.03217258]]\n",
       "\n",
       "  [[ 0.07885333 -0.04289071 -0.11050623]\n",
       "   [ 0.0116862   0.1011362   0.01308129]\n",
       "   [ 0.09525668 -0.00123814  0.00275118]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00897247  0.10901894  0.03509771]\n",
       "   [-0.11319994  0.03147358 -0.03104576]\n",
       "   [-0.02268737  0.05590992  0.11742789]]\n",
       "\n",
       "  [[-0.09170699  0.09731416  0.1078024 ]\n",
       "   [ 0.03355918  0.01081809 -0.05249008]\n",
       "   [-0.00724667  0.01866774  0.02748851]]\n",
       "\n",
       "  [[-0.00050731 -0.06097165 -0.05974628]\n",
       "   [-0.11410346 -0.04882569  0.01884864]\n",
       "   [ 0.01119485  0.04000121 -0.07791477]]]])], relay.attrs.Conv2DAttrs(0x3186f8c8), [TensorType([1, 16, (int64)128, (int64)128], float32), TensorType([32, 16, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x3186aba8), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)])], relay.attrs.MaxPool2DAttrs(0x318c09c8), [TensorType([1, 32, 128, 128], float32)]), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "   [-0.03190579 -0.01584832  0.02670189]\n",
       "   [ 0.01921258 -0.07818282  0.03479443]]\n",
       "\n",
       "  [[-0.00130421 -0.01830789  0.05642799]\n",
       "   [-0.0170652  -0.02210277  0.04254849]\n",
       "   [ 0.01875039 -0.08010064 -0.08040661]]\n",
       "\n",
       "  [[ 0.02165145  0.0240651  -0.04487719]\n",
       "   [-0.02167934 -0.00768209  0.0794398 ]\n",
       "   [-0.02068903  0.06871933  0.07726983]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.03205558  0.00290275 -0.02926568]\n",
       "   [ 0.04182967  0.04922665 -0.06711974]\n",
       "   [-0.02741003  0.05309341  0.01915387]]\n",
       "\n",
       "  [[-0.04150633  0.08178725  0.03009626]\n",
       "   [ 0.05355413  0.03888881 -0.05639726]\n",
       "   [ 0.04942527 -0.00437707  0.00632731]]\n",
       "\n",
       "  [[-0.02561722  0.05984905 -0.05160853]\n",
       "   [-0.07984905 -0.05768615  0.07380161]\n",
       "   [-0.07858952 -0.07737446  0.01850816]]]\n",
       "\n",
       "\n",
       " [[[-0.03143118  0.0695676  -0.04244177]\n",
       "   [ 0.04627309 -0.03359256 -0.06305707]\n",
       "   [ 0.01931474  0.06957508 -0.04066815]]\n",
       "\n",
       "  [[-0.05282148  0.07525725 -0.06407903]\n",
       "   [ 0.05680341  0.03004328 -0.07779044]\n",
       "   [-0.04317856 -0.04223323  0.04984415]]\n",
       "\n",
       "  [[-0.05401897 -0.03738686 -0.04842353]\n",
       "   [ 0.02915064 -0.01600464  0.07291468]\n",
       "   [-0.03190204 -0.0579984   0.04465697]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "   [ 0.00072628 -0.05233977 -0.03741848]\n",
       "   [ 0.07280735 -0.03233246  0.01515931]]\n",
       "\n",
       "  [[-0.05387771 -0.07664208  0.03958815]\n",
       "   [-0.06479758 -0.02311367 -0.05349527]\n",
       "   [-0.03774371 -0.00293905 -0.01947474]]\n",
       "\n",
       "  [[-0.06706224 -0.0475895  -0.03024844]\n",
       "   [-0.06104823 -0.05882414  0.03911529]\n",
       "   [-0.03023565  0.0054945   0.03267833]]]\n",
       "\n",
       "\n",
       " [[[-0.05496893  0.04519042 -0.04979972]\n",
       "   [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "   [ 0.06344249  0.04820261 -0.01685154]]\n",
       "\n",
       "  [[-0.07507978 -0.0369214   0.01589892]\n",
       "   [ 0.07496265 -0.03811238  0.07452969]\n",
       "   [-0.05802975  0.06737594 -0.02538034]]\n",
       "\n",
       "  [[-0.06388503 -0.06834688 -0.02203981]\n",
       "   [ 0.00349629 -0.03683617 -0.07054752]\n",
       "   [ 0.00112883 -0.06129277 -0.03130053]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.03836095  0.0297214   0.07942633]\n",
       "   [-0.01441041  0.00916564  0.06147317]\n",
       "   [ 0.08268154  0.01616826  0.08289457]]\n",
       "\n",
       "  [[ 0.03203704  0.01688347 -0.03459275]\n",
       "   [ 0.00918504 -0.00689121 -0.04055142]\n",
       "   [-0.08139901  0.06464074  0.02731381]]\n",
       "\n",
       "  [[-0.0072248  -0.07411295 -0.05513853]\n",
       "   [-0.02443562  0.03619969 -0.01066486]\n",
       "   [-0.0525009  -0.04152107 -0.04262205]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "   [-0.03333757  0.02255654  0.01452807]\n",
       "   [ 0.07274816  0.04599313 -0.00011758]]\n",
       "\n",
       "  [[ 0.07283399  0.05451591 -0.04420283]\n",
       "   [ 0.07164187  0.08015741  0.06468589]\n",
       "   [-0.03062155 -0.05015038  0.02159031]]\n",
       "\n",
       "  [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "   [-0.00470024  0.00760442 -0.00532582]\n",
       "   [-0.02140979  0.03761176  0.07121743]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "   [ 0.08175186 -0.01663043  0.01697671]\n",
       "   [-0.04998031 -0.00914244  0.02868303]]\n",
       "\n",
       "  [[-0.00251392 -0.02931277 -0.01294055]\n",
       "   [ 0.07991172 -0.0130088  -0.05366091]\n",
       "   [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       "\n",
       "  [[-0.004662   -0.04977087  0.04939119]\n",
       "   [-0.01845763 -0.06482323  0.02449331]\n",
       "   [-0.01165619  0.06523957  0.03770921]]]\n",
       "\n",
       "\n",
       " [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "   [-0.05209206  0.03204753  0.02439884]\n",
       "   [-0.0282647   0.03098512  0.07474277]]\n",
       "\n",
       "  [[-0.05827966  0.00631046 -0.04896474]\n",
       "   [ 0.00211457  0.03935728  0.01188233]\n",
       "   [ 0.0395141  -0.0487875  -0.05219557]]\n",
       "\n",
       "  [[ 0.01199625  0.01175252 -0.08195679]\n",
       "   [-0.04492062 -0.07222724  0.08265557]\n",
       "   [ 0.00680294 -0.06261617 -0.04109164]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.02842131  0.04017299 -0.06411938]\n",
       "   [-0.03479248 -0.00351638  0.04439355]\n",
       "   [-0.00836619 -0.00725466 -0.07700257]]\n",
       "\n",
       "  [[ 0.00681683  0.06109884 -0.03970103]\n",
       "   [-0.07532208  0.02519193  0.03664758]\n",
       "   [ 0.02089242  0.03030465 -0.04797888]]\n",
       "\n",
       "  [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "   [-0.00750206 -0.06763705  0.05190892]\n",
       "   [ 0.02197877  0.07384106  0.04836109]]]\n",
       "\n",
       "\n",
       " [[[-0.03292805  0.05048368  0.05959893]\n",
       "   [-0.00935958  0.07049897  0.07671262]\n",
       "   [-0.0200305   0.02493731 -0.05899358]]\n",
       "\n",
       "  [[-0.06843758  0.01676033  0.07503303]\n",
       "   [-0.00159057  0.07050664 -0.06662065]\n",
       "   [-0.07063043 -0.00717596 -0.07401031]]\n",
       "\n",
       "  [[-0.05164689  0.01307825  0.0358992 ]\n",
       "   [ 0.07245863  0.0667781   0.00989082]\n",
       "   [ 0.02502123 -0.00115818  0.06598707]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "   [ 0.06617681  0.03855822  0.08260872]\n",
       "   [ 0.0201846   0.02270871  0.0820188 ]]\n",
       "\n",
       "  [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "   [ 0.05576969 -0.03805411 -0.05533451]\n",
       "   [ 0.08203562 -0.04242806 -0.03506017]]\n",
       "\n",
       "  [[ 0.03055421 -0.0600045   0.01011878]\n",
       "   [ 0.07702617  0.05981912  0.04538635]\n",
       "   [-0.0253101  -0.06463408 -0.07805812]]]])], relay.attrs.Conv2DAttrs(0x318b5958), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x1e9ea08), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)])], relay.attrs.MaxPool2DAttrs(0x318c0d48), [TensorType([1, 64, 64, 64], float32)]), Constant([[[[-0.00667036  0.07674357  0.02048975]\n",
       "   [-0.0005337   0.06994274 -0.0409746 ]\n",
       "   [-0.01644263  0.02424868 -0.08242689]]\n",
       "\n",
       "  [[-0.0279611   0.02216059 -0.04442815]\n",
       "   [-0.00076614 -0.00510069  0.00525645]\n",
       "   [ 0.05821113  0.01974467  0.01869611]]\n",
       "\n",
       "  [[-0.01291529 -0.04766705 -0.04010829]\n",
       "   [-0.06574585 -0.06930234 -0.07820863]\n",
       "   [ 0.05632005 -0.01981469  0.03960329]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00203542 -0.01508743 -0.05518967]\n",
       "   [ 0.0098869  -0.02211016 -0.05686476]\n",
       "   [ 0.04343555  0.04212476 -0.04262485]]\n",
       "\n",
       "  [[ 0.04512688 -0.01977579 -0.03921237]\n",
       "   [ 0.05846582 -0.01097473 -0.08292767]\n",
       "   [ 0.02642258 -0.05865683  0.00781246]]\n",
       "\n",
       "  [[ 0.00868873  0.01789419 -0.05306506]\n",
       "   [ 0.03495514  0.00849197 -0.03360848]\n",
       "   [ 0.05213998 -0.05043467  0.02092493]]]\n",
       "\n",
       "\n",
       " [[[-0.05225816 -0.03435542  0.06766681]\n",
       "   [-0.00570095 -0.07121497  0.04150715]\n",
       "   [ 0.03178158  0.0278095  -0.03169968]]\n",
       "\n",
       "  [[ 0.08237877  0.00820927  0.07866023]\n",
       "   [ 0.06363843  0.00969597 -0.07367277]\n",
       "   [-0.07699051 -0.07091855 -0.04057622]]\n",
       "\n",
       "  [[ 0.03507438  0.06507566 -0.07537719]\n",
       "   [-0.02447435 -0.06244735 -0.06095092]\n",
       "   [ 0.01566204  0.02181033  0.05003274]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.0431037   0.0482654   0.08321209]\n",
       "   [-0.05071964 -0.05884733 -0.0633956 ]\n",
       "   [ 0.06844861 -0.05180594 -0.0485846 ]]\n",
       "\n",
       "  [[-0.03323257  0.02323034  0.00272747]\n",
       "   [ 0.05667796 -0.0002616  -0.00519013]\n",
       "   [ 0.01162627  0.02526001  0.06600187]]\n",
       "\n",
       "  [[ 0.07655057  0.02485903 -0.05985588]\n",
       "   [ 0.04408409 -0.0380648  -0.00562543]\n",
       "   [-0.03243604 -0.03266114  0.02271339]]]\n",
       "\n",
       "\n",
       " [[[ 0.02307111 -0.07447599  0.00114187]\n",
       "   [ 0.0209925  -0.03011368 -0.04503453]\n",
       "   [-0.01692474  0.06745539 -0.02362834]]\n",
       "\n",
       "  [[ 0.06450888 -0.01736359 -0.02165564]\n",
       "   [-0.0565699   0.01656731  0.02207325]\n",
       "   [-0.03282728 -0.07110369 -0.05474281]]\n",
       "\n",
       "  [[-0.00164378  0.07526512  0.07337628]\n",
       "   [ 0.01917853 -0.02339783  0.00305605]\n",
       "   [-0.05832756 -0.04507156 -0.02815646]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.06093149 -0.06571921 -0.0378267 ]\n",
       "   [-0.05794454  0.02385507  0.04264715]\n",
       "   [ 0.0108671   0.05971035 -0.07129908]]\n",
       "\n",
       "  [[-0.08070076  0.06473055 -0.0824315 ]\n",
       "   [ 0.02900531 -0.03235545 -0.03446659]\n",
       "   [-0.0361414  -0.0720194  -0.06739503]]\n",
       "\n",
       "  [[ 0.06519654  0.05091707 -0.03405452]\n",
       "   [ 0.01338766  0.07065854 -0.01776394]\n",
       "   [ 0.03464925  0.03024761  0.03585237]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.03777675 -0.03727138  0.01838966]\n",
       "   [-0.08274333 -0.064996    0.07656416]\n",
       "   [ 0.00311184  0.00922922  0.08024732]]\n",
       "\n",
       "  [[-0.04885089  0.00447249  0.076678  ]\n",
       "   [-0.06130725 -0.08112308  0.01622806]\n",
       "   [ 0.00925171  0.07307453  0.00239494]]\n",
       "\n",
       "  [[ 0.06266668 -0.07882553 -0.02372478]\n",
       "   [-0.00127685 -0.05542324  0.01506688]\n",
       "   [-0.04899919 -0.02099749 -0.04583566]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.01963693 -0.01299276 -0.00876871]\n",
       "   [ 0.03455848  0.01813295 -0.01817822]\n",
       "   [ 0.00511507  0.01796635  0.03721446]]\n",
       "\n",
       "  [[ 0.02849569 -0.0781398   0.06691042]\n",
       "   [ 0.08145543 -0.06311989 -0.06119695]\n",
       "   [-0.08139144 -0.04604743 -0.03518212]]\n",
       "\n",
       "  [[-0.04671299  0.06773625 -0.05673073]\n",
       "   [-0.06609975  0.01549089  0.02074935]\n",
       "   [ 0.07406517 -0.04903018 -0.04878726]]]\n",
       "\n",
       "\n",
       " [[[-0.02131156  0.06878123  0.02314601]\n",
       "   [ 0.07108916  0.04008206  0.02196169]\n",
       "   [-0.07365716 -0.03871602  0.04667952]]\n",
       "\n",
       "  [[ 0.02348771  0.02149502  0.02541289]\n",
       "   [-0.01793929  0.06772844  0.02993079]\n",
       "   [-0.07476664  0.01974591 -0.07887741]]\n",
       "\n",
       "  [[ 0.05220968  0.00943748  0.03035134]\n",
       "   [ 0.03464494 -0.02933544 -0.04283194]\n",
       "   [ 0.06609956  0.06831052 -0.05975342]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00016204  0.0783995   0.07785139]\n",
       "   [ 0.03268198 -0.01940602  0.05926634]\n",
       "   [-0.05186518 -0.06860392  0.07977588]]\n",
       "\n",
       "  [[ 0.06457258  0.077715   -0.05051591]\n",
       "   [-0.07378592 -0.07513899 -0.02788895]\n",
       "   [-0.06781612 -0.02720525  0.08009199]]\n",
       "\n",
       "  [[-0.00609747 -0.00378752  0.06699146]\n",
       "   [-0.00971287 -0.05465307 -0.02018831]\n",
       "   [ 0.08092386 -0.01566859 -0.06308937]]]\n",
       "\n",
       "\n",
       " [[[-0.01809273 -0.05052249  0.00830408]\n",
       "   [ 0.00651675  0.02668866 -0.02696224]\n",
       "   [ 0.06081321  0.03202073 -0.04717416]]\n",
       "\n",
       "  [[ 0.0587954   0.06785775  0.06052122]\n",
       "   [ 0.00263701 -0.01710707 -0.00749189]\n",
       "   [ 0.02028066 -0.00381591  0.05403914]]\n",
       "\n",
       "  [[-0.06002963  0.00170328  0.01363794]\n",
       "   [ 0.02595466  0.02344725 -0.03352585]\n",
       "   [ 0.06551506  0.0296605   0.06894781]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.04791441  0.06846394  0.05488243]\n",
       "   [-0.04654666 -0.07713521  0.08156196]\n",
       "   [ 0.03400215  0.06116603 -0.02428303]]\n",
       "\n",
       "  [[ 0.06481076  0.04652277 -0.04640434]\n",
       "   [-0.02026961  0.07876632  0.04329368]\n",
       "   [-0.06511961 -0.05031322 -0.04249084]]\n",
       "\n",
       "  [[-0.05632734 -0.02485887 -0.06702858]\n",
       "   [-0.0249401  -0.0442156   0.00897348]\n",
       "   [ 0.06168193  0.00339633  0.07160915]]]])], relay.attrs.Conv2DTransposeAttrs(0x4209048), [TensorType([1, 64, (int64)32, (int64)32], float32), TensorType([64, 32, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x677e588), [TensorType([1, 32, 64, 64], float32), TensorType([32], float32)]), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Constant([[[[ 3.23163867e-02 -8.54633600e-02  5.41195720e-02]\n",
       "   [-1.10573828e-01  1.81553543e-01 -1.22144818e-04]\n",
       "   [ 2.55260766e-02  7.36784637e-02  1.07363641e-01]]\n",
       "\n",
       "  [[ 2.55233049e-02 -4.54409420e-02  1.67028517e-01]\n",
       "   [ 1.45357460e-01 -1.00949802e-01  7.94526637e-02]\n",
       "   [-1.49513945e-01  1.69569105e-02 -5.45993596e-02]]\n",
       "\n",
       "  [[-1.71270907e-01 -1.04798146e-01 -7.64890388e-02]\n",
       "   [-3.08729708e-03  8.45972598e-02 -3.27159166e-02]\n",
       "   [-1.12808652e-01 -7.80549943e-02  1.27093047e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.79601535e-01 -3.15128714e-02  3.91178727e-02]\n",
       "   [ 1.68302536e-01 -1.86983153e-01 -1.29431516e-01]\n",
       "   [ 7.07907379e-02 -5.24235666e-02 -2.14526057e-02]]\n",
       "\n",
       "  [[-1.49425566e-01  1.06974870e-01  1.21452183e-01]\n",
       "   [-3.09053659e-02  1.61907017e-01  1.01942331e-01]\n",
       "   [-1.82749078e-01 -1.50260255e-01 -9.02489349e-02]]\n",
       "\n",
       "  [[ 1.36263520e-02  5.32492995e-03  6.63298666e-02]\n",
       "   [-7.51340613e-02 -1.39353558e-01  7.36561418e-02]\n",
       "   [ 9.17883217e-02 -9.86345112e-03  1.52955800e-01]]]\n",
       "\n",
       "\n",
       " [[[ 2.13009864e-02  1.97265893e-02 -9.45521891e-03]\n",
       "   [ 2.66401619e-02  6.64318204e-02 -5.04366457e-02]\n",
       "   [-3.13195288e-02  8.30757916e-02 -1.36988997e-01]]\n",
       "\n",
       "  [[ 1.63736790e-01 -3.15981656e-02  7.50636458e-02]\n",
       "   [-1.42437190e-01 -1.23402961e-01  2.17434764e-02]\n",
       "   [ 9.64652300e-02 -8.68084654e-02 -9.02800262e-03]]\n",
       "\n",
       "  [[-1.01768948e-01  6.33873343e-02  7.77019560e-03]\n",
       "   [ 9.59634781e-02  1.81303084e-01  1.68824941e-01]\n",
       "   [-5.29856980e-02  4.81943637e-02 -7.51121342e-03]]]\n",
       "\n",
       "\n",
       " [[[ 1.85624272e-01  1.26410723e-02 -4.69885021e-02]\n",
       "   [ 1.31377161e-01  1.20458394e-01 -1.76296934e-01]\n",
       "   [ 1.14306152e-01  2.60501653e-02  1.43022805e-01]]\n",
       "\n",
       "  [[-8.49472657e-02  1.73936397e-01  1.66811049e-01]\n",
       "   [-8.02976787e-02 -8.55044872e-02 -5.39514422e-03]\n",
       "   [-8.56521353e-02  4.48296368e-02 -1.34362057e-01]]\n",
       "\n",
       "  [[-5.33646792e-02  1.81859225e-01 -9.99502242e-02]\n",
       "   [-5.50511777e-02 -3.37825716e-03 -9.55829322e-02]\n",
       "   [ 1.68427318e-01 -1.84786871e-01  1.06600076e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.75437063e-01  1.41930699e-01  1.37000918e-01]\n",
       "   [ 6.71393573e-02 -1.15836464e-01 -9.71407145e-02]\n",
       "   [ 1.50851011e-01 -3.45225483e-02  1.65536791e-01]]\n",
       "\n",
       "  [[-4.98251617e-02  1.47754252e-01 -1.81763440e-01]\n",
       "   [ 1.70889974e-01 -7.70533159e-02 -2.05524266e-03]\n",
       "   [-1.60784572e-02  1.16744578e-01 -4.57684845e-02]]\n",
       "\n",
       "  [[-7.69499764e-02  9.30011570e-02 -5.64735085e-02]\n",
       "   [-8.08795094e-02  1.17174089e-02 -5.56611419e-02]\n",
       "   [-5.66836745e-02  1.47822499e-02 -1.33246005e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.71122193e-01  3.56646329e-02 -7.18362629e-03]\n",
       "   [ 6.42065704e-03  1.79284960e-01  1.59637779e-01]\n",
       "   [-1.06569447e-01  5.86483926e-02  6.74238503e-02]]\n",
       "\n",
       "  [[ 1.18319780e-01  1.49352461e-01 -1.70189336e-01]\n",
       "   [ 4.89703715e-02  1.70334429e-01 -2.83747464e-02]\n",
       "   [-3.65189314e-02 -1.74321979e-01  4.83857393e-02]]\n",
       "\n",
       "  [[ 4.79186773e-02  1.62188262e-02 -1.42041743e-02]\n",
       "   [ 7.07059503e-02  2.94080526e-02  9.45008695e-02]\n",
       "   [-2.93372124e-02 -8.44715536e-02  1.11722261e-01]]]\n",
       "\n",
       "\n",
       " [[[ 6.59125447e-02  5.05997986e-02 -1.31376177e-01]\n",
       "   [-9.17568803e-03  1.57728881e-01 -6.72450662e-02]\n",
       "   [-3.25924158e-03 -3.25219631e-02  4.23832238e-02]]\n",
       "\n",
       "  [[-4.13824767e-02 -1.04881883e-01 -1.65507108e-01]\n",
       "   [-1.14712775e-01  1.10556185e-01  5.17856032e-02]\n",
       "   [-9.48744491e-02 -1.15556352e-01  9.75914598e-02]]\n",
       "\n",
       "  [[ 8.82167220e-02 -2.77179331e-02 -3.64471674e-02]\n",
       "   [ 2.04866976e-02 -6.29722327e-02  3.90434265e-03]\n",
       "   [ 2.56852508e-02 -1.07079864e-01 -8.07872415e-02]]]\n",
       "\n",
       "\n",
       " [[[ 8.50502849e-02  1.25303149e-01  7.59867430e-02]\n",
       "   [-1.54287726e-01  4.52778041e-02 -5.96313626e-02]\n",
       "   [ 5.43416589e-02 -1.00669265e-02 -1.40474871e-01]]\n",
       "\n",
       "  [[ 3.14332843e-02 -5.33489138e-02 -3.00983042e-02]\n",
       "   [ 1.26370758e-01  5.00690490e-02  1.12040311e-01]\n",
       "   [-5.11839390e-02 -1.82937905e-01 -1.06594406e-01]]\n",
       "\n",
       "  [[-1.42154887e-01  8.92073810e-02 -1.30964056e-01]\n",
       "   [ 1.28677249e-01  1.05378956e-01  4.53693122e-02]\n",
       "   [-1.27703100e-02  1.56475574e-01 -1.67467445e-02]]]\n",
       "\n",
       "\n",
       " [[[ 7.65839517e-02 -1.85384154e-01 -2.13601142e-02]\n",
       "   [-4.05054986e-02  1.53220505e-01  9.14503336e-02]\n",
       "   [-1.40803486e-01  4.95741814e-02  3.72883677e-02]]\n",
       "\n",
       "  [[ 1.58338219e-01 -1.36269480e-01 -4.22914475e-02]\n",
       "   [ 1.85696721e-01 -1.55060485e-01 -1.26205191e-01]\n",
       "   [-2.01228559e-02 -1.64159402e-01  1.78344548e-01]]\n",
       "\n",
       "  [[-1.76763535e-01  1.70058161e-02 -1.20139621e-01]\n",
       "   [ 2.70547420e-02 -1.33638024e-01  9.50823426e-02]\n",
       "   [ 2.79787928e-02 -1.27352461e-01  3.58471274e-03]]]\n",
       "\n",
       "\n",
       " [[[-9.39827263e-02  6.04519397e-02  1.08013481e-01]\n",
       "   [-1.16645962e-01 -1.65460393e-01 -6.18870556e-03]\n",
       "   [ 7.21707344e-02  8.47104788e-02 -2.81144679e-02]]\n",
       "\n",
       "  [[-1.20700903e-01  4.26964164e-02 -1.13219075e-01]\n",
       "   [ 5.60186058e-02  8.44514072e-02  5.24652749e-02]\n",
       "   [ 1.08808339e-01  8.52264762e-02 -9.50941294e-02]]\n",
       "\n",
       "  [[-1.44704074e-01  9.54670906e-02  1.66977674e-01]\n",
       "   [ 6.69571757e-03 -1.29601046e-01  7.80875385e-02]\n",
       "   [ 1.46477878e-01  4.82615829e-02  2.14048624e-02]]]\n",
       "\n",
       "\n",
       " [[[-5.59447259e-02 -1.32235035e-01 -9.86072123e-02]\n",
       "   [-1.27232820e-01  1.65347815e-01  1.15593970e-01]\n",
       "   [-1.39994696e-01 -9.94724035e-02  1.91435516e-02]]\n",
       "\n",
       "  [[ 9.60350335e-02  3.54774594e-02  4.69578207e-02]\n",
       "   [ 2.16355771e-02 -1.40012741e-01 -9.27861929e-02]\n",
       "   [ 1.38035059e-01  2.14290172e-02  2.97155827e-02]]\n",
       "\n",
       "  [[ 1.68305576e-01 -9.06663686e-02 -1.77400529e-01]\n",
       "   [ 1.37210518e-01 -1.66981682e-01 -1.75825059e-01]\n",
       "   [-1.13700926e-02 -1.71770379e-01 -1.80754349e-01]]]\n",
       "\n",
       "\n",
       " [[[ 1.17342532e-01 -1.25246122e-01  4.36568260e-02]\n",
       "   [-1.28248915e-01  1.09156132e-01  1.21462047e-01]\n",
       "   [ 1.39765799e-01  5.97490370e-02 -1.55793935e-01]]\n",
       "\n",
       "  [[ 1.29585981e-01 -1.67708784e-01 -1.40104204e-01]\n",
       "   [ 6.32902682e-02  1.34064347e-01  5.54828346e-03]\n",
       "   [-1.66599661e-01  8.09417665e-02  8.66871774e-02]]\n",
       "\n",
       "  [[ 1.37407273e-01  1.36265099e-01 -7.03882799e-02]\n",
       "   [-4.30146158e-02  1.12596929e-01  1.58761173e-01]\n",
       "   [-1.42925531e-02  9.43056047e-02  2.91520506e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.78751215e-01 -2.92624533e-03 -1.51681826e-01]\n",
       "   [-3.31627429e-02 -9.16357115e-02  1.09045208e-01]\n",
       "   [-6.47970811e-02  6.99364543e-02 -1.76437169e-01]]\n",
       "\n",
       "  [[ 5.80471456e-02 -4.29060906e-02  1.38128102e-02]\n",
       "   [-1.13552198e-01  9.72878337e-02 -6.52008951e-02]\n",
       "   [-3.40867937e-02 -1.28898978e-01  1.00027204e-01]]\n",
       "\n",
       "  [[-3.12890708e-02  1.11474395e-01 -4.54277247e-02]\n",
       "   [ 1.28747046e-01 -1.07698761e-01 -1.71826348e-01]\n",
       "   [ 4.67600226e-02  2.13909745e-02  3.19145769e-02]]]\n",
       "\n",
       "\n",
       " [[[ 6.09795153e-02  6.53798580e-02  1.58851147e-02]\n",
       "   [ 1.31815821e-01  9.09388959e-02 -1.17675558e-01]\n",
       "   [ 9.71961319e-02 -1.42025158e-01 -1.18488498e-01]]\n",
       "\n",
       "  [[-9.83842239e-02 -1.17170766e-01 -7.77797997e-02]\n",
       "   [-6.83522299e-02 -1.33498281e-01 -2.27994174e-02]\n",
       "   [-1.75565094e-01 -1.99733377e-02  1.10118210e-01]]\n",
       "\n",
       "  [[ 1.71729535e-01  3.86021286e-02 -4.06473279e-02]\n",
       "   [ 1.09524578e-01 -6.97095841e-02  1.28281116e-02]\n",
       "   [ 5.41785210e-02  2.32059956e-02 -1.25439763e-02]]]\n",
       "\n",
       "\n",
       " [[[-1.80582225e-01  3.25351954e-04 -7.91747496e-02]\n",
       "   [ 1.14499122e-01  1.40993237e-01  1.48832351e-01]\n",
       "   [-5.41790575e-02 -1.05926991e-02 -1.46621108e-01]]\n",
       "\n",
       "  [[-2.73419023e-02 -1.11192904e-01  7.39906430e-02]\n",
       "   [-6.18950874e-02 -1.24993175e-02 -1.74652562e-01]\n",
       "   [-1.69832543e-01  1.49268806e-01 -2.92789787e-02]]\n",
       "\n",
       "  [[-4.84194010e-02  1.83304638e-01 -5.65462112e-02]\n",
       "   [ 6.40254021e-02  1.04462624e-01  1.26508564e-01]\n",
       "   [-1.16557315e-01 -1.24532729e-02 -1.73336715e-02]]]\n",
       "\n",
       "\n",
       " [[[ 4.83467877e-02 -1.24434516e-01  1.19152457e-01]\n",
       "   [ 1.22755438e-01 -1.31298661e-01  5.54364175e-02]\n",
       "   [-1.76441446e-01  5.25495410e-03 -4.09110039e-02]]\n",
       "\n",
       "  [[ 8.47310126e-02  1.60800517e-01  1.48474276e-01]\n",
       "   [ 6.86119199e-02  1.36019379e-01 -1.44075453e-01]\n",
       "   [ 5.23838252e-02 -1.54542968e-01  1.18324161e-01]]\n",
       "\n",
       "  [[-1.41257003e-01  1.13560587e-01 -8.10354948e-04]\n",
       "   [-1.70496285e-01 -3.00478041e-02 -1.24494001e-01]\n",
       "   [-2.46627033e-02  2.51647830e-02  1.82791203e-01]]]])], relay.attrs.Conv2DAttrs(0x31870ba8), [TensorType([1, 3, 256, 256], float32), TensorType([16, 3, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x64461d8), [TensorType([1, 16, 256, 256], float32), TensorType([16], float32)])], relay.attrs.MaxPool2DAttrs(0x677cfe8), [TensorType([1, 16, 256, 256], float32)]), Constant([[[[-0.05230885 -0.0552981   0.11728252]\n",
       "   [ 0.08455608  0.10542003  0.04579628]\n",
       "   [-0.09307583  0.05534854 -0.01750716]]\n",
       "\n",
       "  [[ 0.04393943 -0.06029916 -0.01250177]\n",
       "   [ 0.07909112  0.06802806  0.11071744]\n",
       "   [ 0.0185835   0.03467863 -0.0656544 ]]\n",
       "\n",
       "  [[-0.06746837 -0.06010815  0.09041516]\n",
       "   [ 0.09943489  0.11015844 -0.09712255]\n",
       "   [-0.08474152 -0.04466622 -0.00359616]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.11497544  0.06267113 -0.03177162]\n",
       "   [ 0.06944317  0.10755137  0.03901506]\n",
       "   [ 0.07950256  0.10187579 -0.11717492]]\n",
       "\n",
       "  [[-0.08834244  0.10430969  0.11274465]\n",
       "   [ 0.00843327  0.02345195  0.02834205]\n",
       "   [-0.01871318  0.02506819  0.07203812]]\n",
       "\n",
       "  [[ 0.03502864  0.07529881  0.09674402]\n",
       "   [ 0.07443257 -0.07731336 -0.00925865]\n",
       "   [ 0.03505863 -0.06346579  0.10876042]]]\n",
       "\n",
       "\n",
       " [[[ 0.09483296 -0.08411033  0.02065786]\n",
       "   [-0.04375537 -0.04547243  0.01218746]\n",
       "   [-0.01966642 -0.04684217 -0.01652437]]\n",
       "\n",
       "  [[-0.02192305 -0.10731293 -0.00440802]\n",
       "   [ 0.10163368  0.07662707  0.0321778 ]\n",
       "   [-0.01564635  0.08551753  0.02628522]]\n",
       "\n",
       "  [[ 0.10481966 -0.0304717  -0.08486979]\n",
       "   [-0.02855957  0.01816257 -0.10232589]\n",
       "   [ 0.11503667  0.09423494  0.1027649 ]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.01420354  0.06906321 -0.02200597]\n",
       "   [-0.11723958  0.11678685 -0.01455109]\n",
       "   [ 0.03668139 -0.00778399 -0.11751148]]\n",
       "\n",
       "  [[ 0.00466588 -0.07041381 -0.04968228]\n",
       "   [ 0.04027871  0.10334843  0.11501909]\n",
       "   [-0.05539501 -0.04927304  0.01133548]]\n",
       "\n",
       "  [[ 0.10833482 -0.10027345  0.06273947]\n",
       "   [ 0.06040571  0.05947142 -0.07104565]\n",
       "   [-0.11337631  0.01624221 -0.08089186]]]\n",
       "\n",
       "\n",
       " [[[-0.07835841 -0.03311843  0.09948593]\n",
       "   [-0.05609833  0.09349469 -0.06139599]\n",
       "   [-0.06181434 -0.08554602 -0.1053581 ]]\n",
       "\n",
       "  [[ 0.08503192  0.05499079  0.05056188]\n",
       "   [-0.04506305 -0.10509247  0.06253643]\n",
       "   [ 0.01259098 -0.09399475 -0.00249332]]\n",
       "\n",
       "  [[ 0.01039549  0.11259469  0.11580513]\n",
       "   [ 0.06672735 -0.00530761 -0.09737875]\n",
       "   [-0.02119978 -0.10293067  0.11692385]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.07186478 -0.03072449 -0.0870213 ]\n",
       "   [-0.04209402  0.09946404  0.02351499]\n",
       "   [-0.07072626  0.04365916  0.05129435]]\n",
       "\n",
       "  [[ 0.00765935 -0.01586042 -0.01249991]\n",
       "   [-0.00079244 -0.01467744  0.10067401]\n",
       "   [-0.04039896 -0.02005445 -0.00711605]]\n",
       "\n",
       "  [[-0.10328984 -0.0535966  -0.03392352]\n",
       "   [ 0.02976998  0.07230691  0.06908812]\n",
       "   [-0.04546015 -0.05153897 -0.06480247]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[ 0.0070868   0.00938178 -0.00544529]\n",
       "   [-0.09389155  0.01959044  0.04377877]\n",
       "   [-0.06762378 -0.0329773   0.06007441]]\n",
       "\n",
       "  [[ 0.02986882 -0.11019504 -0.11619313]\n",
       "   [ 0.09995156  0.10913319 -0.10641829]\n",
       "   [-0.06335922  0.00646426  0.10509921]]\n",
       "\n",
       "  [[ 0.08675022  0.08664448 -0.1098199 ]\n",
       "   [ 0.00331356 -0.00187818 -0.07079825]\n",
       "   [ 0.0577076   0.02413637 -0.01189044]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.04778593  0.08398881  0.03136829]\n",
       "   [-0.07407292  0.05938094 -0.02747986]\n",
       "   [ 0.06026339 -0.08766058 -0.11293681]]\n",
       "\n",
       "  [[ 0.04645235 -0.09875906 -0.08499317]\n",
       "   [-0.04851406  0.034994    0.04832434]\n",
       "   [-0.04298678 -0.09601339 -0.10151485]]\n",
       "\n",
       "  [[ 0.07464734 -0.03293914 -0.06233732]\n",
       "   [ 0.02458305  0.10398766  0.04098863]\n",
       "   [ 0.02308751  0.06816975 -0.11231747]]]\n",
       "\n",
       "\n",
       " [[[-0.02933128 -0.06860529 -0.10139706]\n",
       "   [ 0.02435719 -0.10953418  0.01431978]\n",
       "   [ 0.04437434  0.01846709  0.03312323]]\n",
       "\n",
       "  [[ 0.05368101 -0.08317094 -0.08957916]\n",
       "   [ 0.03789932  0.09433054  0.0816843 ]\n",
       "   [-0.02192013  0.11146647 -0.03398576]]\n",
       "\n",
       "  [[-0.00226191  0.10830023 -0.11369399]\n",
       "   [-0.03664935  0.05322992 -0.01288033]\n",
       "   [ 0.08504245 -0.10482323 -0.01505179]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.05494811  0.02482646 -0.10490188]\n",
       "   [ 0.01156456 -0.08555114 -0.06266444]\n",
       "   [ 0.10471573  0.05411824 -0.10698368]]\n",
       "\n",
       "  [[ 0.11158954  0.0869856   0.07516759]\n",
       "   [ 0.11528201 -0.09075028  0.08242213]\n",
       "   [-0.05142607 -0.00498561 -0.04510528]]\n",
       "\n",
       "  [[-0.02594128  0.04859742  0.08633048]\n",
       "   [-0.08991379  0.01653565 -0.01028105]\n",
       "   [ 0.10650278  0.04709851  0.04210464]]]\n",
       "\n",
       "\n",
       " [[[-0.00932021 -0.11301627  0.04408962]\n",
       "   [-0.01989694  0.06719355 -0.0565851 ]\n",
       "   [ 0.06009115 -0.00729082 -0.02609874]]\n",
       "\n",
       "  [[ 0.01176082  0.11522078 -0.00057384]\n",
       "   [-0.0349285   0.05100989  0.05695517]\n",
       "   [-0.0210886  -0.10224926 -0.03217258]]\n",
       "\n",
       "  [[ 0.07885333 -0.04289071 -0.11050623]\n",
       "   [ 0.0116862   0.1011362   0.01308129]\n",
       "   [ 0.09525668 -0.00123814  0.00275118]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00897247  0.10901894  0.03509771]\n",
       "   [-0.11319994  0.03147358 -0.03104576]\n",
       "   [-0.02268737  0.05590992  0.11742789]]\n",
       "\n",
       "  [[-0.09170699  0.09731416  0.1078024 ]\n",
       "   [ 0.03355918  0.01081809 -0.05249008]\n",
       "   [-0.00724667  0.01866774  0.02748851]]\n",
       "\n",
       "  [[-0.00050731 -0.06097165 -0.05974628]\n",
       "   [-0.11410346 -0.04882569  0.01884864]\n",
       "   [ 0.01119485  0.04000121 -0.07791477]]]])], relay.attrs.Conv2DAttrs(0x3186f8c8), [TensorType([1, 16, (int64)128, (int64)128], float32), TensorType([32, 16, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x3186aba8), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)])], relay.attrs.MaxPool2DAttrs(0x318c09c8), [TensorType([1, 32, 128, 128], float32)]), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "   [-0.03190579 -0.01584832  0.02670189]\n",
       "   [ 0.01921258 -0.07818282  0.03479443]]\n",
       "\n",
       "  [[-0.00130421 -0.01830789  0.05642799]\n",
       "   [-0.0170652  -0.02210277  0.04254849]\n",
       "   [ 0.01875039 -0.08010064 -0.08040661]]\n",
       "\n",
       "  [[ 0.02165145  0.0240651  -0.04487719]\n",
       "   [-0.02167934 -0.00768209  0.0794398 ]\n",
       "   [-0.02068903  0.06871933  0.07726983]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.03205558  0.00290275 -0.02926568]\n",
       "   [ 0.04182967  0.04922665 -0.06711974]\n",
       "   [-0.02741003  0.05309341  0.01915387]]\n",
       "\n",
       "  [[-0.04150633  0.08178725  0.03009626]\n",
       "   [ 0.05355413  0.03888881 -0.05639726]\n",
       "   [ 0.04942527 -0.00437707  0.00632731]]\n",
       "\n",
       "  [[-0.02561722  0.05984905 -0.05160853]\n",
       "   [-0.07984905 -0.05768615  0.07380161]\n",
       "   [-0.07858952 -0.07737446  0.01850816]]]\n",
       "\n",
       "\n",
       " [[[-0.03143118  0.0695676  -0.04244177]\n",
       "   [ 0.04627309 -0.03359256 -0.06305707]\n",
       "   [ 0.01931474  0.06957508 -0.04066815]]\n",
       "\n",
       "  [[-0.05282148  0.07525725 -0.06407903]\n",
       "   [ 0.05680341  0.03004328 -0.07779044]\n",
       "   [-0.04317856 -0.04223323  0.04984415]]\n",
       "\n",
       "  [[-0.05401897 -0.03738686 -0.04842353]\n",
       "   [ 0.02915064 -0.01600464  0.07291468]\n",
       "   [-0.03190204 -0.0579984   0.04465697]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "   [ 0.00072628 -0.05233977 -0.03741848]\n",
       "   [ 0.07280735 -0.03233246  0.01515931]]\n",
       "\n",
       "  [[-0.05387771 -0.07664208  0.03958815]\n",
       "   [-0.06479758 -0.02311367 -0.05349527]\n",
       "   [-0.03774371 -0.00293905 -0.01947474]]\n",
       "\n",
       "  [[-0.06706224 -0.0475895  -0.03024844]\n",
       "   [-0.06104823 -0.05882414  0.03911529]\n",
       "   [-0.03023565  0.0054945   0.03267833]]]\n",
       "\n",
       "\n",
       " [[[-0.05496893  0.04519042 -0.04979972]\n",
       "   [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "   [ 0.06344249  0.04820261 -0.01685154]]\n",
       "\n",
       "  [[-0.07507978 -0.0369214   0.01589892]\n",
       "   [ 0.07496265 -0.03811238  0.07452969]\n",
       "   [-0.05802975  0.06737594 -0.02538034]]\n",
       "\n",
       "  [[-0.06388503 -0.06834688 -0.02203981]\n",
       "   [ 0.00349629 -0.03683617 -0.07054752]\n",
       "   [ 0.00112883 -0.06129277 -0.03130053]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.03836095  0.0297214   0.07942633]\n",
       "   [-0.01441041  0.00916564  0.06147317]\n",
       "   [ 0.08268154  0.01616826  0.08289457]]\n",
       "\n",
       "  [[ 0.03203704  0.01688347 -0.03459275]\n",
       "   [ 0.00918504 -0.00689121 -0.04055142]\n",
       "   [-0.08139901  0.06464074  0.02731381]]\n",
       "\n",
       "  [[-0.0072248  -0.07411295 -0.05513853]\n",
       "   [-0.02443562  0.03619969 -0.01066486]\n",
       "   [-0.0525009  -0.04152107 -0.04262205]]]\n",
       "\n",
       "\n",
       " ...\n",
       "\n",
       "\n",
       " [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "   [-0.03333757  0.02255654  0.01452807]\n",
       "   [ 0.07274816  0.04599313 -0.00011758]]\n",
       "\n",
       "  [[ 0.07283399  0.05451591 -0.04420283]\n",
       "   [ 0.07164187  0.08015741  0.06468589]\n",
       "   [-0.03062155 -0.05015038  0.02159031]]\n",
       "\n",
       "  [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "   [-0.00470024  0.00760442 -0.00532582]\n",
       "   [-0.02140979  0.03761176  0.07121743]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "   [ 0.08175186 -0.01663043  0.01697671]\n",
       "   [-0.04998031 -0.00914244  0.02868303]]\n",
       "\n",
       "  [[-0.00251392 -0.02931277 -0.01294055]\n",
       "   [ 0.07991172 -0.0130088  -0.05366091]\n",
       "   [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       "\n",
       "  [[-0.004662   -0.04977087  0.04939119]\n",
       "   [-0.01845763 -0.06482323  0.02449331]\n",
       "   [-0.01165619  0.06523957  0.03770921]]]\n",
       "\n",
       "\n",
       " [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "   [-0.05209206  0.03204753  0.02439884]\n",
       "   [-0.0282647   0.03098512  0.07474277]]\n",
       "\n",
       "  [[-0.05827966  0.00631046 -0.04896474]\n",
       "   [ 0.00211457  0.03935728  0.01188233]\n",
       "   [ 0.0395141  -0.0487875  -0.05219557]]\n",
       "\n",
       "  [[ 0.01199625  0.01175252 -0.08195679]\n",
       "   [-0.04492062 -0.07222724  0.08265557]\n",
       "   [ 0.00680294 -0.06261617 -0.04109164]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[-0.02842131  0.04017299 -0.06411938]\n",
       "   [-0.03479248 -0.00351638  0.04439355]\n",
       "   [-0.00836619 -0.00725466 -0.07700257]]\n",
       "\n",
       "  [[ 0.00681683  0.06109884 -0.03970103]\n",
       "   [-0.07532208  0.02519193  0.03664758]\n",
       "   [ 0.02089242  0.03030465 -0.04797888]]\n",
       "\n",
       "  [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "   [-0.00750206 -0.06763705  0.05190892]\n",
       "   [ 0.02197877  0.07384106  0.04836109]]]\n",
       "\n",
       "\n",
       " [[[-0.03292805  0.05048368  0.05959893]\n",
       "   [-0.00935958  0.07049897  0.07671262]\n",
       "   [-0.0200305   0.02493731 -0.05899358]]\n",
       "\n",
       "  [[-0.06843758  0.01676033  0.07503303]\n",
       "   [-0.00159057  0.07050664 -0.06662065]\n",
       "   [-0.07063043 -0.00717596 -0.07401031]]\n",
       "\n",
       "  [[-0.05164689  0.01307825  0.0358992 ]\n",
       "   [ 0.07245863  0.0667781   0.00989082]\n",
       "   [ 0.02502123 -0.00115818  0.06598707]]\n",
       "\n",
       "  ...\n",
       "\n",
       "  [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "   [ 0.06617681  0.03855822  0.08260872]\n",
       "   [ 0.0201846   0.02270871  0.0820188 ]]\n",
       "\n",
       "  [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "   [ 0.05576969 -0.03805411 -0.05533451]\n",
       "   [ 0.08203562 -0.04242806 -0.03506017]]\n",
       "\n",
       "  [[ 0.03055421 -0.0600045   0.01011878]\n",
       "   [ 0.07702617  0.05981912  0.04538635]\n",
       "   [-0.0253101  -0.06463408 -0.07805812]]]])], relay.attrs.Conv2DAttrs(0x318b5958), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])], relay.attrs.BiasAddAttrs(0x1e9ea08), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)])])], relay.attrs.ConcatenateAttrs(0x677e618), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite(socb, out.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.function.Function'>\n",
      "<class 'tvm.relay.expr.Let'>\n"
     ]
    }
   ],
   "source": [
    "for i in subgraphs:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][0].var.name_hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_8 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_9 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_10 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_11 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_12 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_13 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_14 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_15 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_16 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_17 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_18 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_19 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_20 is bound more than once, this is not valid IR\n",
      "[23:58:33] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_20 is bound more than once, this is not valid IR\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  6: TVMFuncCall\n  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  4: tvm::IRModule::FromExpr(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)\n  3: tvm::IRModule::FromExprInContext(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >)\n  2: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  1: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  0: tvm::relay::DeDup(tvm::RelayExpr const&)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/relay/transforms/de_duplicate.cc\", line 113\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (WellFormed(e)) is false: #[version = \"0.0.5\"]\nfn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n  %0 = (\n    let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n    let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n    let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n    let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n    let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n    let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n    let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n    let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n    let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n    let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n    let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    %x_20\n  );\n  %1 = (\n    let %x_8-malformed-ir = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_9-malformed-ir = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n    let %x_10-malformed-ir = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_11-malformed-ir = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_12-malformed-ir = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n    let %x_13-malformed-ir = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_14-malformed-ir = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n    let %x_15-malformed-ir = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_16-malformed-ir = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_17-malformed-ir = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n    let %x_18-malformed-ir = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_19-malformed-ir = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n    let %x_20-malformed-ir = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    %x_20\n  );\n  %2 = (\n    let %x_20-malformed-ir = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    %x_20\n  );\n  (%0, %1, %2)\n}\n/* For debugging purposes the metadata section has been omitted.\n * If you would like to see the full metadata section you can set the \n * option to `True` when invoking `astext`. \n */",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m out \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39mTuple(outputs[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m ann \u001b[39m=\u001b[39m run_opt_pass(out, transform\u001b[39m.\u001b[39;49mToGraphNormalForm())\n\u001b[1;32m      3\u001b[0m out \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mIRModule\u001b[39m.\u001b[39mfrom_expr(ann)[\u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/testing/__init__.py:53\u001b[0m, in \u001b[0;36mrun_opt_pass\u001b[0;34m(expr, opt_pass, import_prelude)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_opt_pass\u001b[39m(expr, opt_pass, import_prelude\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     52\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(opt_pass, tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPass)\n\u001b[0;32m---> 53\u001b[0m     mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39;49mIRModule\u001b[39m.\u001b[39;49mfrom_expr(expr)\n\u001b[1;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m import_prelude:\n\u001b[1;32m     55\u001b[0m         Prelude(mod)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:243\u001b[0m, in \u001b[0;36mIRModule.from_expr\u001b[0;34m(expr, functions, type_defs)\u001b[0m\n\u001b[1;32m    241\u001b[0m funcs \u001b[39m=\u001b[39m functions \u001b[39mif\u001b[39;00m functions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    242\u001b[0m defs \u001b[39m=\u001b[39m type_defs \u001b[39mif\u001b[39;00m type_defs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39;49mModule_FromExpr(expr, funcs, defs)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  6: TVMFuncCall\n  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  4: tvm::IRModule::FromExpr(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)\n  3: tvm::IRModule::FromExprInContext(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >)\n  2: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  1: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  0: tvm::relay::DeDup(tvm::RelayExpr const&)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/relay/transforms/de_duplicate.cc\", line 113\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (WellFormed(e)) is false: #[version = \"0.0.5\"]\nfn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n  %0 = (\n    let %x_0: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */ = meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n    let %x_1: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %x_0, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */ = meta[relay.Constant][1] /* ty=Tensor[(16), float32] */;\n    let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_1, %x_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n    let %x_4: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_3, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n    let %x_5: Tensor[(32, 16, 3, 3), float32] /* ty=Tensor[(32, 16, 3, 3), float32] */ = meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */;\n    let %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.conv2d(%x_4, %x_5, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][3] /* ty=Tensor[(32), float32] */;\n    let %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */ = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_9: Tensor[(1, 32, 64i64, 64i64), float32] /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n    let %x_10: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_11: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */ = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n    let %x_13: Tensor[(1, 64, 64, 64), float32] /* ty=Tensor[(1, 64, 64, 64), float32] */ = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_14: Tensor[(1, 64, 32i64, 32i64), float32] /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n    let %x_15: Tensor[(64, 32, 3, 3), float32] /* ty=Tensor[(64, 32, 3, 3), float32] */ = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_16: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_17: Tensor[(32), float32] /* ty=Tensor[(32), float32] */ = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n    let %x_18: Tensor[(1, 32, 64, 64), float32] /* ty=Tensor[(1, 32, 64, 64), float32] */ = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */ = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n    let %x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */ = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    %x_20\n  );\n  %1 = (\n    let %x_8-malformed-ir = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n    let %x_9-malformed-ir = nn.max_pool2d(%x_8, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n    let %x_10-malformed-ir = meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_11-malformed-ir = nn.conv2d(%x_9, %x_10, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_12-malformed-ir = meta[relay.Constant][5] /* ty=Tensor[(64), float32] */;\n    let %x_13-malformed-ir = nn.bias_add(%x_11, %x_12) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n    let %x_14-malformed-ir = nn.max_pool2d(%x_13, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n    let %x_15-malformed-ir = meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */;\n    let %x_16-malformed-ir = nn.conv2d_transpose(%x_14, %x_15, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_17-malformed-ir = meta[relay.Constant][7] /* ty=Tensor[(32), float32] */;\n    let %x_18-malformed-ir = nn.bias_add(%x_16, %x_17) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n    let %x_19-malformed-ir = (%x_18, %x_13) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n    let %x_20-malformed-ir = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    %x_20\n  );\n  %2 = (\n    let %x_20-malformed-ir = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n    %x_20\n  );\n  (%0, %1, %2)\n}\n/* For debugging purposes the metadata section has been omitted.\n * If you would like to see the full metadata section you can set the \n * option to `True` when invoking `astext`. \n */"
     ]
    }
   ],
   "source": [
    "out = relay.Tuple(outputs[0])\n",
    "ann = run_opt_pass(out, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  3: TVMFuncCall\n  2: tvm::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const [clone .isra.0]\n  1: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  0: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 191\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n\n  Check failed: fv.size() == 0 (3 vs. 0) : Function:\nfn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n  %3 = nn.conv2d(%2, meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %4 = nn.bias_add(%3, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n  %6 = nn.conv2d(%5, meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %7 = nn.bias_add(%6, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n  %9 = nn.conv2d_transpose(%8, meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %10 = nn.bias_add(%9, meta[relay.Constant][7] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %11 = (%10, %7) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n  free_var %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  free_var %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n  %12 = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %13 = nn.max_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n  %14 = nn.conv2d(%13, meta[relay.Constant][8] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %15 = nn.bias_add(%14, meta[relay.Constant][9] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %16 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n  %17 = nn.conv2d_transpose(%16, meta[relay.Constant][10] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %18 = nn.bias_add(%17, meta[relay.Constant][11] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %19 = (%18, %15) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n  free_var %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n  %20 = concatenate(%11, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n  %21 = concatenate(%19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n  %22 = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n  (%20, %21, %22)\n}\n\ncontains free variables: [Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), Var(x_7, ty=TensorType([32], float32)), Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m out1 \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39mFunction(out\u001b[39m.\u001b[39mparams, relay\u001b[39m.\u001b[39mTuple(outnew), out\u001b[39m.\u001b[39mret_type, out\u001b[39m.\u001b[39mtype_params, out\u001b[39m.\u001b[39mattrs)\n\u001b[1;32m      6\u001b[0m mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mIRModule()\n\u001b[0;32m----> 7\u001b[0m mod[\u001b[39m\"\u001b[39;49m\u001b[39mmain\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m out1\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:75\u001b[0m, in \u001b[0;36mIRModule.__setitem__\u001b[0;34m(self, var, val)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, var, val):\n\u001b[1;32m     65\u001b[0m     \u001b[39m\"\"\"Add a mapping to the module.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m        The value.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add(var, val, \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:84\u001b[0m, in \u001b[0;36mIRModule._add\u001b[0;34m(self, var, val, update)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m             var \u001b[39m=\u001b[39m _expr\u001b[39m.\u001b[39mGlobalVar(var)\n\u001b[0;32m---> 84\u001b[0m     _ffi_api\u001b[39m.\u001b[39;49mModule_Add(\u001b[39mself\u001b[39;49m, var, val, update)\n\u001b[1;32m     85\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(val, _ty\u001b[39m.\u001b[39mType)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  3: TVMFuncCall\n  2: tvm::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const [clone .isra.0]\n  1: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  0: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 191\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n\n  Check failed: fv.size() == 0 (3 vs. 0) : Function:\nfn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */) {\n  %0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n  %2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n  %3 = nn.conv2d(%2, meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %4 = nn.bias_add(%3, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n  %6 = nn.conv2d(%5, meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %7 = nn.bias_add(%6, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n  %9 = nn.conv2d_transpose(%8, meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %10 = nn.bias_add(%9, meta[relay.Constant][7] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %11 = (%10, %7) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n  free_var %x_6: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  free_var %x_7: Tensor[(32), float32] /* ty=Tensor[(32), float32] */;\n  %12 = nn.bias_add(%x_6, %x_7) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n  %13 = nn.max_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n  %14 = nn.conv2d(%13, meta[relay.Constant][8] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %15 = nn.bias_add(%14, meta[relay.Constant][9] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n  %16 = nn.max_pool2d(%15, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n  %17 = nn.conv2d_transpose(%16, meta[relay.Constant][10] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %18 = nn.bias_add(%17, meta[relay.Constant][11] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n  %19 = (%18, %15) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n  free_var %x_19: (Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n  %20 = concatenate(%11, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n  %21 = concatenate(%19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n  %22 = concatenate(%x_19, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n  (%20, %21, %22)\n}\n\ncontains free variables: [Var(x_6, ty=TensorType([1, 32, 128, 128], float32)), Var(x_7, ty=TensorType([32], float32)), Var(x_19, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))]"
     ]
    }
   ],
   "source": [
    "out = subgraphs[0]\n",
    "ann = run_opt_pass(out, transform.ToGraphNormalForm())\n",
    "out = tvm.IRModule.from_expr(ann)['main']\n",
    "# outnew = [run_opt_pass(i, transform.ToGraphNormalForm()) for i in outputs[0]]\n",
    "out1 = relay.Function(out.params, relay.Tuple(outnew), out.ret_type, out.type_params, out.attrs)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = out1\n",
    "\n",
    "# with tvm.transform.PassContext(opt_level=4):\n",
    "#     lib = relay.build(out1, 'cuda', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:54:16] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_20 is bound more than once, this is not valid IR\n",
      "[23:54:16] /home/jd/workspace/tvm-v0.9.0/src/relay/analysis/well_formed.cc:49: The IR is not well formed with: The variable x_8 is bound more than once, this is not valid IR\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  6: TVMFuncCall\n  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  4: tvm::IRModule::FromExpr(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)\n  3: tvm::IRModule::FromExprInContext(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >)\n  2: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  1: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  0: tvm::relay::DeDup(tvm::RelayExpr const&)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/relay/transforms/de_duplicate.cc\", line 113\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (WellFormed(e)) is false: #[version = \"0.0.5\"]\nfn (%x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */, %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */) {\n  fn (%x_20-malformed-ir, %x_8-malformed-ir) {\n    %0 = nn.conv2d_transpose(%x_20, meta[relay.Constant][0] /* ty=Tensor[(96, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n    %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n    %2 = (%1, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n    %3 = concatenate(%2, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n    %4 = nn.conv2d_transpose(%3, meta[relay.Constant][2] /* ty=Tensor[(48, 1, 3, 3), float32] */, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n    nn.bias_add(%4, meta[relay.Constant][3] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 256, 256), float32] */\n  }\n}\n/* For debugging purposes the metadata section has been omitted.\n * If you would like to see the full metadata section you can set the \n * option to `True` when invoking `astext`. \n */",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m out2 \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39mFunction(out\u001b[39m.\u001b[39mparams, out, out\u001b[39m.\u001b[39mret_type, out\u001b[39m.\u001b[39mtype_params, out\u001b[39m.\u001b[39mattrs)\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     lib \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mbuild(out2, \u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:407\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[39mif\u001b[39;00m params:\n\u001b[1;32m    406\u001b[0m         ir_mod \u001b[39m=\u001b[39m bind_params_by_name(ir_mod, params)\n\u001b[0;32m--> 407\u001b[0m     ir_mod \u001b[39m=\u001b[39m IRModule\u001b[39m.\u001b[39;49mfrom_expr(ir_mod)\n\u001b[1;32m    408\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    409\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use input parameter mod (tvm.IRModule) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstead of deprecated parameter mod (tvm.relay.function.Function)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    411\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    412\u001b[0m     )\n\u001b[1;32m    414\u001b[0m raw_targets \u001b[39m=\u001b[39m Target\u001b[39m.\u001b[39mcanon_multi_target_and_host(Target\u001b[39m.\u001b[39mtarget_or_current(target), target_host)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:243\u001b[0m, in \u001b[0;36mIRModule.from_expr\u001b[0;34m(expr, functions, type_defs)\u001b[0m\n\u001b[1;32m    241\u001b[0m funcs \u001b[39m=\u001b[39m functions \u001b[39mif\u001b[39;00m functions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    242\u001b[0m defs \u001b[39m=\u001b[39m type_defs \u001b[39mif\u001b[39;00m type_defs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39;49mModule_FromExpr(expr, funcs, defs)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  6: TVMFuncCall\n  5: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>::AssignTypedLambda<tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)>(tvm::IRModule (*)(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  4: tvm::IRModule::FromExpr(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&)\n  3: tvm::IRModule::FromExprInContext(tvm::RelayExpr const&, tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> const&, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void> const&, std::unordered_set<tvm::runtime::String, std::hash<tvm::runtime::String>, std::equal_to<tvm::runtime::String>, std::allocator<tvm::runtime::String> >)\n  2: tvm::IRModuleNode::Add(tvm::GlobalVar const&, tvm::BaseFunc const&, bool)\n  1: tvm::WarnIfMalformed(tvm::IRModule const&, tvm::relay::Function)\n  0: tvm::relay::DeDup(tvm::RelayExpr const&)\n  File \"/home/jd/workspace/tvm-v0.9.0/src/relay/transforms/de_duplicate.cc\", line 113\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (WellFormed(e)) is false: #[version = \"0.0.5\"]\nfn (%x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */, %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */) {\n  fn (%x_20-malformed-ir, %x_8-malformed-ir) {\n    %0 = nn.conv2d_transpose(%x_20, meta[relay.Constant][0] /* ty=Tensor[(96, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n    %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n    %2 = (%1, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n    %3 = concatenate(%2, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n    %4 = nn.conv2d_transpose(%3, meta[relay.Constant][2] /* ty=Tensor[(48, 1, 3, 3), float32] */, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n    nn.bias_add(%4, meta[relay.Constant][3] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 256, 256), float32] */\n  }\n}\n/* For debugging purposes the metadata section has been omitted.\n * If you would like to see the full metadata section you can set the \n * option to `True` when invoking `astext`. \n */"
     ]
    }
   ],
   "source": [
    "# out = subgraphs[1]\n",
    "# ann = run_opt_pass(out, transform.ToGraphNormalForm())\n",
    "# out = tvm.IRModule.from_expr(ann)['main']\n",
    "# out2 = relay.Function(out.params, out, out.ret_type, out.type_params, out.attrs)\n",
    "# with tvm.transform.PassContext(opt_level=4):\n",
    "#     lib = relay.build(out2, 'cuda', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%x_20: Tensor[(1, 96, 64, 64), float32] /* ty=Tensor[(1, 96, 64, 64), float32] */, %x_8: Tensor[(1, 32, 128, 128), float32] /* ty=Tensor[(1, 32, 128, 128), float32] */) {\n",
       "  %0 = nn.conv2d_transpose(%x_20, meta[relay.Constant][0] /* ty=Tensor[(96, 16, 3, 3), float32] */, channels=16, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
       "  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 128, 128), float32] */;\n",
       "  %2 = (%1, %x_8) /* ty=(Tensor[(1, 16, 128, 128), float32], Tensor[(1, 32, 128, 128), float32]) */;\n",
       "  %3 = concatenate(%2, axis=1) /* ty=Tensor[(1, 48, 128, 128), float32] */;\n",
       "  %4 = nn.conv2d_transpose(%3, meta[relay.Constant][2] /* ty=Tensor[(48, 1, 3, 3), float32] */, channels=1, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
       "  nn.bias_add(%4, meta[relay.Constant][3] /* ty=Tensor[(1), float32] */) /* ty=Tensor[(1, 1, 256, 256), float32] */\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.function.Function"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(subgraphs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[LetNode(Var(x_225, ty=TensorType([1, 32, 128, 128], float32)), CallNode(Op(nn.bias_add), [Var(x_223, ty=TensorType([1, 32, 128, 128], float32)), Var(x_224, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x30b172c8), [TensorType([1, 32, 128, 128], float32), TensorType([32], float32)]), LetNode(Var(x_226, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), CallNode(Op(nn.max_pool2d), [Var(x_225, ty=TensorType([1, 32, 128, 128], float32))], relay.attrs.MaxPool2DAttrs(0x30aedf08), [TensorType([1, 32, 128, 128], float32)]), LetNode(Var(x_227, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00034386 -0.00349673  0.07773861]\n",
       "     [-0.03190579 -0.01584832  0.02670189]\n",
       "     [ 0.01921258 -0.07818282  0.03479443]]\n",
       "  \n",
       "    [[-0.00130421 -0.01830789  0.05642799]\n",
       "     [-0.0170652  -0.02210277  0.04254849]\n",
       "     [ 0.01875039 -0.08010064 -0.08040661]]\n",
       "  \n",
       "    [[ 0.02165145  0.0240651  -0.04487719]\n",
       "     [-0.02167934 -0.00768209  0.0794398 ]\n",
       "     [-0.02068903  0.06871933  0.07726983]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[-0.03205558  0.00290275 -0.02926568]\n",
       "     [ 0.04182967  0.04922665 -0.06711974]\n",
       "     [-0.02741003  0.05309341  0.01915387]]\n",
       "  \n",
       "    [[-0.04150633  0.08178725  0.03009626]\n",
       "     [ 0.05355413  0.03888881 -0.05639726]\n",
       "     [ 0.04942527 -0.00437707  0.00632731]]\n",
       "  \n",
       "    [[-0.02561722  0.05984905 -0.05160853]\n",
       "     [-0.07984905 -0.05768615  0.07380161]\n",
       "     [-0.07858952 -0.07737446  0.01850816]]]\n",
       "  \n",
       "  \n",
       "   [[[-0.03143118  0.0695676  -0.04244177]\n",
       "     [ 0.04627309 -0.03359256 -0.06305707]\n",
       "     [ 0.01931474  0.06957508 -0.04066815]]\n",
       "  \n",
       "    [[-0.05282148  0.07525725 -0.06407903]\n",
       "     [ 0.05680341  0.03004328 -0.07779044]\n",
       "     [-0.04317856 -0.04223323  0.04984415]]\n",
       "  \n",
       "    [[-0.05401897 -0.03738686 -0.04842353]\n",
       "     [ 0.02915064 -0.01600464  0.07291468]\n",
       "     [-0.03190204 -0.0579984   0.04465697]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[-0.00600344 -0.01771474 -0.0669682 ]\n",
       "     [ 0.00072628 -0.05233977 -0.03741848]\n",
       "     [ 0.07280735 -0.03233246  0.01515931]]\n",
       "  \n",
       "    [[-0.05387771 -0.07664208  0.03958815]\n",
       "     [-0.06479758 -0.02311367 -0.05349527]\n",
       "     [-0.03774371 -0.00293905 -0.01947474]]\n",
       "  \n",
       "    [[-0.06706224 -0.0475895  -0.03024844]\n",
       "     [-0.06104823 -0.05882414  0.03911529]\n",
       "     [-0.03023565  0.0054945   0.03267833]]]\n",
       "  \n",
       "  \n",
       "   [[[-0.05496893  0.04519042 -0.04979972]\n",
       "     [-0.0025231  -0.04394376 -0.0357133 ]\n",
       "     [ 0.06344249  0.04820261 -0.01685154]]\n",
       "  \n",
       "    [[-0.07507978 -0.0369214   0.01589892]\n",
       "     [ 0.07496265 -0.03811238  0.07452969]\n",
       "     [-0.05802975  0.06737594 -0.02538034]]\n",
       "  \n",
       "    [[-0.06388503 -0.06834688 -0.02203981]\n",
       "     [ 0.00349629 -0.03683617 -0.07054752]\n",
       "     [ 0.00112883 -0.06129277 -0.03130053]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[ 0.03836095  0.0297214   0.07942633]\n",
       "     [-0.01441041  0.00916564  0.06147317]\n",
       "     [ 0.08268154  0.01616826  0.08289457]]\n",
       "  \n",
       "    [[ 0.03203704  0.01688347 -0.03459275]\n",
       "     [ 0.00918504 -0.00689121 -0.04055142]\n",
       "     [-0.08139901  0.06464074  0.02731381]]\n",
       "  \n",
       "    [[-0.0072248  -0.07411295 -0.05513853]\n",
       "     [-0.02443562  0.03619969 -0.01066486]\n",
       "     [-0.0525009  -0.04152107 -0.04262205]]]\n",
       "  \n",
       "  \n",
       "   ...\n",
       "  \n",
       "  \n",
       "   [[[-0.06229639  0.00368265 -0.0067502 ]\n",
       "     [-0.03333757  0.02255654  0.01452807]\n",
       "     [ 0.07274816  0.04599313 -0.00011758]]\n",
       "  \n",
       "    [[ 0.07283399  0.05451591 -0.04420283]\n",
       "     [ 0.07164187  0.08015741  0.06468589]\n",
       "     [-0.03062155 -0.05015038  0.02159031]]\n",
       "  \n",
       "    [[ 0.00773998 -0.02750689 -0.03792113]\n",
       "     [-0.00470024  0.00760442 -0.00532582]\n",
       "     [-0.02140979  0.03761176  0.07121743]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[ 0.08014026  0.00458467  0.0824988 ]\n",
       "     [ 0.08175186 -0.01663043  0.01697671]\n",
       "     [-0.04998031 -0.00914244  0.02868303]]\n",
       "  \n",
       "    [[-0.00251392 -0.02931277 -0.01294055]\n",
       "     [ 0.07991172 -0.0130088  -0.05366091]\n",
       "     [ 0.0464421  -0.06485568  0.0763394 ]]\n",
       "  \n",
       "    [[-0.004662   -0.04977087  0.04939119]\n",
       "     [-0.01845763 -0.06482323  0.02449331]\n",
       "     [-0.01165619  0.06523957  0.03770921]]]\n",
       "  \n",
       "  \n",
       "   [[[ 0.01544333 -0.01124992 -0.05245157]\n",
       "     [-0.05209206  0.03204753  0.02439884]\n",
       "     [-0.0282647   0.03098512  0.07474277]]\n",
       "  \n",
       "    [[-0.05827966  0.00631046 -0.04896474]\n",
       "     [ 0.00211457  0.03935728  0.01188233]\n",
       "     [ 0.0395141  -0.0487875  -0.05219557]]\n",
       "  \n",
       "    [[ 0.01199625  0.01175252 -0.08195679]\n",
       "     [-0.04492062 -0.07222724  0.08265557]\n",
       "     [ 0.00680294 -0.06261617 -0.04109164]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[-0.02842131  0.04017299 -0.06411938]\n",
       "     [-0.03479248 -0.00351638  0.04439355]\n",
       "     [-0.00836619 -0.00725466 -0.07700257]]\n",
       "  \n",
       "    [[ 0.00681683  0.06109884 -0.03970103]\n",
       "     [-0.07532208  0.02519193  0.03664758]\n",
       "     [ 0.02089242  0.03030465 -0.04797888]]\n",
       "  \n",
       "    [[ 0.06098434 -0.05125368 -0.07491653]\n",
       "     [-0.00750206 -0.06763705  0.05190892]\n",
       "     [ 0.02197877  0.07384106  0.04836109]]]\n",
       "  \n",
       "  \n",
       "   [[[-0.03292805  0.05048368  0.05959893]\n",
       "     [-0.00935958  0.07049897  0.07671262]\n",
       "     [-0.0200305   0.02493731 -0.05899358]]\n",
       "  \n",
       "    [[-0.06843758  0.01676033  0.07503303]\n",
       "     [-0.00159057  0.07050664 -0.06662065]\n",
       "     [-0.07063043 -0.00717596 -0.07401031]]\n",
       "  \n",
       "    [[-0.05164689  0.01307825  0.0358992 ]\n",
       "     [ 0.07245863  0.0667781   0.00989082]\n",
       "     [ 0.02502123 -0.00115818  0.06598707]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[ 0.00485136 -0.08295983 -0.03392466]\n",
       "     [ 0.06617681  0.03855822  0.08260872]\n",
       "     [ 0.0201846   0.02270871  0.0820188 ]]\n",
       "  \n",
       "    [[-0.04204714  0.02072773 -0.0725994 ]\n",
       "     [ 0.05576969 -0.03805411 -0.05533451]\n",
       "     [ 0.08203562 -0.04242806 -0.03506017]]\n",
       "  \n",
       "    [[ 0.03055421 -0.0600045   0.01011878]\n",
       "     [ 0.07702617  0.05981912  0.04538635]\n",
       "     [-0.0253101  -0.06463408 -0.07805812]]]]), LetNode(Var(x_228, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.conv2d), [Var(x_226, ty=TensorType([1, 32, (int64)64, (int64)64], float32)), Var(x_227, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x306a8508), [TensorType([1, 32, (int64)64, (int64)64], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_229, ty=TensorType([64], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_230, ty=TensorType([1, 64, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_228, ty=TensorType([1, 64, 64, 64], float32)), Var(x_229, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x30aedb18), [TensorType([1, 64, 64, 64], float32), TensorType([64], float32)]), LetNode(Var(x_231, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), CallNode(Op(nn.max_pool2d), [Var(x_230, ty=TensorType([1, 64, 64, 64], float32))], relay.attrs.MaxPool2DAttrs(0x30b03d38), [TensorType([1, 64, 64, 64], float32)]), LetNode(Var(x_232, ty=TensorType([64, 32, 3, 3], float32)), Constant([[[[-0.00667036  0.07674357  0.02048975]\n",
       "     [-0.0005337   0.06994274 -0.0409746 ]\n",
       "     [-0.01644263  0.02424868 -0.08242689]]\n",
       "  \n",
       "    [[-0.0279611   0.02216059 -0.04442815]\n",
       "     [-0.00076614 -0.00510069  0.00525645]\n",
       "     [ 0.05821113  0.01974467  0.01869611]]\n",
       "  \n",
       "    [[-0.01291529 -0.04766705 -0.04010829]\n",
       "     [-0.06574585 -0.06930234 -0.07820863]\n",
       "     [ 0.05632005 -0.01981469  0.03960329]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[-0.00203542 -0.01508743 -0.05518967]\n",
       "     [ 0.0098869  -0.02211016 -0.05686476]\n",
       "     [ 0.04343555  0.04212476 -0.04262485]]\n",
       "  \n",
       "    [[ 0.04512688 -0.01977579 -0.03921237]\n",
       "     [ 0.05846582 -0.01097473 -0.08292767]\n",
       "     [ 0.02642258 -0.05865683  0.00781246]]\n",
       "  \n",
       "    [[ 0.00868873  0.01789419 -0.05306506]\n",
       "     [ 0.03495514  0.00849197 -0.03360848]\n",
       "     [ 0.05213998 -0.05043467  0.02092493]]]\n",
       "  \n",
       "  \n",
       "   [[[-0.05225816 -0.03435542  0.06766681]\n",
       "     [-0.00570095 -0.07121497  0.04150715]\n",
       "     [ 0.03178158  0.0278095  -0.03169968]]\n",
       "  \n",
       "    [[ 0.08237877  0.00820927  0.07866023]\n",
       "     [ 0.06363843  0.00969597 -0.07367277]\n",
       "     [-0.07699051 -0.07091855 -0.04057622]]\n",
       "  \n",
       "    [[ 0.03507438  0.06507566 -0.07537719]\n",
       "     [-0.02447435 -0.06244735 -0.06095092]\n",
       "     [ 0.01566204  0.02181033  0.05003274]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[ 0.0431037   0.0482654   0.08321209]\n",
       "     [-0.05071964 -0.05884733 -0.0633956 ]\n",
       "     [ 0.06844861 -0.05180594 -0.0485846 ]]\n",
       "  \n",
       "    [[-0.03323257  0.02323034  0.00272747]\n",
       "     [ 0.05667796 -0.0002616  -0.00519013]\n",
       "     [ 0.01162627  0.02526001  0.06600187]]\n",
       "  \n",
       "    [[ 0.07655057  0.02485903 -0.05985588]\n",
       "     [ 0.04408409 -0.0380648  -0.00562543]\n",
       "     [-0.03243604 -0.03266114  0.02271339]]]\n",
       "  \n",
       "  \n",
       "   [[[ 0.02307111 -0.07447599  0.00114187]\n",
       "     [ 0.0209925  -0.03011368 -0.04503453]\n",
       "     [-0.01692474  0.06745539 -0.02362834]]\n",
       "  \n",
       "    [[ 0.06450888 -0.01736359 -0.02165564]\n",
       "     [-0.0565699   0.01656731  0.02207325]\n",
       "     [-0.03282728 -0.07110369 -0.05474281]]\n",
       "  \n",
       "    [[-0.00164378  0.07526512  0.07337628]\n",
       "     [ 0.01917853 -0.02339783  0.00305605]\n",
       "     [-0.05832756 -0.04507156 -0.02815646]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[-0.06093149 -0.06571921 -0.0378267 ]\n",
       "     [-0.05794454  0.02385507  0.04264715]\n",
       "     [ 0.0108671   0.05971035 -0.07129908]]\n",
       "  \n",
       "    [[-0.08070076  0.06473055 -0.0824315 ]\n",
       "     [ 0.02900531 -0.03235545 -0.03446659]\n",
       "     [-0.0361414  -0.0720194  -0.06739503]]\n",
       "  \n",
       "    [[ 0.06519654  0.05091707 -0.03405452]\n",
       "     [ 0.01338766  0.07065854 -0.01776394]\n",
       "     [ 0.03464925  0.03024761  0.03585237]]]\n",
       "  \n",
       "  \n",
       "   ...\n",
       "  \n",
       "  \n",
       "   [[[ 0.03777675 -0.03727138  0.01838966]\n",
       "     [-0.08274333 -0.064996    0.07656416]\n",
       "     [ 0.00311184  0.00922922  0.08024732]]\n",
       "  \n",
       "    [[-0.04885089  0.00447249  0.076678  ]\n",
       "     [-0.06130725 -0.08112308  0.01622806]\n",
       "     [ 0.00925171  0.07307453  0.00239494]]\n",
       "  \n",
       "    [[ 0.06266668 -0.07882553 -0.02372478]\n",
       "     [-0.00127685 -0.05542324  0.01506688]\n",
       "     [-0.04899919 -0.02099749 -0.04583566]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[-0.01963693 -0.01299276 -0.00876871]\n",
       "     [ 0.03455848  0.01813295 -0.01817822]\n",
       "     [ 0.00511507  0.01796635  0.03721446]]\n",
       "  \n",
       "    [[ 0.02849569 -0.0781398   0.06691042]\n",
       "     [ 0.08145543 -0.06311989 -0.06119695]\n",
       "     [-0.08139144 -0.04604743 -0.03518212]]\n",
       "  \n",
       "    [[-0.04671299  0.06773625 -0.05673073]\n",
       "     [-0.06609975  0.01549089  0.02074935]\n",
       "     [ 0.07406517 -0.04903018 -0.04878726]]]\n",
       "  \n",
       "  \n",
       "   [[[-0.02131156  0.06878123  0.02314601]\n",
       "     [ 0.07108916  0.04008206  0.02196169]\n",
       "     [-0.07365716 -0.03871602  0.04667952]]\n",
       "  \n",
       "    [[ 0.02348771  0.02149502  0.02541289]\n",
       "     [-0.01793929  0.06772844  0.02993079]\n",
       "     [-0.07476664  0.01974591 -0.07887741]]\n",
       "  \n",
       "    [[ 0.05220968  0.00943748  0.03035134]\n",
       "     [ 0.03464494 -0.02933544 -0.04283194]\n",
       "     [ 0.06609956  0.06831052 -0.05975342]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[ 0.00016204  0.0783995   0.07785139]\n",
       "     [ 0.03268198 -0.01940602  0.05926634]\n",
       "     [-0.05186518 -0.06860392  0.07977588]]\n",
       "  \n",
       "    [[ 0.06457258  0.077715   -0.05051591]\n",
       "     [-0.07378592 -0.07513899 -0.02788895]\n",
       "     [-0.06781612 -0.02720525  0.08009199]]\n",
       "  \n",
       "    [[-0.00609747 -0.00378752  0.06699146]\n",
       "     [-0.00971287 -0.05465307 -0.02018831]\n",
       "     [ 0.08092386 -0.01566859 -0.06308937]]]\n",
       "  \n",
       "  \n",
       "   [[[-0.01809273 -0.05052249  0.00830408]\n",
       "     [ 0.00651675  0.02668866 -0.02696224]\n",
       "     [ 0.06081321  0.03202073 -0.04717416]]\n",
       "  \n",
       "    [[ 0.0587954   0.06785775  0.06052122]\n",
       "     [ 0.00263701 -0.01710707 -0.00749189]\n",
       "     [ 0.02028066 -0.00381591  0.05403914]]\n",
       "  \n",
       "    [[-0.06002963  0.00170328  0.01363794]\n",
       "     [ 0.02595466  0.02344725 -0.03352585]\n",
       "     [ 0.06551506  0.0296605   0.06894781]]\n",
       "  \n",
       "    ...\n",
       "  \n",
       "    [[ 0.04791441  0.06846394  0.05488243]\n",
       "     [-0.04654666 -0.07713521  0.08156196]\n",
       "     [ 0.03400215  0.06116603 -0.02428303]]\n",
       "  \n",
       "    [[ 0.06481076  0.04652277 -0.04640434]\n",
       "     [-0.02026961  0.07876632  0.04329368]\n",
       "     [-0.06511961 -0.05031322 -0.04249084]]\n",
       "  \n",
       "    [[-0.05632734 -0.02485887 -0.06702858]\n",
       "     [-0.0249401  -0.0442156   0.00897348]\n",
       "     [ 0.06168193  0.00339633  0.07160915]]]]), LetNode(Var(x_233, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.conv2d_transpose), [Var(x_231, ty=TensorType([1, 64, (int64)32, (int64)32], float32)), Var(x_232, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x33f4a08), [TensorType([1, 64, (int64)32, (int64)32], float32), TensorType([64, 32, 3, 3], float32)]), LetNode(Var(x_234, ty=TensorType([32], float32)), Constant([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0.]), LetNode(Var(x_235, ty=TensorType([1, 32, 64, 64], float32)), CallNode(Op(nn.bias_add), [Var(x_233, ty=TensorType([1, 32, 64, 64], float32)), Var(x_234, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x56e1288), [TensorType([1, 32, 64, 64], float32), TensorType([32], float32)]), LetNode(Var(x_236, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])), Tuple([Var(x_235, ty=TensorType([1, 32, 64, 64], float32)), Var(x_230, ty=TensorType([1, 64, 64, 64], float32))]), LetNode(Var(x_237, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_236, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x56e1318), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Var(x_237, ty=TensorType([1, 96, 64, 64], float32))))))))))))))),\n",
       "  LetNode(Var(x_237, ty=TensorType([1, 96, 64, 64], float32)), CallNode(Op(concatenate), [Var(x_236, ty=TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)]))], relay.attrs.ConcatenateAttrs(0x56e1318), [TupleTypeNode([TensorType([1, 32, 64, 64], float32), TensorType([1, 64, 64, 64], float32)])]), Var(x_237, ty=TensorType([1, 96, 64, 64], float32)))],\n",
       " []]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ann = run_opt_pass(subgraphs.body, transform.ToGraphNormalForm())\n",
    "tmp_mod = tvm.IRModule.from_expr(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetNode(Var(x_29, ty=TensorType([1], float32)), Constant([0.]), LetNode(Var(x_30, ty=TensorType([1, 1, 256, 256], float32)), CallNode(Op(nn.bias_add), [Var(x_28, ty=TensorType([1, 1, 256, 256], float32)), Var(x_29, ty=TensorType([1], float32))], relay.attrs.BiasAddAttrs(0x309037a8), [TensorType([1, 1, 256, 256], float32), TensorType([1], float32)]), Var(x_30, ty=TensorType([1, 1, 256, 256], float32))))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraphs[1].body.body.body.body.body.body.body.body.body.body.body.body.body.body.body.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = run_opt_pass(subgraphs[1].body, transform.ToGraphNormalForm())\n",
    "# mod = tvm.IRModule.from_expr(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_20'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod['main'].params[0].name_hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = quantize(mod, 2)\n",
    "dev = tvm.cuda(0)\n",
    "target = 'cuda'\n",
    "# with tvm.transform.PassContext(opt_level=4, disabled_pass={}):\n",
    "#     lib = relay.build(out, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])], relay.attrs.MaxPool2DAttrs(0x31dcbfd8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x6a38268), [])], relay.attrs.CastAttrs(0x31df5538), [])], (nullptr), [])], relay.attrs.CastAttrs(0x6d106b8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x31da9498), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x437d268), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])])], relay.attrs.ConcatenateAttrs(0x4a2fbb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31de6ce8), [])], relay.attrs.CastAttrs(0x31dcbf38), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_9, ty=TensorType([96, 16, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x31df5818), []), Var(_param_10, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x4749e38), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])])], relay.attrs.ConcatenateAttrs(0x6d895c8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e4add8), [])], relay.attrs.CastAttrs(0x31de34d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x4716e28), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_11, ty=TensorType([48, 1, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x474c558), []), Var(_param_12, ty=TensorType([1], float32))], relay.attrs.BiasAddAttrs(0x4731598), []), CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])], relay.attrs.MaxPool2DAttrs(0x31dcbfd8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x6a38268), [])], relay.attrs.CastAttrs(0x31df5538), [])], (nullptr), [])], relay.attrs.CastAttrs(0x6d106b8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x31da9498), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x437d268), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])])], relay.attrs.ConcatenateAttrs(0x4a2fbb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31de6ce8), [])], relay.attrs.CastAttrs(0x31dcbf38), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_9, ty=TensorType([96, 16, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x31df5818), []), Var(_param_10, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x4749e38), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])])], relay.attrs.ConcatenateAttrs(0x6d895c8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e4add8), [])], relay.attrs.CastAttrs(0x31de34d8), []), CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(concatenate), [Tuple([CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d_transpose), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])], relay.attrs.MaxPool2DAttrs(0x31dcbfd8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x6a38268), [])], relay.attrs.CastAttrs(0x31df5538), [])], (nullptr), [])], relay.attrs.CastAttrs(0x6d106b8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_7, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DTransposeAttrs(0x31da9498), []), Var(_param_8, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x437d268), []), CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])])], relay.attrs.ConcatenateAttrs(0x4a2fbb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31de6ce8), [])], relay.attrs.CastAttrs(0x31dcbf38), []), CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x31e193a8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_5, ty=TensorType([64, 32, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dac258), []), Var(_param_6, ty=TensorType([64], float32))], relay.attrs.BiasAddAttrs(0x31dfee38), [])], relay.attrs.MaxPool2DAttrs(0x31dcbfd8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x6a38268), [])], relay.attrs.CastAttrs(0x31df5538), []), CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [CallNode(Op(add), [CallNode(Op(divide), [CallNode(Op(cast), [CallNode(Op(annotation.stop_fusion), [CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])], (nullptr), [])], relay.attrs.CastAttrs(0x7de78d8), []), Constant(7.0)], (nullptr), []), Constant(18.0)], (nullptr), []), Var(_param_3, ty=TensorType([32, 16, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31df0e98), []), Var(_param_4, ty=TensorType([32], float32))], relay.attrs.BiasAddAttrs(0x31dea5e8), [])], relay.attrs.MaxPool2DAttrs(0x31dcd6d8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31e34aa8), [])], relay.attrs.CastAttrs(0x31df9bc8), []), CallNode(Op(cast), [CallNode(Op(clip), [CallNode(Op(round), [CallNode(Op(multiply), [CallNode(Op(subtract), [CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x31dec048), []), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x6991b58), [])], relay.attrs.MaxPool2DAttrs(0x31dbdfb8), []), Constant(18.0)], (nullptr), []), Constant(7.0)], (nullptr), [])], (nullptr), [])], relay.attrs.ClipAttrs(0x31dda018), [])], relay.attrs.CastAttrs(0x31de98d8), [])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = out.body\n",
    "body = run_opt_pass(body, transform.ToANormalForm())\n",
    "body = run_opt_pass(body, transform.InferType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "mod['main'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.function.Function"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submods = []\n",
    "for g in subgraphs:\n",
    "    ann = run_opt_pass(g.body, transform.ToGraphNormalForm())\n",
    "    tmp_mod = tvm.IRModule.from_expr(ann)\n",
    "    submods.append(tmp_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "mod['main'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_attr = {\"color\": \"red\"}\n",
    "node_attr = {\"color\": \"blue\"}\n",
    "edge_attr = {\"color\": \"black\"}\n",
    "def get_node_attr(node):\n",
    "    if \"nn.conv2d\" in node.type_name and \"NCHW\" in node.detail:\n",
    "        return {\n",
    "            \"fillcolor\": \"green\",\n",
    "            \"style\": \"filled\",\n",
    "            \"shape\": \"box\",\n",
    "        }\n",
    "    if \"Var\" in node.type_name:\n",
    "        return {\"shape\": \"ellipse\"}\n",
    "    return {\"shape\": \"box\"}\n",
    "    \n",
    "dot_plotter = relay_viz.DotPlotter(\n",
    "    graph_attr=graph_attr,\n",
    "    node_attr=node_attr,\n",
    "    edge_attr=edge_attr,\n",
    "    get_node_attr=get_node_attr)\n",
    "\n",
    "viz = relay_viz.RelayVisualizer(\n",
    "    # submods[1],\n",
    "    mod,\n",
    "    relay_param=params,\n",
    "    plotter=dot_plotter,\n",
    "    parser=relay_viz.DotVizParser())\n",
    "viz.render(\"newnew\")\n",
    "\n",
    "# viz = relay_viz.RelayVisualizer(\n",
    "#     # submods[0],\n",
    "#     out1,\n",
    "#     relay_param=params,\n",
    "#     plotter=dot_plotter,\n",
    "#     parser=relay_viz.DotVizParser())\n",
    "# viz.render(\"simple_0\")\n",
    "# viz = relay_viz.RelayVisualizer(\n",
    "#     mod,\n",
    "#     relay_param=params,\n",
    "#     plotter=dot_plotter,\n",
    "#     parser=relay_viz.DotVizParser())\n",
    "# viz.render(\"simple_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "%0 = nn.conv2d(%input_1, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "%1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float32] */) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "%2 = nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "%3 = nn.conv2d(%2, meta[relay.Constant][2] /* ty=Tensor[(32, 16, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "%4 = nn.bias_add(%3, meta[relay.Constant][3] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 128, 128), float32] */;\n",
      "%5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 32, 64i64, 64i64), float32] */;\n",
      "%6 = nn.conv2d(%5, meta[relay.Constant][4] /* ty=Tensor[(64, 32, 3, 3), float32] */, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "%7 = nn.bias_add(%6, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 64, 64), float32] */;\n",
      "%8 = nn.max_pool2d(%7, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 32i64, 32i64), float32] */;\n",
      "%9 = nn.conv2d_transpose(%8, meta[relay.Constant][6] /* ty=Tensor[(64, 32, 3, 3), float32] */, channels=32, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "%10 = nn.bias_add(%9, meta[relay.Constant][7] /* ty=Tensor[(32), float32] */) /* ty=Tensor[(1, 32, 64, 64), float32] */;\n",
      "%11 = (%10, %7) /* ty=(Tensor[(1, 32, 64, 64), float32], Tensor[(1, 64, 64, 64), float32]) */;\n",
      "%12 = concatenate(%11, axis=1) /* ty=Tensor[(1, 96, 64, 64), float32] */;\n",
      "(%4, %12) /* ty=(Tensor[(1, 32, 128, 128), float32], Tensor[(1, 96, 64, 64), float32]) */\n",
      "/* For debugging purposes the metadata section has been omitted.\n",
      " * If you would like to see the full metadata section you can set the \n",
      " * option to `True` when invoking `astext`. \n",
      " */\n"
     ]
    }
   ],
   "source": [
    "print(mod['main'].body.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "free_var %v_param_1: Tensor[(64, 3, 3, 3), float32] /* ty=Tensor[(64, 3, 3, 3), float32] */;\n",
      "let %x_1745: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_2: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_1746: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.bias_add(%x_1745, %v_param_2) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_3: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_4: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_5: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_6: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_1747: (Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */ = nn.batch_norm(%x_1746, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "let %x_1748: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = %x_1747.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1749: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.leaky_relu(%x_1748, alpha=0.2f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1750: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1751: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = subtract(%x_1749, %x_1750) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1752: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1753: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = multiply(%x_1751, %x_1752) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1754: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = round(%x_1753) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1755: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = clip(%x_1754, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1756: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = cast(%x_1755, dtype=\"int8\") /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_1757: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = annotation.stop_fusion(%x_1756) /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_1758: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = cast(%x_1757, dtype=\"float32\") /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1759: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1760: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = divide(%x_1758, %x_1759) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1761: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1762: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = add(%x_1760, %x_1761) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_7: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
      "let %x_1763: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.conv2d(%x_1762, %v_param_7, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_8: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_1764: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.bias_add(%x_1763, %v_param_8) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_9: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_10: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_11: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_12: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_1765: (Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */ = nn.batch_norm(%x_1764, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "let %x_1766: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = %x_1765.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1767: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1768: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = subtract(%x_1766, %x_1767) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1769: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1770: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = multiply(%x_1768, %x_1769) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1771: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = round(%x_1770) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1772: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = clip(%x_1771, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1773: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = cast(%x_1772, dtype=\"int8\") /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_1774: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = annotation.stop_fusion(%x_1773) /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_1775: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = cast(%x_1774, dtype=\"float32\") /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1776: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1777: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = divide(%x_1775, %x_1776) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1778: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1779: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = add(%x_1777, %x_1778) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_1780: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_1779, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1781: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1782: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = subtract(%x_1780, %x_1781) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1783: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1784: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = multiply(%x_1782, %x_1783) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1785: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = round(%x_1784) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1786: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = clip(%x_1785, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1787: Tensor[(1, 64, 128i64, 128i64), int8] /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */ = cast(%x_1786, dtype=\"int8\") /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */;\n",
      "let %x_1788: Tensor[(1, 64, 128i64, 128i64), int8] /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */ = annotation.stop_fusion(%x_1787) /* ty=Tensor[(1, 64, 128i64, 128i64), int8] */;\n",
      "let %x_1789: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = cast(%x_1788, dtype=\"float32\") /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1790: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1791: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = divide(%x_1789, %x_1790) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "let %x_1792: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1793: Tensor[(1, 64, 128i64, 128i64), float32] /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */ = add(%x_1791, %x_1792) /* ty=Tensor[(1, 64, 128i64, 128i64), float32] */;\n",
      "free_var %v_param_13: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */;\n",
      "let %x_1794: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.conv2d(%x_1793, %v_param_13, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_14: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_1795: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.bias_add(%x_1794, %v_param_14) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_15: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_16: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_17: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_18: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_1796: (Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */ = nn.batch_norm(%x_1795, %v_param_15, %v_param_16, %v_param_17, %v_param_18, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
      "let %x_1797: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = %x_1796.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1798: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.leaky_relu(%x_1797, alpha=0.2f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1799: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1800: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = subtract(%x_1798, %x_1799) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1801: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1802: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = multiply(%x_1800, %x_1801) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1803: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = round(%x_1802) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1804: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = clip(%x_1803, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1805: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = cast(%x_1804, dtype=\"int8\") /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_1806: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = annotation.stop_fusion(%x_1805) /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_1807: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = cast(%x_1806, dtype=\"float32\") /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1808: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1809: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = divide(%x_1807, %x_1808) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1810: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1811: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = add(%x_1809, %x_1810) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_19: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */;\n",
      "let %x_1812: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.conv2d(%x_1811, %v_param_19, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_20: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_1813: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.bias_add(%x_1812, %v_param_20) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_21: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_22: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_23: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_24: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_1814: (Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */ = nn.batch_norm(%x_1813, %v_param_21, %v_param_22, %v_param_23, %v_param_24, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
      "let %x_1815: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = %x_1814.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1816: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1817: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = subtract(%x_1815, %x_1816) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1818: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1819: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = multiply(%x_1817, %x_1818) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1820: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = round(%x_1819) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1821: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = clip(%x_1820, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1822: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = cast(%x_1821, dtype=\"int8\") /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_1823: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = annotation.stop_fusion(%x_1822) /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_1824: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = cast(%x_1823, dtype=\"float32\") /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1825: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1826: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = divide(%x_1824, %x_1825) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1827: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1828: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = add(%x_1826, %x_1827) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_1829: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = nn.max_pool2d(%x_1828, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1830: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1831: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = subtract(%x_1829, %x_1830) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1832: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1833: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = multiply(%x_1831, %x_1832) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1834: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = round(%x_1833) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1835: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = clip(%x_1834, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1836: Tensor[(1, 128, 64i64, 64i64), int8] /* ty=Tensor[(1, 128, 64i64, 64i64), int8] */ = cast(%x_1835, dtype=\"int8\") /* ty=Tensor[(1, 128, 64i64, 64i64), int8] */;\n",
      "let %x_1837: Tensor[(1, 128, 64i64, 64i64), int8] /* ty=Tensor[(1, 128, 64i64, 64i64), int8] */ = annotation.stop_fusion(%x_1836) /* ty=Tensor[(1, 128, 64i64, 64i64), int8] */;\n",
      "let %x_1838: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = cast(%x_1837, dtype=\"float32\") /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1839: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1840: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = divide(%x_1838, %x_1839) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "let %x_1841: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1842: Tensor[(1, 128, 64i64, 64i64), float32] /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */ = add(%x_1840, %x_1841) /* ty=Tensor[(1, 128, 64i64, 64i64), float32] */;\n",
      "free_var %v_param_25: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */;\n",
      "let %x_1843: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.conv2d(%x_1842, %v_param_25, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_26: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_1844: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.bias_add(%x_1843, %v_param_26) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_27: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_28: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_29: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_30: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_1845: (Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */ = nn.batch_norm(%x_1844, %v_param_27, %v_param_28, %v_param_29, %v_param_30, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
      "let %x_1846: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = %x_1845.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1847: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.leaky_relu(%x_1846, alpha=0.2f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1848: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1849: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = subtract(%x_1847, %x_1848) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1850: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1851: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = multiply(%x_1849, %x_1850) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1852: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = round(%x_1851) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1853: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = clip(%x_1852, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1854: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = cast(%x_1853, dtype=\"int8\") /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_1855: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = annotation.stop_fusion(%x_1854) /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_1856: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = cast(%x_1855, dtype=\"float32\") /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1857: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1858: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = divide(%x_1856, %x_1857) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1859: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1860: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = add(%x_1858, %x_1859) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_31: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */;\n",
      "let %x_1861: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.conv2d(%x_1860, %v_param_31, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_32: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_1862: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.bias_add(%x_1861, %v_param_32) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_33: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_34: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_35: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_36: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_1863: (Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */ = nn.batch_norm(%x_1862, %v_param_33, %v_param_34, %v_param_35, %v_param_36, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
      "let %x_1864: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = %x_1863.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1865: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1866: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = subtract(%x_1864, %x_1865) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1867: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1868: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = multiply(%x_1866, %x_1867) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1869: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = round(%x_1868) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1870: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = clip(%x_1869, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1871: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = cast(%x_1870, dtype=\"int8\") /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_1872: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = annotation.stop_fusion(%x_1871) /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_1873: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = cast(%x_1872, dtype=\"float32\") /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1874: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1875: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = divide(%x_1873, %x_1874) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1876: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1877: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = add(%x_1875, %x_1876) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_1878: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = nn.max_pool2d(%x_1877, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1879: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1880: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = subtract(%x_1878, %x_1879) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1881: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1882: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = multiply(%x_1880, %x_1881) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1883: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = round(%x_1882) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1884: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = clip(%x_1883, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1885: Tensor[(1, 256, 32i64, 32i64), int8] /* ty=Tensor[(1, 256, 32i64, 32i64), int8] */ = cast(%x_1884, dtype=\"int8\") /* ty=Tensor[(1, 256, 32i64, 32i64), int8] */;\n",
      "let %x_1886: Tensor[(1, 256, 32i64, 32i64), int8] /* ty=Tensor[(1, 256, 32i64, 32i64), int8] */ = annotation.stop_fusion(%x_1885) /* ty=Tensor[(1, 256, 32i64, 32i64), int8] */;\n",
      "let %x_1887: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = cast(%x_1886, dtype=\"float32\") /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1888: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1889: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = divide(%x_1887, %x_1888) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "let %x_1890: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1891: Tensor[(1, 256, 32i64, 32i64), float32] /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */ = add(%x_1889, %x_1890) /* ty=Tensor[(1, 256, 32i64, 32i64), float32] */;\n",
      "free_var %v_param_37: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */;\n",
      "let %x_1892: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.conv2d(%x_1891, %v_param_37, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_38: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1893: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.bias_add(%x_1892, %v_param_38) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_39: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_40: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_41: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_42: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1894: (Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */ = nn.batch_norm(%x_1893, %v_param_39, %v_param_40, %v_param_41, %v_param_42, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
      "let %x_1895: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = %x_1894.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1896: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.leaky_relu(%x_1895, alpha=0.2f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1897: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1898: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = subtract(%x_1896, %x_1897) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1899: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1900: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = multiply(%x_1898, %x_1899) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1901: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = round(%x_1900) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1902: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = clip(%x_1901, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1903: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = cast(%x_1902, dtype=\"int8\") /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_1904: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = annotation.stop_fusion(%x_1903) /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_1905: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = cast(%x_1904, dtype=\"float32\") /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1906: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1907: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = divide(%x_1905, %x_1906) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1908: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1909: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = add(%x_1907, %x_1908) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_43: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
      "let %x_1910: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.conv2d(%x_1909, %v_param_43, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_44: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1911: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.bias_add(%x_1910, %v_param_44) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_45: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_46: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_47: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_48: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1912: (Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */ = nn.batch_norm(%x_1911, %v_param_45, %v_param_46, %v_param_47, %v_param_48, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
      "let %x_1913: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = %x_1912.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1914: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1915: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = subtract(%x_1913, %x_1914) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1916: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1917: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = multiply(%x_1915, %x_1916) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1918: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = round(%x_1917) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1919: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = clip(%x_1918, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1920: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = cast(%x_1919, dtype=\"int8\") /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_1921: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = annotation.stop_fusion(%x_1920) /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_1922: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = cast(%x_1921, dtype=\"float32\") /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1923: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1924: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = divide(%x_1922, %x_1923) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1925: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1926: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = add(%x_1924, %x_1925) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1927: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = nn.max_pool2d(%x_1926, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1928: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1929: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = subtract(%x_1927, %x_1928) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1930: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1931: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = multiply(%x_1929, %x_1930) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1932: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = round(%x_1931) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1933: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = clip(%x_1932, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1934: Tensor[(1, 512, 16i64, 16i64), int8] /* ty=Tensor[(1, 512, 16i64, 16i64), int8] */ = cast(%x_1933, dtype=\"int8\") /* ty=Tensor[(1, 512, 16i64, 16i64), int8] */;\n",
      "let %x_1935: Tensor[(1, 512, 16i64, 16i64), int8] /* ty=Tensor[(1, 512, 16i64, 16i64), int8] */ = annotation.stop_fusion(%x_1934) /* ty=Tensor[(1, 512, 16i64, 16i64), int8] */;\n",
      "let %x_1936: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = cast(%x_1935, dtype=\"float32\") /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1937: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1938: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = divide(%x_1936, %x_1937) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "let %x_1939: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1940: Tensor[(1, 512, 16i64, 16i64), float32] /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */ = add(%x_1938, %x_1939) /* ty=Tensor[(1, 512, 16i64, 16i64), float32] */;\n",
      "free_var %v_param_49: Tensor[(1024, 512, 3, 3), float32] /* ty=Tensor[(1024, 512, 3, 3), float32] */;\n",
      "let %x_1941: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = nn.conv2d(%x_1940, %v_param_49, padding=[1i64, 1i64, 1i64, 1i64], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "free_var %v_param_50: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "let %x_1942: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = nn.bias_add(%x_1941, %v_param_50) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "free_var %v_param_51: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "free_var %v_param_52: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "free_var %v_param_53: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "free_var %v_param_54: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "let %x_1943: (Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) /* ty=(Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */ = nn.batch_norm(%x_1942, %v_param_51, %v_param_52, %v_param_53, %v_param_54, epsilon=0.001f) /* ty=(Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;\n",
      "let %x_1944: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = %x_1943.0 /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1945: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = nn.leaky_relu(%x_1944, alpha=0.2f) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1946: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1947: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = subtract(%x_1945, %x_1946) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1948: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1949: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = multiply(%x_1947, %x_1948) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1950: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = round(%x_1949) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1951: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = clip(%x_1950, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1952: Tensor[(1, 1024, 16, 16), int8] /* ty=Tensor[(1, 1024, 16, 16), int8] */ = cast(%x_1951, dtype=\"int8\") /* ty=Tensor[(1, 1024, 16, 16), int8] */;\n",
      "let %x_1953: Tensor[(1, 1024, 16, 16), int8] /* ty=Tensor[(1, 1024, 16, 16), int8] */ = annotation.stop_fusion(%x_1952) /* ty=Tensor[(1, 1024, 16, 16), int8] */;\n",
      "let %x_1954: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = cast(%x_1953, dtype=\"float32\") /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1955: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1956: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = divide(%x_1954, %x_1955) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "let %x_1957: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1958: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = add(%x_1956, %x_1957) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "free_var %v_param_55: Tensor[(1024, 1024, 3, 3), float32] /* ty=Tensor[(1024, 1024, 3, 3), float32] */;\n",
      "let %x_1959: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = nn.conv2d(%x_1958, %v_param_55, padding=[1i64, 1i64, 1i64, 1i64], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "free_var %v_param_56: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "let %x_1960: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = nn.bias_add(%x_1959, %v_param_56) /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "free_var %v_param_57: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "free_var %v_param_58: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "free_var %v_param_59: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "free_var %v_param_60: Tensor[(1024), float32] /* ty=Tensor[(1024), float32] */;\n",
      "let %x_1961: (Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) /* ty=(Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */ = nn.batch_norm(%x_1960, %v_param_57, %v_param_58, %v_param_59, %v_param_60, epsilon=0.001f) /* ty=(Tensor[(1, 1024, 16, 16), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;\n",
      "let %x_1962: Tensor[(1, 1024, 16, 16), float32] /* ty=Tensor[(1, 1024, 16, 16), float32] */ = %x_1961.0 /* ty=Tensor[(1, 1024, 16, 16), float32] */;\n",
      "free_var %v_param_61: Tensor[(1024, 512, 3, 3), float32] /* ty=Tensor[(1024, 512, 3, 3), float32] */;\n",
      "let %x_1963: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.conv2d_transpose(%x_1962, %v_param_61, channels=512, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_62: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1964: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.bias_add(%x_1963, %v_param_62) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_63: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_64: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_65: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_66: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1965: (Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */ = nn.batch_norm(%x_1964, %v_param_63, %v_param_64, %v_param_65, %v_param_66, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
      "let %x_1966: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = %x_1965.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1967: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.leaky_relu(%x_1966, alpha=0.2f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1968: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1969: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = subtract(%x_1967, %x_1968) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1970: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1971: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = multiply(%x_1969, %x_1970) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1972: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = round(%x_1971) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1973: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = clip(%x_1972, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1974: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = cast(%x_1973, dtype=\"int8\") /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_1975: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = annotation.stop_fusion(%x_1974) /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_1976: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = cast(%x_1975, dtype=\"float32\") /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1977: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1978: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = divide(%x_1976, %x_1977) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1979: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1980: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = add(%x_1978, %x_1979) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_1981: (Tensor[(1, 512, 32, 32), float32], Tensor[(1, 512, 32, 32), float32]) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(1, 512, 32, 32), float32]) */ = (%x_1980, %x_1926) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(1, 512, 32, 32), float32]) */;\n",
      "let %x_1982: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = concatenate(%x_1981, axis=1) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1983: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1984: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = subtract(%x_1982, %x_1983) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1985: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1986: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = multiply(%x_1984, %x_1985) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1987: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = round(%x_1986) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1988: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = clip(%x_1987, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1989: Tensor[(1, 1024, 32, 32), int8] /* ty=Tensor[(1, 1024, 32, 32), int8] */ = cast(%x_1988, dtype=\"int8\") /* ty=Tensor[(1, 1024, 32, 32), int8] */;\n",
      "let %x_1990: Tensor[(1, 1024, 32, 32), int8] /* ty=Tensor[(1, 1024, 32, 32), int8] */ = annotation.stop_fusion(%x_1989) /* ty=Tensor[(1, 1024, 32, 32), int8] */;\n",
      "let %x_1991: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = cast(%x_1990, dtype=\"float32\") /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1992: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_1993: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = divide(%x_1991, %x_1992) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "let %x_1994: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_1995: Tensor[(1, 1024, 32, 32), float32] /* ty=Tensor[(1, 1024, 32, 32), float32] */ = add(%x_1993, %x_1994) /* ty=Tensor[(1, 1024, 32, 32), float32] */;\n",
      "free_var %v_param_67: Tensor[(512, 1024, 3, 3), float32] /* ty=Tensor[(512, 1024, 3, 3), float32] */;\n",
      "let %x_1996: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.conv2d(%x_1995, %v_param_67, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_68: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1997: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.bias_add(%x_1996, %v_param_68) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_69: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_70: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_71: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_72: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_1998: (Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */ = nn.batch_norm(%x_1997, %v_param_69, %v_param_70, %v_param_71, %v_param_72, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
      "let %x_1999: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = %x_1998.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2000: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.leaky_relu(%x_1999, alpha=0.2f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2001: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2002: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = subtract(%x_2000, %x_2001) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2003: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2004: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = multiply(%x_2002, %x_2003) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2005: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = round(%x_2004) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2006: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = clip(%x_2005, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2007: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = cast(%x_2006, dtype=\"int8\") /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_2008: Tensor[(1, 512, 32, 32), int8] /* ty=Tensor[(1, 512, 32, 32), int8] */ = annotation.stop_fusion(%x_2007) /* ty=Tensor[(1, 512, 32, 32), int8] */;\n",
      "let %x_2009: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = cast(%x_2008, dtype=\"float32\") /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2010: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2011: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = divide(%x_2009, %x_2010) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "let %x_2012: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2013: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = add(%x_2011, %x_2012) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_73: Tensor[(512, 512, 3, 3), float32] /* ty=Tensor[(512, 512, 3, 3), float32] */;\n",
      "let %x_2014: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.conv2d(%x_2013, %v_param_73, padding=[1i64, 1i64, 1i64, 1i64], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_74: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_2015: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = nn.bias_add(%x_2014, %v_param_74) /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_75: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_76: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_77: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "free_var %v_param_78: Tensor[(512), float32] /* ty=Tensor[(512), float32] */;\n",
      "let %x_2016: (Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */ = nn.batch_norm(%x_2015, %v_param_75, %v_param_76, %v_param_77, %v_param_78, epsilon=0.001f) /* ty=(Tensor[(1, 512, 32, 32), float32], Tensor[(512), float32], Tensor[(512), float32]) */;\n",
      "let %x_2017: Tensor[(1, 512, 32, 32), float32] /* ty=Tensor[(1, 512, 32, 32), float32] */ = %x_2016.0 /* ty=Tensor[(1, 512, 32, 32), float32] */;\n",
      "free_var %v_param_79: Tensor[(512, 256, 3, 3), float32] /* ty=Tensor[(512, 256, 3, 3), float32] */;\n",
      "let %x_2018: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.conv2d_transpose(%x_2017, %v_param_79, channels=256, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_80: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_2019: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.bias_add(%x_2018, %v_param_80) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_81: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_82: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_83: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_84: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_2020: (Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */ = nn.batch_norm(%x_2019, %v_param_81, %v_param_82, %v_param_83, %v_param_84, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
      "let %x_2021: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = %x_2020.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2022: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.leaky_relu(%x_2021, alpha=0.2f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2023: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2024: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = subtract(%x_2022, %x_2023) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2025: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2026: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = multiply(%x_2024, %x_2025) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2027: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = round(%x_2026) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2028: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = clip(%x_2027, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2029: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = cast(%x_2028, dtype=\"int8\") /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_2030: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = annotation.stop_fusion(%x_2029) /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_2031: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = cast(%x_2030, dtype=\"float32\") /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2032: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2033: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = divide(%x_2031, %x_2032) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2034: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2035: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = add(%x_2033, %x_2034) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2036: (Tensor[(1, 256, 64, 64), float32], Tensor[(1, 256, 64, 64), float32]) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(1, 256, 64, 64), float32]) */ = (%x_2035, %x_1877) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(1, 256, 64, 64), float32]) */;\n",
      "let %x_2037: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = concatenate(%x_2036, axis=1) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2038: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2039: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = subtract(%x_2037, %x_2038) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2040: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2041: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = multiply(%x_2039, %x_2040) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2042: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = round(%x_2041) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2043: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = clip(%x_2042, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2044: Tensor[(1, 512, 64, 64), int8] /* ty=Tensor[(1, 512, 64, 64), int8] */ = cast(%x_2043, dtype=\"int8\") /* ty=Tensor[(1, 512, 64, 64), int8] */;\n",
      "let %x_2045: Tensor[(1, 512, 64, 64), int8] /* ty=Tensor[(1, 512, 64, 64), int8] */ = annotation.stop_fusion(%x_2044) /* ty=Tensor[(1, 512, 64, 64), int8] */;\n",
      "let %x_2046: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = cast(%x_2045, dtype=\"float32\") /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2047: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2048: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = divide(%x_2046, %x_2047) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "let %x_2049: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2050: Tensor[(1, 512, 64, 64), float32] /* ty=Tensor[(1, 512, 64, 64), float32] */ = add(%x_2048, %x_2049) /* ty=Tensor[(1, 512, 64, 64), float32] */;\n",
      "free_var %v_param_85: Tensor[(256, 512, 3, 3), float32] /* ty=Tensor[(256, 512, 3, 3), float32] */;\n",
      "let %x_2051: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.conv2d(%x_2050, %v_param_85, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_86: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_2052: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.bias_add(%x_2051, %v_param_86) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_87: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_88: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_89: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_90: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_2053: (Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */ = nn.batch_norm(%x_2052, %v_param_87, %v_param_88, %v_param_89, %v_param_90, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
      "let %x_2054: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = %x_2053.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2055: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.leaky_relu(%x_2054, alpha=0.2f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2056: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2057: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = subtract(%x_2055, %x_2056) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2058: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2059: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = multiply(%x_2057, %x_2058) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2060: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = round(%x_2059) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2061: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = clip(%x_2060, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2062: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = cast(%x_2061, dtype=\"int8\") /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_2063: Tensor[(1, 256, 64, 64), int8] /* ty=Tensor[(1, 256, 64, 64), int8] */ = annotation.stop_fusion(%x_2062) /* ty=Tensor[(1, 256, 64, 64), int8] */;\n",
      "let %x_2064: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = cast(%x_2063, dtype=\"float32\") /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2065: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2066: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = divide(%x_2064, %x_2065) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "let %x_2067: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2068: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = add(%x_2066, %x_2067) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_91: Tensor[(256, 256, 3, 3), float32] /* ty=Tensor[(256, 256, 3, 3), float32] */;\n",
      "let %x_2069: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.conv2d(%x_2068, %v_param_91, padding=[1i64, 1i64, 1i64, 1i64], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_92: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_2070: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = nn.bias_add(%x_2069, %v_param_92) /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_93: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_94: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_95: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "free_var %v_param_96: Tensor[(256), float32] /* ty=Tensor[(256), float32] */;\n",
      "let %x_2071: (Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */ = nn.batch_norm(%x_2070, %v_param_93, %v_param_94, %v_param_95, %v_param_96, epsilon=0.001f) /* ty=(Tensor[(1, 256, 64, 64), float32], Tensor[(256), float32], Tensor[(256), float32]) */;\n",
      "let %x_2072: Tensor[(1, 256, 64, 64), float32] /* ty=Tensor[(1, 256, 64, 64), float32] */ = %x_2071.0 /* ty=Tensor[(1, 256, 64, 64), float32] */;\n",
      "free_var %v_param_97: Tensor[(256, 128, 3, 3), float32] /* ty=Tensor[(256, 128, 3, 3), float32] */;\n",
      "let %x_2073: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.conv2d_transpose(%x_2072, %v_param_97, channels=128, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_98: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_2074: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.bias_add(%x_2073, %v_param_98) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_99: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_100: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_101: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_102: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_2075: (Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */ = nn.batch_norm(%x_2074, %v_param_99, %v_param_100, %v_param_101, %v_param_102, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
      "let %x_2076: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = %x_2075.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2077: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.leaky_relu(%x_2076, alpha=0.2f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2078: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2079: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = subtract(%x_2077, %x_2078) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2080: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2081: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = multiply(%x_2079, %x_2080) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2082: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = round(%x_2081) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2083: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = clip(%x_2082, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2084: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = cast(%x_2083, dtype=\"int8\") /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_2085: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = annotation.stop_fusion(%x_2084) /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_2086: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = cast(%x_2085, dtype=\"float32\") /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2087: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2088: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = divide(%x_2086, %x_2087) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2089: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2090: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = add(%x_2088, %x_2089) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2091: (Tensor[(1, 128, 128, 128), float32], Tensor[(1, 128, 128, 128), float32]) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(1, 128, 128, 128), float32]) */ = (%x_2090, %x_1828) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(1, 128, 128, 128), float32]) */;\n",
      "let %x_2092: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = concatenate(%x_2091, axis=1) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2093: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2094: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = subtract(%x_2092, %x_2093) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2095: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2096: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = multiply(%x_2094, %x_2095) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2097: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = round(%x_2096) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2098: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = clip(%x_2097, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2099: Tensor[(1, 256, 128, 128), int8] /* ty=Tensor[(1, 256, 128, 128), int8] */ = cast(%x_2098, dtype=\"int8\") /* ty=Tensor[(1, 256, 128, 128), int8] */;\n",
      "let %x_2100: Tensor[(1, 256, 128, 128), int8] /* ty=Tensor[(1, 256, 128, 128), int8] */ = annotation.stop_fusion(%x_2099) /* ty=Tensor[(1, 256, 128, 128), int8] */;\n",
      "let %x_2101: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = cast(%x_2100, dtype=\"float32\") /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2102: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2103: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = divide(%x_2101, %x_2102) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "let %x_2104: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2105: Tensor[(1, 256, 128, 128), float32] /* ty=Tensor[(1, 256, 128, 128), float32] */ = add(%x_2103, %x_2104) /* ty=Tensor[(1, 256, 128, 128), float32] */;\n",
      "free_var %v_param_103: Tensor[(128, 256, 3, 3), float32] /* ty=Tensor[(128, 256, 3, 3), float32] */;\n",
      "let %x_2106: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.conv2d(%x_2105, %v_param_103, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_104: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_2107: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.bias_add(%x_2106, %v_param_104) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_105: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_106: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_107: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_108: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_2108: (Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */ = nn.batch_norm(%x_2107, %v_param_105, %v_param_106, %v_param_107, %v_param_108, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
      "let %x_2109: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = %x_2108.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2110: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.leaky_relu(%x_2109, alpha=0.2f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2111: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2112: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = subtract(%x_2110, %x_2111) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2113: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2114: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = multiply(%x_2112, %x_2113) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2115: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = round(%x_2114) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2116: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = clip(%x_2115, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2117: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = cast(%x_2116, dtype=\"int8\") /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_2118: Tensor[(1, 128, 128, 128), int8] /* ty=Tensor[(1, 128, 128, 128), int8] */ = annotation.stop_fusion(%x_2117) /* ty=Tensor[(1, 128, 128, 128), int8] */;\n",
      "let %x_2119: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = cast(%x_2118, dtype=\"float32\") /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2120: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2121: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = divide(%x_2119, %x_2120) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "let %x_2122: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2123: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = add(%x_2121, %x_2122) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_109: Tensor[(128, 128, 3, 3), float32] /* ty=Tensor[(128, 128, 3, 3), float32] */;\n",
      "let %x_2124: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.conv2d(%x_2123, %v_param_109, padding=[1i64, 1i64, 1i64, 1i64], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_110: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_2125: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = nn.bias_add(%x_2124, %v_param_110) /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_111: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_112: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_113: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "free_var %v_param_114: Tensor[(128), float32] /* ty=Tensor[(128), float32] */;\n",
      "let %x_2126: (Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */ = nn.batch_norm(%x_2125, %v_param_111, %v_param_112, %v_param_113, %v_param_114, epsilon=0.001f) /* ty=(Tensor[(1, 128, 128, 128), float32], Tensor[(128), float32], Tensor[(128), float32]) */;\n",
      "let %x_2127: Tensor[(1, 128, 128, 128), float32] /* ty=Tensor[(1, 128, 128, 128), float32] */ = %x_2126.0 /* ty=Tensor[(1, 128, 128, 128), float32] */;\n",
      "free_var %v_param_115: Tensor[(128, 64, 3, 3), float32] /* ty=Tensor[(128, 64, 3, 3), float32] */;\n",
      "let %x_2128: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.conv2d_transpose(%x_2127, %v_param_115, channels=64, kernel_size=[3, 3], strides=[2, 2], padding=[0i64, 0i64, 1i64, 1i64], kernel_layout=\"IOHW\") /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_116: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_2129: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.bias_add(%x_2128, %v_param_116) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_117: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_118: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_119: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_120: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_2130: (Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */ = nn.batch_norm(%x_2129, %v_param_117, %v_param_118, %v_param_119, %v_param_120, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "let %x_2131: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = %x_2130.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2132: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.leaky_relu(%x_2131, alpha=0.2f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2133: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2134: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = subtract(%x_2132, %x_2133) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2135: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2136: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = multiply(%x_2134, %x_2135) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2137: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = round(%x_2136) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2138: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = clip(%x_2137, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2139: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = cast(%x_2138, dtype=\"int8\") /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_2140: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = annotation.stop_fusion(%x_2139) /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_2141: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = cast(%x_2140, dtype=\"float32\") /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2142: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2143: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = divide(%x_2141, %x_2142) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2144: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2145: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = add(%x_2143, %x_2144) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2146: (Tensor[(1, 64, 256, 256), float32], Tensor[(1, 64, 256, 256), float32]) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(1, 64, 256, 256), float32]) */ = (%x_2145, %x_1779) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(1, 64, 256, 256), float32]) */;\n",
      "let %x_2147: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = concatenate(%x_2146, axis=1) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2148: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2149: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = subtract(%x_2147, %x_2148) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2150: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2151: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = multiply(%x_2149, %x_2150) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2152: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = round(%x_2151) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2153: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = clip(%x_2152, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2154: Tensor[(1, 128, 256, 256), int8] /* ty=Tensor[(1, 128, 256, 256), int8] */ = cast(%x_2153, dtype=\"int8\") /* ty=Tensor[(1, 128, 256, 256), int8] */;\n",
      "let %x_2155: Tensor[(1, 128, 256, 256), int8] /* ty=Tensor[(1, 128, 256, 256), int8] */ = annotation.stop_fusion(%x_2154) /* ty=Tensor[(1, 128, 256, 256), int8] */;\n",
      "let %x_2156: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = cast(%x_2155, dtype=\"float32\") /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2157: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2158: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = divide(%x_2156, %x_2157) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "let %x_2159: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2160: Tensor[(1, 128, 256, 256), float32] /* ty=Tensor[(1, 128, 256, 256), float32] */ = add(%x_2158, %x_2159) /* ty=Tensor[(1, 128, 256, 256), float32] */;\n",
      "free_var %v_param_121: Tensor[(64, 128, 3, 3), float32] /* ty=Tensor[(64, 128, 3, 3), float32] */;\n",
      "let %x_2161: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.conv2d(%x_2160, %v_param_121, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_122: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_2162: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.bias_add(%x_2161, %v_param_122) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_123: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_124: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_125: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_126: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_2163: (Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */ = nn.batch_norm(%x_2162, %v_param_123, %v_param_124, %v_param_125, %v_param_126, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "let %x_2164: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = %x_2163.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2165: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.leaky_relu(%x_2164, alpha=0.2f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2166: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2167: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = subtract(%x_2165, %x_2166) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2168: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2169: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = multiply(%x_2167, %x_2168) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2170: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = round(%x_2169) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2171: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = clip(%x_2170, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2172: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = cast(%x_2171, dtype=\"int8\") /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_2173: Tensor[(1, 64, 256, 256), int8] /* ty=Tensor[(1, 64, 256, 256), int8] */ = annotation.stop_fusion(%x_2172) /* ty=Tensor[(1, 64, 256, 256), int8] */;\n",
      "let %x_2174: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = cast(%x_2173, dtype=\"float32\") /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2175: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_2176: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = divide(%x_2174, %x_2175) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "let %x_2177: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_2178: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = add(%x_2176, %x_2177) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_127: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
      "let %x_2179: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.conv2d(%x_2178, %v_param_127, padding=[1i64, 1i64, 1i64, 1i64], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_128: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_2180: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = nn.bias_add(%x_2179, %v_param_128) /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_129: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_130: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_131: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "free_var %v_param_132: Tensor[(64), float32] /* ty=Tensor[(64), float32] */;\n",
      "let %x_2181: (Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */ = nn.batch_norm(%x_2180, %v_param_129, %v_param_130, %v_param_131, %v_param_132, epsilon=0.001f) /* ty=(Tensor[(1, 64, 256, 256), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "let %x_2182: Tensor[(1, 64, 256, 256), float32] /* ty=Tensor[(1, 64, 256, 256), float32] */ = %x_2181.0 /* ty=Tensor[(1, 64, 256, 256), float32] */;\n",
      "free_var %v_param_133: Tensor[(1, 64, 3, 3), float32] /* ty=Tensor[(1, 64, 3, 3), float32] */;\n",
      "let %x_2183: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.conv2d(%x_2182, %v_param_133, padding=[1i64, 1i64, 1i64, 1i64], channels=1, kernel_size=[3, 3]) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "free_var %v_param_134: Tensor[(1), float32] /* ty=Tensor[(1), float32] */;\n",
      "let %x_2184: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = nn.bias_add(%x_2183, %v_param_134) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_2185: Tensor[(1, 1, 256, 256), float32] /* ty=Tensor[(1, 1, 256, 256), float32] */ = sigmoid(%x_2184) /* ty=Tensor[(1, 1, 256, 256), float32] */;\n",
      "let %x_2186: (Tensor[(1, 1, 256, 256), float32], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 128, 256, 256), int8], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 256, 128, 128), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 512, 64, 64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 1024, 32, 32), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 1024, 16, 16), int8], Tensor[(1, 512, 16i64, 16i64), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 256, 32i64, 32i64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 128, 64i64, 64i64), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 64, 128i64, 128i64), int8], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 64, 256, 256), int8]) /* ty=(Tensor[(1, 1, 256, 256), float32], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 128, 256, 256), int8], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 256, 128, 128), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 512, 64, 64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 1024, 32, 32), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 1024, 16, 16), int8], Tensor[(1, 512, 16i64, 16i64), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 256, 32i64, 32i64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 128, 64i64, 64i64), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 64, 128i64, 128i64), int8], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 64, 256, 256), int8]) */ = (%x_2185, %x_2172, %x_2154, %x_2139, %x_2117, %x_2099, %x_2084, %x_2062, %x_2044, %x_2029, %x_2007, %x_1989, %x_1974, %x_1952, %x_1934, %x_1920, %x_1903, %x_1885, %x_1871, %x_1854, %x_1836, %x_1822, %x_1805, %x_1787, %x_1773, %x_1756) /* ty=(Tensor[(1, 1, 256, 256), float32], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 128, 256, 256), int8], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 256, 128, 128), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 512, 64, 64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 1024, 32, 32), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 1024, 16, 16), int8], Tensor[(1, 512, 16i64, 16i64), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 512, 32, 32), int8], Tensor[(1, 256, 32i64, 32i64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 256, 64, 64), int8], Tensor[(1, 128, 64i64, 64i64), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 128, 128, 128), int8], Tensor[(1, 64, 128i64, 128i64), int8], Tensor[(1, 64, 256, 256), int8], Tensor[(1, 64, 256, 256), int8]) */;\n",
      "%x_2186\n"
     ]
    }
   ],
   "source": [
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network():\n",
    "    img_size = 8\n",
    "    out_channels = 16\n",
    "    batch_size = 1\n",
    "    data = relay.var(\"data\", relay.TensorType((batch_size, 3, img_size, img_size), \"float16\"))\n",
    "    dense_weight = relay.var(\n",
    "        \"dweight\", relay.TensorType((batch_size, 16 * img_size * img_size), \"float16\")\n",
    "    )\n",
    "    weight = relay.var(\"weight\")\n",
    "    second_weight = relay.var(\"second_weight\")\n",
    "    bn_gamma = relay.var(\"bn_gamma\")\n",
    "    bn_beta = relay.var(\"bn_beta\")\n",
    "    bn_mmean = relay.var(\"bn_mean\")\n",
    "    bn_mvar = relay.var(\"bn_var\")\n",
    "    simple_net = relay.nn.conv2d(\n",
    "        data=data, weight=weight, kernel_size=(3, 3), channels=out_channels, padding=(1, 1)\n",
    "    )\n",
    "    simple_net = relay.nn.batch_norm(simple_net, bn_gamma, bn_beta, bn_mmean, bn_mvar)[0]\n",
    "    simple_net = relay.nn.relu(simple_net)\n",
    "    simple_net = relay.nn.batch_flatten(simple_net)\n",
    "    simple_net = relay.nn.dense(simple_net, dense_weight)\n",
    "    simple_net = relay.Function(relay.analysis.free_vars(simple_net), simple_net)\n",
    "    data_shape = (batch_size, 3, img_size, img_size)\n",
    "    net, params = testing.create_workload(simple_net)\n",
    "    return net, params, data_shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */, %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */, %bn_gamma: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_beta: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_mean: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_var: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %dweight: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */) -> Tensor[(2, 1), float16] {\n",
      "  %0 = nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  %1 = nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  %2 = (%0, %1) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(1, 16, 8, 8), float16]) */;\n",
      "  %3 = concatenate(%2) /* ty=Tensor[(2, 16, 8, 8), float16] */;\n",
      "  %4 = nn.batch_norm(%3, %bn_gamma, %bn_beta, %bn_mean, %bn_var) /* ty=(Tensor[(2, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */;\n",
      "  %5 = %4.0 /* ty=Tensor[(2, 16, 8, 8), float16] */;\n",
      "  %6 = nn.relu(%5) /* ty=Tensor[(2, 16, 8, 8), float16] */;\n",
      "  %7 = nn.batch_flatten(%6) /* ty=Tensor[(2, 1024), float16] */;\n",
      "  nn.dense(%7, %dweight, units=None) /* ty=Tensor[(2, 1), float16] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_skip_net():\n",
    "    img_size = 8\n",
    "    out_channels = 16\n",
    "    batch_size = 1\n",
    "    data = relay.var(\"data\", relay.TensorType((batch_size, 3, img_size, img_size), \"float16\"))\n",
    "    dense_weight = relay.var(\n",
    "        \"dweight\", relay.TensorType((batch_size, 16 * img_size * img_size), \"float16\")\n",
    "    )\n",
    "    weight = relay.var(\"weight\")\n",
    "    second_weight = relay.var(\"second_weight\")\n",
    "    bn_gamma = relay.var(\"bn_gamma\")\n",
    "    bn_beta = relay.var(\"bn_beta\")\n",
    "    bn_mmean = relay.var(\"bn_mean\")\n",
    "    bn_mvar = relay.var(\"bn_var\")\n",
    "    x0 = relay.nn.conv2d(\n",
    "        data=data, weight=weight, kernel_size=(3, 3), channels=out_channels, padding=(1, 1)\n",
    "    )\n",
    "    x1 = relay.nn.conv2d(\n",
    "        data=data, weight=weight, kernel_size=(3, 3), channels=out_channels, padding=(1, 1)\n",
    "    )\n",
    "    simple_net = relay.op.concatenate(relay.Tuple([x0, x1]), axis=0)\n",
    "    simple_net = relay.nn.batch_norm(simple_net, bn_gamma, bn_beta, bn_mmean, bn_mvar)[0]\n",
    "    simple_net = relay.nn.relu(simple_net)\n",
    "    simple_net = relay.nn.batch_flatten(simple_net)\n",
    "    simple_net = relay.nn.dense(simple_net, dense_weight)\n",
    "    simple_net = relay.Function(relay.analysis.free_vars(simple_net), simple_net)\n",
    "    data_shape = (batch_size, 3, img_size, img_size)\n",
    "    net, params = testing.create_workload(simple_net)\n",
    "    return net, params, data_shape\n",
    "\n",
    "print(get_skip_net()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = get_skip_net()[0]['main'].body\n",
    "body = run_opt_pass(body, transform.ToANormalForm())\n",
    "body = run_opt_pass(body, transform.InferType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetNode(Var(x_51), CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x6d1fb98), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), LetNode(Var(x_52), CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x6c03a68), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), LetNode(Var(x_53), Tuple([Var(x_51), Var(x_52)]), LetNode(Var(x_54), CallNode(Op(concatenate), [Var(x_53)], relay.attrs.ConcatenateAttrs(0x6cbe958), [TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([1, 16, 8, 8], float16)])]), LetNode(Var(x_55), CallNode(Op(nn.batch_norm), [Var(x_54), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x6bfd428), [TensorType([2, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), LetNode(Var(x_56), TupleGetItemNode(Var(x_55), 0), LetNode(Var(x_57), CallNode(Op(nn.relu), [Var(x_56)], (nullptr), [TensorType([2, 16, 8, 8], float16)]), LetNode(Var(x_58), CallNode(Op(nn.batch_flatten), [Var(x_57)], (nullptr), [TensorType([2, 16, 8, 8], float16)]), LetNode(Var(x_59), CallNode(Op(nn.dense), [Var(x_58), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x6bf3428), [TensorType([2, 1024], float16), TensorType([1, 1024], float16)]), Var(x_59))))))))))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LetNode(\n",
    "    Var(x_51), \n",
    "    CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x6d1fb98), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), \n",
    "    LetNode(\n",
    "        Var(x_52), \n",
    "        CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x6c03a68), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), \n",
    "        LetNode(\n",
    "            Var(x_53), \n",
    "            Tuple([Var(x_51), Var(x_52)]), \n",
    "            LetNode(\n",
    "                Var(x_54), \n",
    "                CallNode(Op(concatenate), [Var(x_53)], relay.attrs.ConcatenateAttrs(0x6cbe958), [TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([1, 16, 8, 8], float16)])]), \n",
    "                LetNode(\n",
    "                    Var(x_55), \n",
    "                    CallNode(Op(nn.batch_norm), [Var(x_54), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x6bfd428), [TensorType([2, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), \n",
    "                    LetNode(Var(x_56), TupleGetItemNode(Var(x_55), 0), LetNode(Var(x_57), CallNode(Op(nn.relu), [Var(x_56)], (nullptr), [TensorType([2, 16, 8, 8], float16)]), LetNode(Var(x_58), CallNode(Op(nn.batch_flatten), [Var(x_57)], (nullptr), [TensorType([2, 16, 8, 8], float16)]), LetNode(Var(x_59), CallNode(Op(nn.dense), [Var(x_58), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x6bf3428), [TensorType([2, 1024], float16), TensorType([1, 1024], float16)]), Var(x_59))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LetNode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LetNode(\n\u001b[1;32m      2\u001b[0m     Var(x_42, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m      3\u001b[0m     CallNode(Op(nn\u001b[39m.\u001b[39mconv2d), [Var(data, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), Var(weight, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], float16))], relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mConv2DAttrs(\u001b[39m0x6c7b508\u001b[39m), [TensorType([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], float16)]\n\u001b[1;32m      4\u001b[0m     ), \n\u001b[1;32m      5\u001b[0m     LetNode(\n\u001b[1;32m      6\u001b[0m         Var(x_43, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m      7\u001b[0m         CallNode(Op(nn\u001b[39m.\u001b[39mconv2d), [Var(data, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), Var(weight, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], float16))], relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mConv2DAttrs(\u001b[39m0x6c2a268\u001b[39m), [TensorType([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], float16)]\n\u001b[1;32m      8\u001b[0m         ), \n\u001b[1;32m      9\u001b[0m         LetNode(\n\u001b[1;32m     10\u001b[0m             Var(x_44, ty\u001b[39m=\u001b[39mTupleTypeNode([TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)])), \n\u001b[1;32m     11\u001b[0m             Tuple([Var(x_42, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), Var(x_43, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16))]\n\u001b[1;32m     12\u001b[0m             ), \n\u001b[1;32m     13\u001b[0m             LetNode(\n\u001b[1;32m     14\u001b[0m                 Var(x_45, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m     15\u001b[0m                 CallNode(Op(concatenate), [Var(x_44, ty\u001b[39m=\u001b[39mTupleTypeNode([TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)]))], relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mConcatenateAttrs(\u001b[39m0x6c938b8\u001b[39m), [TupleTypeNode([TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)])]\n\u001b[1;32m     16\u001b[0m                 ), \n\u001b[1;32m     17\u001b[0m                 LetNode(\n\u001b[1;32m     18\u001b[0m                     Var(x_46, ty\u001b[39m=\u001b[39mTupleTypeNode([TensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16)])), \n\u001b[1;32m     19\u001b[0m                     CallNode(Op(nn\u001b[39m.\u001b[39mbatch_norm), [Var(x_45, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), Var(bn_gamma, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16)), Var(bn_beta, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16)), Var(bn_mean, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16)), Var(bn_var, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16))], relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mBatchNormAttrs(\u001b[39m0x6cb11b8\u001b[39m), [TensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16)]\n\u001b[1;32m     20\u001b[0m                     ), \n\u001b[1;32m     21\u001b[0m                     LetNode(Var(x_47, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), TupleGetItemNode(Var(x_46, ty\u001b[39m=\u001b[39mTupleTypeNode([TensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16)])), \u001b[39m0\u001b[39m), LetNode(Var(x_48, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), CallNode(Op(nn\u001b[39m.\u001b[39mrelu), [Var(x_47, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16))], (nullptr), [TensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)]), LetNode(Var(x_49, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m1024\u001b[39m], float16)), CallNode(Op(nn\u001b[39m.\u001b[39mbatch_flatten), [Var(x_48, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16))], (nullptr), [TensorType([\u001b[39m2\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)]), LetNode(Var(x_50, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m], float16)), CallNode(Op(nn\u001b[39m.\u001b[39mdense), [Var(x_49, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m1024\u001b[39m], float16)), Var(dweight, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16))], relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mDenseAttrs(\u001b[39m0x6b79f78\u001b[39m), [TensorType([\u001b[39m2\u001b[39m, \u001b[39m1024\u001b[39m], float16), TensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16)]), Var(x_50, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m], float16)))))))))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LetNode' is not defined"
     ]
    }
   ],
   "source": [
    "LetNode(\n",
    "    Var(x_42, ty=TensorType([1, 16, 8, 8], float16)), \n",
    "    CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x6c7b508), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]\n",
    "    ), \n",
    "    LetNode(\n",
    "        Var(x_43, ty=TensorType([1, 16, 8, 8], float16)), \n",
    "        CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x6c2a268), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]\n",
    "        ), \n",
    "        LetNode(\n",
    "            Var(x_44, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([1, 16, 8, 8], float16)])), \n",
    "            Tuple([Var(x_42, ty=TensorType([1, 16, 8, 8], float16)), Var(x_43, ty=TensorType([1, 16, 8, 8], float16))]\n",
    "            ), \n",
    "            LetNode(\n",
    "                Var(x_45, ty=TensorType([2, 16, 8, 8], float16)), \n",
    "                CallNode(Op(concatenate), [Var(x_44, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([1, 16, 8, 8], float16)]))], relay.attrs.ConcatenateAttrs(0x6c938b8), [TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([1, 16, 8, 8], float16)])]\n",
    "                ), \n",
    "                LetNode(\n",
    "                    Var(x_46, ty=TupleTypeNode([TensorType([2, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), \n",
    "                    CallNode(Op(nn.batch_norm), [Var(x_45, ty=TensorType([2, 16, 8, 8], float16)), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x6cb11b8), [TensorType([2, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]\n",
    "                    ), \n",
    "                    LetNode(Var(x_47, ty=TensorType([2, 16, 8, 8], float16)), TupleGetItemNode(Var(x_46, ty=TupleTypeNode([TensorType([2, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), 0), LetNode(Var(x_48, ty=TensorType([2, 16, 8, 8], float16)), CallNode(Op(nn.relu), [Var(x_47, ty=TensorType([2, 16, 8, 8], float16))], (nullptr), [TensorType([2, 16, 8, 8], float16)]), LetNode(Var(x_49, ty=TensorType([2, 1024], float16)), CallNode(Op(nn.batch_flatten), [Var(x_48, ty=TensorType([2, 16, 8, 8], float16))], (nullptr), [TensorType([2, 16, 8, 8], float16)]), LetNode(Var(x_50, ty=TensorType([2, 1], float16)), CallNode(Op(nn.dense), [Var(x_49, ty=TensorType([2, 1024], float16)), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x6b79f78), [TensorType([2, 1024], float16), TensorType([1, 1024], float16)]), Var(x_50, ty=TensorType([2, 1], float16)))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[TupleGetItemNode(\n",
    "    CallNode(Op(nn.batch_norm), \n",
    "        [CallNode(Op(concatenate), \n",
    "        [Tuple([CallNode(Op(nn.conv2d), \n",
    "        [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], \n",
    "        relay.attrs.Conv2DAttrs(0x6d34998), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), \n",
    "        CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], \n",
    "        relay.attrs.Conv2DAttrs(0x6bfeed8), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)])])], \n",
    "        relay.attrs.ConcatenateAttrs(0x6c1cbe8), \n",
    "        [TupleTypeNode([TensorType([1, 16, 8, 8], float16), \n",
    "        TensorType([1, 16, 8, 8], float16)])]), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x6c05b58), [TensorType([2, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), 0)], (nullptr), [TensorType([2, 16, 8, 8], float16)])], (nullptr), [TensorType([2, 16, 8, 8], float16)]), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x6c6c018), [TensorType([2, 1024], float16), TensorType([1, 1024], float16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, params, data_shape = get_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(nn.dense), [CallNode(Op(nn.batch_flatten), [CallNode(Op(nn.relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x65c2968), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x331cbf8), [TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), 0)], (nullptr), [TensorType([1, 16, 8, 8], float16)])], (nullptr), [TensorType([1, 16, 8, 8], float16)]), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x331d478), [TensorType([1, 1024], float16), TensorType([1, 1024], float16)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net['main'].body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CallNode(Op(nn.dense), [CallNode(Op(nn.batch_flatten), [CallNode(Op(nn.relu), [TupleGetItemNode(CallNode(Op(nn.batch_norm), [CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x65c2968), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(\n",
    "    bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x331cbf8), [TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), 0)], (nullptr), [TensorType([1, 16, 8, 8], float16)])], (nullptr), [TensorType([1, 16, 8, 8], float16)]), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x331d478), [TensorType([1, 1024], float16), TensorType([1, 1024], float16)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets explore\n",
    "body = net['main'].body\n",
    "body = run_opt_pass(body, transform.ToANormalForm())\n",
    "body = run_opt_pass(body, transform.InferType())\n",
    "cur = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */;\n",
      "free_var %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */;\n",
      "let %x_0: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "free_var %bn_gamma: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "free_var %bn_beta: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "free_var %bn_mean: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "free_var %bn_var: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "let %x_1: (Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */ = nn.batch_norm(%x_0, %bn_gamma, %bn_beta, %bn_mean, %bn_var) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */;\n",
      "let %x_2: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = %x_1.0 /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "let %x_3: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = nn.relu(%x_2) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "let %x_4: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */ = nn.batch_flatten(%x_3) /* ty=Tensor[(1, 1024), float16] */;\n",
      "free_var %dweight: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */;\n",
      "let %x_5: Tensor[(1, 1), float16] /* ty=Tensor[(1, 1), float16] */ = nn.dense(%x_4, %dweight, units=None) /* ty=Tensor[(1, 1), float16] */;\n",
      "%x_5\n"
     ]
    }
   ],
   "source": [
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */;\n",
      "free_var %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */;\n",
      "nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */\n",
      "<class 'tvm.relay.expr.Call'>\n"
     ]
    }
   ],
   "source": [
    "pre = cur\n",
    "cur = cur.value\n",
    "print(cur)\n",
    "print(type(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.expr.Let"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetNode(Var(x_0, ty=TensorType([1, 16, 8, 8], float16)), CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x65c2968), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]), LetNode(Var(x_1, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), CallNode(Op(nn.batch_norm), [Var(x_0, ty=TensorType([1, 16, 8, 8], float16)), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x331cbf8), [TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), LetNode(Var(x_2, ty=TensorType([1, 16, 8, 8], float16)), TupleGetItemNode(Var(x_1, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), 0), LetNode(Var(x_3, ty=TensorType([1, 16, 8, 8], float16)), CallNode(Op(nn.relu), [Var(x_2, ty=TensorType([1, 16, 8, 8], float16))], (nullptr), [TensorType([1, 16, 8, 8], float16)]), LetNode(Var(x_4, ty=TensorType([1, 1024], float16)), CallNode(Op(nn.batch_flatten), [Var(x_3, ty=TensorType([1, 16, 8, 8], float16))], (nullptr), [TensorType([1, 16, 8, 8], float16)]), LetNode(Var(x_5, ty=TensorType([1, 1], float16)), CallNode(Op(nn.dense), [Var(x_4, ty=TensorType([1, 1024], float16)), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x331d478), [TensorType([1, 1024], float16), TensorType([1, 1024], float16)]), Var(x_5, ty=TensorType([1, 1], float16))))))))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var(x_0, ty=TensorType([1, 16, 8, 8], float16))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(nn.conv2d), [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], relay.attrs.Conv2DAttrs(0x65c2968), [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetNode(Var(x_1, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), CallNode(Op(nn.batch_norm), [Var(x_0, ty=TensorType([1, 16, 8, 8], float16)), Var(bn_gamma, ty=TensorType([16], float16)), Var(bn_beta, ty=TensorType([16], float16)), Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))], relay.attrs.BatchNormAttrs(0x331cbf8), [TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]), LetNode(Var(x_2, ty=TensorType([1, 16, 8, 8], float16)), TupleGetItemNode(Var(x_1, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), 0), LetNode(Var(x_3, ty=TensorType([1, 16, 8, 8], float16)), CallNode(Op(nn.relu), [Var(x_2, ty=TensorType([1, 16, 8, 8], float16))], (nullptr), [TensorType([1, 16, 8, 8], float16)]), LetNode(Var(x_4, ty=TensorType([1, 1024], float16)), CallNode(Op(nn.batch_flatten), [Var(x_3, ty=TensorType([1, 16, 8, 8], float16))], (nullptr), [TensorType([1, 16, 8, 8], float16)]), LetNode(Var(x_5, ty=TensorType([1, 1], float16)), CallNode(Op(nn.dense), [Var(x_4, ty=TensorType([1, 1024], float16)), Var(dweight, ty=TensorType([1, 1024], float16))], relay.attrs.DenseAttrs(0x331d478), [TensorType([1, 1024], float16), TensorType([1, 1024], float16)]), Var(x_5, ty=TensorType([1, 1], float16)))))))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LetNode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LetNode(\n\u001b[1;32m      2\u001b[0m     Var(x_0, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m      3\u001b[0m     CallNode(\n\u001b[1;32m      4\u001b[0m         Op(nn\u001b[39m.\u001b[39mconv2d), \n\u001b[1;32m      5\u001b[0m         [Var(data, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), Var(weight, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], float16))], \n\u001b[1;32m      6\u001b[0m         relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mConv2DAttrs(\u001b[39m0x65c2968\u001b[39m), \n\u001b[1;32m      7\u001b[0m         [TensorType([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m], float16)]\n\u001b[1;32m      8\u001b[0m     ), \n\u001b[1;32m      9\u001b[0m     LetNode(\n\u001b[1;32m     10\u001b[0m         Var(x_1, ty\u001b[39m=\u001b[39mTupleTypeNode([TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16)])), \n\u001b[1;32m     11\u001b[0m         CallNode(\n\u001b[1;32m     12\u001b[0m             Op(nn\u001b[39m.\u001b[39mbatch_norm), \n\u001b[1;32m     13\u001b[0m             [\n\u001b[1;32m     14\u001b[0m                 Var(x_0, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m     15\u001b[0m                 Var(bn_gamma, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16)), \n\u001b[1;32m     16\u001b[0m                 Var(bn_beta, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16)), \n\u001b[1;32m     17\u001b[0m                 Var(bn_mean, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16)), Var(bn_var, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m16\u001b[39m], float16))\n\u001b[1;32m     18\u001b[0m             ], \n\u001b[1;32m     19\u001b[0m             relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mBatchNormAttrs(\u001b[39m0x331cbf8\u001b[39m), \n\u001b[1;32m     20\u001b[0m             [TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16)]\n\u001b[1;32m     21\u001b[0m         ), \n\u001b[1;32m     22\u001b[0m         LetNode(\n\u001b[1;32m     23\u001b[0m             Var(x_2, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m     24\u001b[0m             TupleGetItemNode(Var(x_1, ty\u001b[39m=\u001b[39mTupleTypeNode([TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16), TensorType([\u001b[39m16\u001b[39m], float16)])), \u001b[39m0\u001b[39m), \n\u001b[1;32m     25\u001b[0m             LetNode(\n\u001b[1;32m     26\u001b[0m                 Var(x_3, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)), \n\u001b[1;32m     27\u001b[0m                 CallNode(\n\u001b[1;32m     28\u001b[0m                     Op(nn\u001b[39m.\u001b[39mrelu), \n\u001b[1;32m     29\u001b[0m                     [Var(x_2, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16))], \n\u001b[1;32m     30\u001b[0m                     (nullptr), \n\u001b[1;32m     31\u001b[0m                     [TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)]\n\u001b[1;32m     32\u001b[0m                 ), \n\u001b[1;32m     33\u001b[0m                 LetNode(Var(x_4, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16)), CallNode(Op(nn\u001b[39m.\u001b[39mbatch_flatten), [Var(x_3, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16))], (nullptr), [TensorType([\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m], float16)]), LetNode(Var(x_5, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], float16)), CallNode(Op(nn\u001b[39m.\u001b[39mdense), [Var(x_4, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16)), Var(dweight, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16))], relay\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mDenseAttrs(\u001b[39m0x331d478\u001b[39m), [TensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16), TensorType([\u001b[39m1\u001b[39m, \u001b[39m1024\u001b[39m], float16)]), Var(x_5, ty\u001b[39m=\u001b[39mTensorType([\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], float16))))))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LetNode' is not defined"
     ]
    }
   ],
   "source": [
    "LetNode(\n",
    "    Var(x_0, ty=TensorType([1, 16, 8, 8], float16)), \n",
    "    CallNode(\n",
    "        Op(nn.conv2d), \n",
    "        [Var(data, ty=TensorType([1, 3, 8, 8], float16)), Var(weight, ty=TensorType([16, 3, 3, 3], float16))], \n",
    "        relay.attrs.Conv2DAttrs(0x65c2968), \n",
    "        [TensorType([1, 3, 8, 8], float16), TensorType([16, 3, 3, 3], float16)]\n",
    "    ), \n",
    "    LetNode(\n",
    "        Var(x_1, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), \n",
    "        CallNode(\n",
    "            Op(nn.batch_norm), \n",
    "            [\n",
    "                Var(x_0, ty=TensorType([1, 16, 8, 8], float16)), \n",
    "                Var(bn_gamma, ty=TensorType([16], float16)), \n",
    "                Var(bn_beta, ty=TensorType([16], float16)), \n",
    "                Var(bn_mean, ty=TensorType([16], float16)), Var(bn_var, ty=TensorType([16], float16))\n",
    "            ], \n",
    "            relay.attrs.BatchNormAttrs(0x331cbf8), \n",
    "            [TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16), TensorType([16], float16)]\n",
    "        ), \n",
    "        LetNode(\n",
    "            Var(x_2, ty=TensorType([1, 16, 8, 8], float16)), \n",
    "            TupleGetItemNode(Var(x_1, ty=TupleTypeNode([TensorType([1, 16, 8, 8], float16), TensorType([16], float16), TensorType([16], float16)])), 0), \n",
    "            LetNode(\n",
    "                Var(x_3, ty=TensorType([1, 16, 8, 8], float16)), \n",
    "                CallNode(\n",
    "                    Op(nn.relu), \n",
    "                    [Var(x_2, ty=TensorType([1, 16, 8, 8], float16))], \n",
    "                    (nullptr), \n",
    "                    [TensorType([1, 16, 8, 8], float16)]\n",
    "                ), \n",
    "                LetNode(\n",
    "                    Var(x_4, ty=TensorType([1, 1024], float16)), \n",
    "                    CallNode(\n",
    "                        Op(nn.batch_flatten), \n",
    "                        [Var(x_3, ty=TensorType([1, 16, 8, 8], float16))], \n",
    "                        (nullptr), \n",
    "                        [TensorType([1, 16, 8, 8], float16)]\n",
    "                    ), \n",
    "                    LetNode(\n",
    "                        Var(x_5, ty=TensorType([1, 1], float16)), \n",
    "                        CallNode(\n",
    "                            Op(nn.dense), \n",
    "                            [Var(x_4, ty=TensorType([1, 1024], float16)), Var(dweight, ty=TensorType([1, 1024], float16))], \n",
    "                            relay.attrs.DenseAttrs(0x331d478), [TensorType([1, 1024], float16), TensorType([1, 1024], float16)]\n",
    "                        ), \n",
    "                        Var(x_5, ty=TensorType([1, 1], float16))\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_split(expr, split_conf, params=None):\n",
    "    \"\"\"Splitting the graph into a list of subgraphs\"\"\"\n",
    "\n",
    "    def get_dep_var(sub_var_dep):\n",
    "        return [var for var in sub_var_dep[len(sub_var_dep) - 1][\"ref_nodes\"]]\n",
    "\n",
    "    def parse_dependency(value, snode_dep, new_input_idx):\n",
    "        new_args = []\n",
    "        need_update = False\n",
    "        for var in value.args:\n",
    "            is_free_var = False\n",
    "            for dep in snode_dep[:-1]:\n",
    "                if var in dep[\"nodes\"]:\n",
    "                    # Mark the previous subgraph node as a dependency.\n",
    "                    dep[\"nodes\"][var] += 1\n",
    "                    dep[\"ref_nodes\"][var] = dep[\"nodes\"][var]\n",
    "                    # The var of this call is a free_var\n",
    "                    is_free_var = True\n",
    "            # if the var of this call is a free_var, recreate it and give it a fixed input name.\n",
    "            if is_free_var:\n",
    "                need_update = True\n",
    "                new_args.append(relay.var(f\"data_n_{new_input_idx}\", var.checked_type))\n",
    "                new_input_idx += 1\n",
    "            else:\n",
    "                new_args.append(var)\n",
    "        # if the 'tvm.relay.expr.Call' has a free_var, recreate it with new name as 'data_n_*'.\n",
    "        if need_update:\n",
    "            value = tvm.relay.expr.Call(\n",
    "                value.op, new_args, value.attrs, value.type_args, value.span\n",
    "            )\n",
    "        return value, snode_dep, new_input_idx\n",
    "\n",
    "    def merge_constant_expr(constant_expr, expr):\n",
    "        # merge constant express with a express\n",
    "        if not isinstance(constant_expr.body, tvm.relay.expr.Let):\n",
    "            return tvm.relay.expr.Let(constant_expr.var, constant_expr.value, expr)\n",
    "\n",
    "        return tvm.relay.expr.Let(\n",
    "            constant_expr.var, constant_expr.value, merge_constant_expr(constant_expr.body, expr)\n",
    "        )\n",
    "\n",
    "    def _recursion(anf, pipeline_mods, split_conf, constant_expr):\n",
    "        # Enumurate all operators of compute graph, then split the compute graph into a group of\n",
    "        # subgraph.\n",
    "        nonlocal operator_index_map\n",
    "        nonlocal new_input_idx\n",
    "        nonlocal snode_dep\n",
    "        # Get last element in snode_dep : current node's dependency\n",
    "        cur_node_dep = snode_dep[len(snode_dep) - 1]\n",
    "        # If function -> decouple\n",
    "        if isinstance(anf, tvm.relay.Function):\n",
    "            return tvm.relay.Function(\n",
    "                anf.params,\n",
    "                _recursion(anf.body, pipeline_mods, split_conf, constant_expr),\n",
    "                anf.ret_type,\n",
    "                anf.type_params,\n",
    "                anf.attrs,\n",
    "            )\n",
    "        # Function of Let\n",
    "        if isinstance(anf, tvm.relay.expr.Let):\n",
    "            value = anf.value\n",
    "            # record the constant expr to make sure all sugraphs can find correct constant.\n",
    "            if isinstance(value, tvm.relay.expr.Constant):\n",
    "                # cosntant_expr is initally None\n",
    "                if not constant_expr:\n",
    "                    constant_expr = tvm.relay.expr.Let(anf.var, value, anf.var)\n",
    "                else:\n",
    "                    constant_expr = tvm.relay.expr.Let(anf.var, value, constant_expr)\n",
    "            if isinstance(value, tvm.relay.expr.Call):\n",
    "                new_args = []\n",
    "                # build current var list\n",
    "                cur_node_dep[\"nodes\"][anf.var] = 0\n",
    "                # Get the dependency information of the nodes.\n",
    "                value, snode_dep, new_input_idx = parse_dependency(value, snode_dep, new_input_idx)\n",
    "                if isinstance(value.op, tvm.ir.Op):\n",
    "                    if value.op.name in operator_index_map:\n",
    "                        operator_index_map[value.op.name] += 1\n",
    "                    else:\n",
    "                        operator_index_map[value.op.name] = 0\n",
    "                    split_operator_name = split_conf[0][\"op_name\"] if split_conf else \"\"\n",
    "                    split_operator_index = split_conf[0][\"op_index\"] if split_conf else \"\"\n",
    "                    # if a operator name and repeating count in the network match with the values\n",
    "                    # of the 'split configuration', then this place is where we should do the\n",
    "                    # graph splitting.\n",
    "                    if (\n",
    "                        split_conf\n",
    "                        and split_operator_name in operator_index_map\n",
    "                        and operator_index_map[split_operator_name] >= split_operator_index\n",
    "                    ):\n",
    "                        # Do graph splitting.\n",
    "                        split_conf.pop(0)\n",
    "                        snode_dep.append({\"nodes\": {}, \"ref_nodes\": {}})\n",
    "                        ann = _recursion(\n",
    "                            anf.body,\n",
    "                            pipeline_mods,\n",
    "                            split_conf,\n",
    "                            constant_expr,\n",
    "                        )\n",
    "                        snode_dep.pop()\n",
    "                        dep_vars = get_dep_var(snode_dep)\n",
    "                        # When the nodes of the current subgraph are the depedency node of another\n",
    "                        # subgraph, we need to set them as the output of current subgraph.\n",
    "                        body = relay.Tuple(dep_vars) if len(dep_vars) > 1 else anf.var\n",
    "                        # when the operator of current subgraph uses previous subgraph constant\n",
    "                        # as the argument of a \"relay.expr.call\", such constant may become a free\n",
    "                        # varaible if the constant does not exist in the current subgraph.\n",
    "                        # merge the previous constant with current subgraph to avoid such issue.\n",
    "                        if constant_expr:\n",
    "                            ann = merge_constant_expr(constant_expr, ann)\n",
    "                        ann = run_opt_pass(ann, transform.ToGraphNormalForm())\n",
    "                        mod = tvm.IRModule.from_expr(ann)\n",
    "                        pipeline_mods.insert(0, mod)\n",
    "                        # Return the last node of the current subgraph.\n",
    "                        return tvm.relay.expr.Let(anf.var, value, body)\n",
    "            return tvm.relay.expr.Let(\n",
    "                anf.var,\n",
    "                value,\n",
    "                _recursion(anf.body, pipeline_mods, split_conf, constant_expr),\n",
    "            )\n",
    "        # Or End\n",
    "        else:\n",
    "            return anf\n",
    "\n",
    "    snode_dep = [{\"nodes\": {}, \"ref_nodes\": {}}]\n",
    "    pipeline_mods = []\n",
    "    operator_index_map = {}\n",
    "    # Used to tracking new input which caused by graph splitting.\n",
    "    new_input_idx = 0\n",
    "    constant_expr = None\n",
    "    subgraph_split_conf = split_conf.copy()\n",
    "    # Binding the parameters.\n",
    "    if params:\n",
    "        expr = build_module.bind_params_by_name(expr, params)\n",
    "    anf = run_opt_pass(expr, transform.ToANormalForm())\n",
    "    anf = run_opt_pass(anf, transform.InferType())\n",
    "    ann = _recursion(\n",
    "        anf,\n",
    "        pipeline_mods,\n",
    "        subgraph_split_conf,\n",
    "        constant_expr,\n",
    "    )\n",
    "    ann = run_opt_pass(ann.body, transform.ToGraphNormalForm())\n",
    "    mod = tvm.IRModule.from_expr(ann)\n",
    "    pipeline_mods.insert(0, mod)\n",
    "    return pipeline_mods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */, %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */, %bn_gamma: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_beta: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_mean: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_var: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %dweight: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */) -> Tensor[(1, 1), float16] {\n",
      "  %0 = nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  %1 = nn.batch_norm(%0, %bn_gamma, %bn_beta, %bn_mean, %bn_var) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */;\n",
      "  %2 = %1.0 /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  %3 = nn.relu(%2) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  %4 = nn.batch_flatten(%3) /* ty=Tensor[(1, 1024), float16] */;\n",
      "  nn.dense(%4, %dweight, units=None) /* ty=Tensor[(1, 1), float16] */\n",
      "} /* ty=fn (Tensor[(1, 3, 8, 8), float16], Tensor[(16, 3, 3, 3), float16], Tensor[(16), float16], Tensor[(16), float16], Tensor[(16), float16], Tensor[(16), float16], Tensor[(1, 1024), float16]) -> Tensor[(1, 1), float16] */\n"
     ]
    }
   ],
   "source": [
    "split_config = [{\"op_name\": \"nn.relu\", \"op_index\": 0}]\n",
    "print(net['main'])\n",
    "subgraphs = graph_split(net[\"main\"], split_config, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "netnet = run_opt_pass(net[\"main\"], transform.ToANormalForm())\n",
    "netnet = run_opt_pass(netnet, transform.InferType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */, %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */, %bn_gamma: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_beta: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_mean: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %bn_var: Tensor[(16), float16] /* ty=Tensor[(16), float16] */, %dweight: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */) -> Tensor[(1, 1), float16] {\n",
      "  let %x_12: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  let %x_13: (Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */ = nn.batch_norm(%x_12, %bn_gamma, %bn_beta, %bn_mean, %bn_var) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */;\n",
      "  let %x_14: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = %x_13.0 /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  let %x_15: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = nn.relu(%x_14) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  let %x_16: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */ = nn.batch_flatten(%x_15) /* ty=Tensor[(1, 1024), float16] */;\n",
      "  let %x_17: Tensor[(1, 1), float16] /* ty=Tensor[(1, 1), float16] */ = nn.dense(%x_16, %dweight, units=None) /* ty=Tensor[(1, 1), float16] */;\n",
      "  %x_17\n",
      "} /* ty=fn (Tensor[(1, 3, 8, 8), float16], Tensor[(16, 3, 3, 3), float16], Tensor[(16), float16], Tensor[(16), float16], Tensor[(16), float16], Tensor[(16), float16], Tensor[(1, 1024), float16]) -> Tensor[(1, 1), float16] */\n"
     ]
    }
   ],
   "source": [
    "print(netnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */;\n",
      "free_var %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */;\n",
      "let %x_12: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "free_var %bn_gamma: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "free_var %bn_beta: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "free_var %bn_mean: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "free_var %bn_var: Tensor[(16), float16] /* ty=Tensor[(16), float16] */;\n",
      "let %x_13: (Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */ = nn.batch_norm(%x_12, %bn_gamma, %bn_beta, %bn_mean, %bn_var) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */;\n",
      "let %x_14: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = %x_13.0 /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "let %x_15: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */ = nn.relu(%x_14) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "let %x_16: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */ = nn.batch_flatten(%x_15) /* ty=Tensor[(1, 1024), float16] */;\n",
      "free_var %dweight: Tensor[(1, 1024), float16] /* ty=Tensor[(1, 1024), float16] */;\n",
      "let %x_17: Tensor[(1, 1), float16] /* ty=Tensor[(1, 1), float16] */ = nn.dense(%x_16, %dweight, units=None) /* ty=Tensor[(1, 1), float16] */;\n",
      "%x_17\n"
     ]
    }
   ],
   "source": [
    "print(netnet.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_var %data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */;\n",
      "free_var %weight: Tensor[(16, 3, 3, 3), float16] /* ty=Tensor[(16, 3, 3, 3), float16] */;\n",
      "nn.conv2d(%data, %weight, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */\n"
     ]
    }
   ],
   "source": [
    "print(netnet.body.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.ir.container.Array'>\n",
      "free_var %data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */;\n",
      "%data\n"
     ]
    }
   ],
   "source": [
    "print(type(netnet.body.value.args))\n",
    "print(netnet.body.value.args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 8, 8), float16] /* ty=Tensor[(1, 3, 8, 8), float16] */) {\n",
      "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(16, 3, 3, 3), float16] */, padding=[1, 1, 1, 1], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  %1 = nn.batch_norm(%0, meta[relay.Constant][1] /* ty=Tensor[(16), float16] */, meta[relay.Constant][2] /* ty=Tensor[(16), float16] */, meta[relay.Constant][3] /* ty=Tensor[(16), float16] */, meta[relay.Constant][4] /* ty=Tensor[(16), float16] */) /* ty=(Tensor[(1, 16, 8, 8), float16], Tensor[(16), float16], Tensor[(16), float16]) */;\n",
      "  %2 = %1.0 /* ty=Tensor[(1, 16, 8, 8), float16] */;\n",
      "  nn.relu(%2) /* ty=Tensor[(1, 16, 8, 8), float16] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subgraphs[0]['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%data_n_0: Tensor[(1, 16, 8, 8), float16] /* ty=Tensor[(1, 16, 8, 8), float16] */) {\n",
       "  %0 = nn.batch_flatten(%data_n_0) /* ty=Tensor[(1, 1024), float16] */;\n",
       "  nn.dense(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 1024), float16] */, units=None) /* ty=Tensor[(1, 1), float16] */\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraphs[1]['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = Model(3, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cuda'\n",
    "dev = tvm.cuda()\n",
    "img_size = 256\n",
    "input_data = np.random.normal(0,1,(1,img_size,img_size,3)).astype(np.float32)\n",
    "# tvm result\n",
    "input_data = input_data.transpose([0, 3, 1, 2])\n",
    "\n",
    "shape_dict = {\"input_1\": input_data.shape}\n",
    "mod, params = relay.frontend.from_keras(model_keras, shape_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_1: Tensor[(1, 3, 256, 256), float32], %v_param_1: Tensor[(16, 3, 3, 3), float32], %v_param_2: Tensor[(16), float32], %v_param_3: Tensor[(16), float32], %v_param_4: Tensor[(16), float32], %v_param_5: Tensor[(16), float32], %v_param_6: Tensor[(16), float32], %v_param_7: Tensor[(16, 16, 3, 3), float32], %v_param_8: Tensor[(16), float32], %v_param_9: Tensor[(16), float32], %v_param_10: Tensor[(16), float32], %v_param_11: Tensor[(16), float32], %v_param_12: Tensor[(16), float32]) {\n",
       "  %0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %1 = nn.bias_add(%0, %v_param_2);\n",
       "  %2 = nn.batch_norm(%1, %v_param_3, %v_param_4, %v_param_5, %v_param_6, epsilon=0.001f);\n",
       "  %3 = %2.0;\n",
       "  %4 = nn.leaky_relu(%3, alpha=0.2f);\n",
       "  %5 = nn.conv2d(%4, %v_param_7, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]);\n",
       "  %6 = nn.bias_add(%5, %v_param_8);\n",
       "  %7 = nn.batch_norm(%6, %v_param_9, %v_param_10, %v_param_11, %v_param_12, epsilon=0.001f);\n",
       "  %7.0\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  7: TVMFuncCall\n  6: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  5: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  4: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  3: tvm::relay::backend::RelayBuildModule::OptimizeImpl(tvm::IRModule)\n  2: tvm::relay::backend::BindParamsInModule(tvm::IRModule, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::NDArray, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tvm::runtime::NDArray> > > const&)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     lib \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mbuild(mod, target, params\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:438\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    437\u001b[0m     bld_mod \u001b[39m=\u001b[39m BuildModule()\n\u001b[0;32m--> 438\u001b[0m     graph_json, runtime_mod, params \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39;49mbuild(\n\u001b[1;32m    439\u001b[0m         mod\u001b[39m=\u001b[39;49mir_mod,\n\u001b[1;32m    440\u001b[0m         target\u001b[39m=\u001b[39;49mraw_targets,\n\u001b[1;32m    441\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    442\u001b[0m         executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[1;32m    443\u001b[0m         runtime\u001b[39m=\u001b[39;49mruntime,\n\u001b[1;32m    444\u001b[0m         workspace_memory_pools\u001b[39m=\u001b[39;49mworkspace_memory_pools,\n\u001b[1;32m    445\u001b[0m         constant_memory_pools\u001b[39m=\u001b[39;49mconstant_memory_pools,\n\u001b[1;32m    446\u001b[0m         mod_name\u001b[39m=\u001b[39;49mmod_name,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m     func_metadata \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_function_metadata()\n\u001b[1;32m    449\u001b[0m     devices \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[39mor\u001b[39;00m is_meta_schedule_enabled() \u001b[39mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[39m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(\n\u001b[1;32m    162\u001b[0m     mod,\n\u001b[1;32m    163\u001b[0m     target,\n\u001b[1;32m    164\u001b[0m     target_host,\n\u001b[1;32m    165\u001b[0m     executor,\n\u001b[1;32m    166\u001b[0m     runtime,\n\u001b[1;32m    167\u001b[0m     workspace_memory_pools,\n\u001b[1;32m    168\u001b[0m     constant_memory_pools,\n\u001b[1;32m    169\u001b[0m     mod_name,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[39m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  7: TVMFuncCall\n  6: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  5: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  4: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  3: tvm::relay::backend::RelayBuildModule::OptimizeImpl(tvm::IRModule)\n  2: tvm::relay::backend::BindParamsInModule(tvm::IRModule, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::NDArray, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tvm::runtime::NDArray> > > const&)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "<class 'tvm.ir.expr.GlobalVar'> has no attribute params",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [96], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m z \u001b[39m=\u001b[39m mm\u001b[39m.\u001b[39mget_global_vars()[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m f \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39mFunction(z\u001b[39m.\u001b[39;49mparams, z\u001b[39m.\u001b[39mbody)\n\u001b[1;32m      3\u001b[0m mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mIRModule()\n\u001b[1;32m      4\u001b[0m mod[\u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m f\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/runtime/object.py:67\u001b[0m, in \u001b[0;36mObject.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_node_api\u001b[39m.\u001b[39mNodeGetAttr(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)), name)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: <class 'tvm.ir.expr.GlobalVar'> has no attribute params"
     ]
    }
   ],
   "source": [
    "z = mm.get_global_vars()[0]\n",
    "f = relay.Function(z.params, z.body)\n",
    "mod = tvm.IRModule()\n",
    "mod['main'] = f\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvmgen_default_ccompiler_main_4\n",
      "tvmgen_default_ccompiler_main_0\n",
      "tvmgen_default_ccompiler_main_2\n",
      "main\n"
     ]
    }
   ],
   "source": [
    "for func in mm.functions:\n",
    "    print(func.astext().split('\\n')[-1].split('@')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "z = mm['tvmgen_default_ccompiler_main_0'](x,y)\n",
    "f = relay.Function([x, y], z)\n",
    "mod1 = tvm.IRModule()\n",
    "mod1['main'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.function.Function"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  2: TVMFuncCall\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  3: TVMFuncCall\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  0: tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  File \"/home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h\", line 777\nTVMError: In function ir.IRModule(0: Map<GlobalVar, BaseFunc>, 1: Map<GlobalTypeVar, relay.TypeData>) -> IRModule: error while converting argument 0: [21:29:35] /home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h:1863: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected Map[GlobalVar, BaseFunc], but got relay.Function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m z\u001b[39m.\u001b[39mattrs\u001b[39m.\u001b[39mglobal_symbol \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m z \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mwith_attr(\u001b[39m\"\u001b[39m\u001b[39mglobal_symbol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m mod \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39;49mIRModule(z)\n\u001b[1;32m      5\u001b[0m \u001b[39m# mod['main'] = z\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/ir/module.py:62\u001b[0m, in \u001b[0;36mIRModule.__init__\u001b[0;34m(self, functions, type_definitions)\u001b[0m\n\u001b[1;32m     60\u001b[0m         mapped_type_defs[k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     61\u001b[0m     type_definitions \u001b[39m=\u001b[39m mapped_type_defs\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__init_handle_by_constructor__(_ffi_api\u001b[39m.\u001b[39;49mIRModule, functions, type_definitions)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/object.py:136\u001b[0m, in \u001b[0;36mObjectBase.__init_handle_by_constructor__\u001b[0;34m(self, fconstructor, *args)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m# assign handle first to avoid error raising\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m handle \u001b[39m=\u001b[39m __init_by_constructor__(fconstructor, args)\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, ObjectHandle):\n\u001b[1;32m    138\u001b[0m     handle \u001b[39m=\u001b[39m ObjectHandle(handle)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:260\u001b[0m, in \u001b[0;36m__init_handle_by_constructor__\u001b[0;34m(fconstructor, args)\u001b[0m\n\u001b[1;32m    248\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    250\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    251\u001b[0m         fconstructor\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    259\u001b[0m ):\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    261\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    262\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  2: TVMFuncCall\n  1: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  0: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  3: TVMFuncCall\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::IRModule (tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)>::AssignTypedLambda<tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}>(tvm::{lambda(tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void>, tvm::runtime::Map<tvm::GlobalTypeVar, tvm::TypeData, void, void>)#2}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tvm::runtime::TVMRetValue)\n  1: tvm::runtime::TVMMovableArgValueWithContext_::operator tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void><tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  0: tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Map<tvm::GlobalVar, tvm::BaseFunc, void, void> >() const\n  File \"/home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h\", line 777\nTVMError: In function ir.IRModule(0: Map<GlobalVar, BaseFunc>, 1: Map<GlobalTypeVar, relay.TypeData>) -> IRModule: error while converting argument 0: [21:29:35] /home/jd/workspace/tvm-v0.9.0/include/tvm/runtime/packed_func.h:1863: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (!checked_type.defined()) is false: Expected Map[GlobalVar, BaseFunc], but got relay.Function\n"
     ]
    }
   ],
   "source": [
    "z = mm['tvmgen_default_ccompiler_main_0']\n",
    "z.attrs.global_symbol = 'main'\n",
    "z = z.with_attr(\"global_symbol\", \"main\")\n",
    "mod = tvm.IRModule(z)\n",
    "# mod['main'] = z\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func0 = func0.with_attr(\"global_symbol\", \"main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @main(%x: Tensor[(8, 8), float32], %y: Tensor[(8, 8), float32]) {\n",
       "  %0 = fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
       "    add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
       "  } /* ty=fn (Tensor[(8, 8), float32], Tensor[(8, 8), float32]) -> Tensor[(8, 8), float32] */;\n",
       "  %0(%x, %y)\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = mm['tvmgen_default_ccompiler_main_0']\n",
    "f = relay.Function(z.params, z.body)\n",
    "mod = tvm.IRModule()\n",
    "mod['main'] = f\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GraphExecutorFactoryModule' object has no attribute 'body'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lib\u001b[39m.\u001b[39;49mbody\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphExecutorFactoryModule' object has no attribute 'body'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */) {\n",
       "  add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
       "}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod2, target, params=params)\n",
    "    # lib = relay.build(mod2, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
      "  add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
      "} /* ty=fn (Tensor[(8, 8), float32], Tensor[(8, 8), float32]) -> Tensor[(8, 8), float32] */\n"
     ]
    }
   ],
   "source": [
    "print(mm['tvmgen_default_ccompiler_main_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%x: Tensor[(8, 8), float32], %y: Tensor[(8, 8), float32]) {\n",
      "  %0 = fn (%ccompiler_0_i0: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, %ccompiler_0_i1: Tensor[(8, 8), float32] /* ty=Tensor[(8, 8), float32] */, Inline=1, Compiler=\"ccompiler\", global_symbol=\"tvmgen_default_ccompiler_main_0\", Primitive=1) -> Tensor[(8, 8), float32] {\n",
      "    add(%ccompiler_0_i0, %ccompiler_0_i1) /* ty=Tensor[(8, 8), float32] */\n",
      "  } /* ty=fn (Tensor[(8, 8), float32], Tensor[(8, 8), float32]) -> Tensor[(8, 8), float32] */;\n",
      "  %0(%x, %y)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n",
    "    # lib = relay.build(mod2, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.relay.backend.executor_factory.GraphExecutorFactoryModule at 0x7fe15c70dd00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(type(legion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tvm.relay.function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mm['main']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = type(mm['tvmgen_default_ccompiler_main_0'])\n",
    "# mod = tvm.IRModule()\n",
    "# mod[\"main\"] = mm['tvmgen_default_ccompiler_main_0']\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legion = mm['tvmgen_default_ccompiler_main_0']\n",
    "# mod2 = tvm.IRModule()\n",
    "# mod2[\"main\"] = legion\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    # lib = relay.build(mm['tvmgen_default_ccompiler_main_0'], target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n",
    "    lib = relay.build(mm, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  8: TVMFuncCall\n  7: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  6: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  5: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::relay::backend::GraphExecutorCodegenModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::backend::GraphExecutorCodegen::Codegen(tvm::IRModule, tvm::relay::Function, tvm::runtime::String)\n  2: tvm::relay::tec::UpdateMainWorkspaceSize(tvm::IRModule const&, tvm::CompilationConfig const&, tvm::runtime::Map<tvm::RelayExpr, tvm::relay::backend::StorageInfo, void, void>)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m mod2[\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m legion\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mPassContext(opt_level\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[39m# lib = relay.build(mm['tvmgen_default_ccompiler_main_0'], target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     lib \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39;49mbuild(mod2, target, params\u001b[39m=\u001b[39;49mparams,mod_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtvmgen_default_ccompiler_main_0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:438\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    437\u001b[0m     bld_mod \u001b[39m=\u001b[39m BuildModule()\n\u001b[0;32m--> 438\u001b[0m     graph_json, runtime_mod, params \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39;49mbuild(\n\u001b[1;32m    439\u001b[0m         mod\u001b[39m=\u001b[39;49mir_mod,\n\u001b[1;32m    440\u001b[0m         target\u001b[39m=\u001b[39;49mraw_targets,\n\u001b[1;32m    441\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    442\u001b[0m         executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[1;32m    443\u001b[0m         runtime\u001b[39m=\u001b[39;49mruntime,\n\u001b[1;32m    444\u001b[0m         workspace_memory_pools\u001b[39m=\u001b[39;49mworkspace_memory_pools,\n\u001b[1;32m    445\u001b[0m         constant_memory_pools\u001b[39m=\u001b[39;49mconstant_memory_pools,\n\u001b[1;32m    446\u001b[0m         mod_name\u001b[39m=\u001b[39;49mmod_name,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m     func_metadata \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_function_metadata()\n\u001b[1;32m    449\u001b[0m     devices \u001b[39m=\u001b[39m bld_mod\u001b[39m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[39mor\u001b[39;00m is_meta_schedule_enabled() \u001b[39mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[39m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(\n\u001b[1;32m    162\u001b[0m     mod,\n\u001b[1;32m    163\u001b[0m     target,\n\u001b[1;32m    164\u001b[0m     target_host,\n\u001b[1;32m    165\u001b[0m     executor,\n\u001b[1;32m    166\u001b[0m     runtime,\n\u001b[1;32m    167\u001b[0m     workspace_memory_pools,\n\u001b[1;32m    168\u001b[0m     constant_memory_pools,\n\u001b[1;32m    169\u001b[0m     mod_name,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m autotvm\u001b[39m.\u001b[39mGLOBAL_SCOPE\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[39m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/tvm-v0.9.0/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  8: TVMFuncCall\n  7: tvm::relay::backend::RelayBuildModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#3}::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  6: tvm::relay::backend::RelayBuildModule::Build(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&, tvm::Target const&, tvm::relay::Executor const&, tvm::relay::Runtime const&, tvm::WorkspaceMemoryPools const&, tvm::ConstantMemoryPools const&, tvm::runtime::String)\n  5: tvm::relay::backend::RelayBuildModule::BuildRelay(tvm::IRModule, tvm::runtime::String const&)\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::relay::backend::GraphExecutorCodegenModule::GetFunction(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tvm::runtime::ObjectPtr<tvm::runtime::Object> const&)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::relay::backend::GraphExecutorCodegen::Codegen(tvm::IRModule, tvm::relay::Function, tvm::runtime::String)\n  2: tvm::relay::tec::UpdateMainWorkspaceSize(tvm::IRModule const&, tvm::CompilationConfig const&, tvm::runtime::Map<tvm::RelayExpr, tvm::relay::backend::StorageInfo, void, void>)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/home/jd/workspace/tvm-v0.9.0/src/ir/module.cc\", line 144\nValueError: Cannot find global var \"main\" in the Module\ncandidates are: [\"tvmgen_default_ccompiler_main_0\"]"
     ]
    }
   ],
   "source": [
    "# legion = mm['tvmgen_default_ccompiler_main_0']\n",
    "# mod2 = tvm.IRModule()\n",
    "# mod2[\"main\"] = legion\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    # lib = relay.build(mm['tvmgen_default_ccompiler_main_0'], target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n",
    "    lib = relay.build(mm, target, params=params,mod_name='tvmgen_default_ccompiler_main_0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mm, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jd/workspace/tvm-v0.9.0/python/tvm/driver/build_module.py:267: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mm, target, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.relay.backend.executor_factory.GraphExecutorFactoryModule at 0x7fe15b392190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.runtime.packed_func.PackedFunc at 0x7fdc8dacd240>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib['get_graph_json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_json_raw = lib['get_graph_json']()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "import json\n",
    "def show_graph(json_data, file_name=None):\n",
    "    if type(json_data) == str:\n",
    "        json_data = json.loads(json_data)\n",
    "    A = pgv.AGraph(directed=True)\n",
    "    for node_idx, node in enumerate(json_data['nodes']):\n",
    "        for src in node['inputs']:\n",
    "            # if args.show_size == 1:\n",
    "            if 1 == 1:\n",
    "                src_size = 1\n",
    "                for i in json_data['attrs']['shape'][1][src[0]]:\n",
    "                    src_size = src_size * i\n",
    "                \n",
    "                dst_size = 1\n",
    "                for i in json_data['attrs']['shape'][1][node_idx]:\n",
    "                    dst_size = dst_size * i\n",
    "                # print(src[0], json_data['nodes'][src[0]]['name'], src_size)\n",
    "\n",
    "                A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]) + \"[{}]\".format(src_size), node['name'] + '[{}]'.format(node_idx) + '{}'.format(json_data['attrs']['dltype'][1][node_idx]) + \"[{}]\".format(dst_size))\n",
    "            else:\n",
    "                A.add_edge(json_data['nodes'][src[0]]['name'] + '[{}]'.format(src[0]) + '{}'.format(json_data['attrs']['dltype'][1][src[0]]), node['name'] + '[{}]'.format(node_idx) + '{}'.format(json_data['attrs']['dltype'][1][node_idx]))\n",
    "    if file_name:\n",
    "        A.draw(file_name + '.png', format='png', prog='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(graph_json_raw, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

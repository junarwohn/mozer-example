{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import os\n",
    "import numpy as np\n",
    "from tvm.relay.testing import run_opt_pass\n",
    "from tvm import relay\n",
    "from tvm.relay import transform, build_module\n",
    "from tensorflow import keras\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.dataflow_pattern import *\n",
    "\n",
    "class QuantCallback(DFPatternCallback):\n",
    "    # A callback class to rewrite the matched pattern to a batch_norm op.\n",
    "    def __init__(self, name_hints, require_type=False):\n",
    "        super().__init__(require_type)\n",
    "        super().__init__(rewrite_once=True)\n",
    "\n",
    "        # self.tuple_get_item_node = is_tuple_get_item(wildcard(), 0)\n",
    "        # self.pattern_1 = self.tuple_get_item_node\n",
    "        # leaky_relu_node = is_op('nn.leaky_relu')(wildcard())| is_op('nn.relu')(wildcard())\n",
    "        # self.name_hints = name_hints\n",
    "        # print(name_hints[0])\n",
    "        # self.var = is_var(str(name_hints[0]))\n",
    "        self.var = is_expr(name_hints[0])\n",
    "        # self.param = wildcard()\n",
    "        # self.pattern = is_op(\"nn.conv2d\")(self.var, self.param)\n",
    "        self.pattern = self.var\n",
    "        self.counter = 0\n",
    "        self.tmp = []\n",
    "\n",
    "    def quant(self, node):\n",
    "        # cast_to_int8 = relay.cast(\n",
    "        #     relay.clip(\n",
    "        #         relay.round(\n",
    "        #             relay.multiply(node, relay.const(8.0))\n",
    "        #         ), \n",
    "        #         a_min=-127.0, a_max=127.0\n",
    "        #     ),\n",
    "        #     dtype=\"int8\"\n",
    "        # )\n",
    "\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(\n",
    "                        relay.subtract(node, relay.const(18.0))\n",
    "                        , relay.const(7.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        # result_node = relay.annotation.stop_fusion(cast_to_int8)\n",
    "        # self.tmp.append(result_node)\n",
    "        return cast_to_int8\n",
    "\n",
    "    def dequant(self, node):\n",
    "        # cast_to_float32 = relay.divide(\n",
    "        #     relay.cast(node, dtype='float32'), relay.const(8.0)\n",
    "        # )\n",
    "        cast_to_float32 = relay.add(\n",
    "                relay.divide(\n",
    "                relay.cast(node, dtype='float32'), relay.const(7.0))\n",
    "            , relay.const(18.0)\n",
    "        )\n",
    "        return cast_to_float32\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        print(\"quant\")\n",
    "        a = node_map[self.var][0]\n",
    "        print(pre)\n",
    "        print(a)\n",
    "        try:\n",
    "            if a.name_hint in self.name_hints:\n",
    "                print(\"asdasd\")\n",
    "                new_var = relay.var('input_0', relay.TensorType(a.checked_type.shape, 'int8'))\n",
    "                return relay.nn.conv2d(self.dequant(new_var), b)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return post\n",
    "        return post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./simple_model.h5\")\n",
    "data = np.random.randint(0, 256, size=(1, 256,256,3)) / 255\n",
    "data = data.transpose([0, 3, 1, 2])\n",
    "\n",
    "shape_dict = {\"input_1\": data.shape}\n",
    "\n",
    "mod, params = relay.frontend.from_keras(model, shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */, %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */, %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */) -> Tensor[(1, 16, 128i64, 128i64), float32] {\n",
      "  let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "  let %x_4: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "  let %x_5: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "  %x_5\n",
      "} /* ty=fn (Tensor[(1, 3, 256, 256), float32], Tensor[(16, 3, 3, 3), float32], Tensor[(16), float32]) -> Tensor[(1, 16, 128i64, 128i64), float32] */\n"
     ]
    }
   ],
   "source": [
    "anf = run_opt_pass(mod['main'], transform.ToANormalForm())\n",
    "anf = run_opt_pass(anf, transform.InferType())\n",
    "\n",
    "print(anf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcb = QuantCallback(['input_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcb = QuantCallback([relay.analysis.free_vars(anf.body)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "newanf = rewrite(qcb, anf.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Var(input_0, ty=TensorType([1, 3, 256, 256], int8))]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relay.analysis.free_vars(newanf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequant(node):\n",
    "    # cast_to_float32 = relay.divide(\n",
    "    #     relay.cast(node, dtype='float32'), relay.const(8.0)\n",
    "    # )\n",
    "    cast_to_float32 = relay.add(\n",
    "            relay.divide(\n",
    "            relay.cast(node, dtype='float32'), relay.const(7.0))\n",
    "        , relay.const(18.0)\n",
    "    )\n",
    "    # cast_to_float32 = run_opt_pass(cast_to_float32, transform.ToANormalForm())\n",
    "    # cast_to_float32 = run_opt_pass(cast_to_float32, transform.InferType())\n",
    "    return cast_to_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newanf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m newf \u001b[39m=\u001b[39m relay\u001b[39m.\u001b[39mFunction(relay\u001b[39m.\u001b[39manalysis\u001b[39m.\u001b[39mfree_vars(newanf), anf\u001b[39m.\u001b[39mbody)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'newanf' is not defined"
     ]
    }
   ],
   "source": [
    "newf = relay.Function(relay.analysis.free_vars(newanf), anf.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "free_var %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "free_var %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_5: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "%x_5\n"
     ]
    }
   ],
   "source": [
    "print(anf.body.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetNode(Var(x_3, ty=TensorType([1, 16, 256, 256], float32)), CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x2ff24698), [TensorType([1, 3, 256, 256], float32), TensorType([16, 3, 3, 3], float32)]), LetNode(Var(x_4, ty=TensorType([1, 16, 256, 256], float32)), CallNode(Op(nn.bias_add), [Var(x_3, ty=TensorType([1, 16, 256, 256], float32)), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x2ff52ec8), [TensorType([1, 16, 256, 256], float32), TensorType([16], float32)]), LetNode(Var(x_5, ty=TensorType([1, 16, (int64)128, (int64)128], float32)), CallNode(Op(nn.max_pool2d), [Var(x_4, ty=TensorType([1, 16, 256, 256], float32))], relay.attrs.MaxPool2DAttrs(0x2ff25db8), [TensorType([1, 16, 256, 256], float32)]), Var(x_5, ty=TensorType([1, 16, (int64)128, (int64)128], float32)))))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anf.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var(input_1, ty=TensorType([1, 3, 256, 256], float32))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anf.body.value.args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "anf = run_opt_pass(anf, transform.ToGraphNormalForm())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "free_var %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "%0 = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "free_var %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "%1 = nn.bias_add(%0, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "nn.max_pool2d(%1, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */\n"
     ]
    }
   ],
   "source": [
    "print(anf.body.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_0: Tensor[(1, 3, 256, 256), int8] /* ty=Tensor[(1, 3, 256, 256), int8] */;\n",
      "%0 = cast(%input_0, dtype=\"float32\") /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "%1 = divide(%0, 7f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "%2 = add(%1, 18f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "free_var %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "%3 = nn.conv2d(%2, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "free_var %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "%4 = nn.bias_add(%3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */\n"
     ]
    }
   ],
   "source": [
    "print(new_anf.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt =dequant(anf.body.value.args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_6: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */ = cast(%input_1, dtype=\"float32\") /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_7: float32 /* ty=float32 */ = 7f /* ty=float32 */;\n",
      "let %x_8: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */ = divide(%x_6, %x_7) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "let %x_9: float32 /* ty=float32 */ = 18f /* ty=float32 */;\n",
      "let %x_10: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */ = add(%x_8, %x_9) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "%x_10\n"
     ]
    }
   ],
   "source": [
    "print(tt.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var(x_3, ty=TensorType([1, 16, 256, 256], float32))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anf.body.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var(input_1, ty=TensorType([1, 3, 256, 256], float32))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relay.analysis.free_vars(anf.body)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = tvm.relay.expr.Var('input_0', relay.TensorType(anf.body.value.args[0].checked_type.shape, 'int8'))\n",
    "tt = dequant(new_input)\n",
    "new_anf = tvm.relay.expr.Let(relay.analysis.free_vars(anf.body)[0], tt, anf.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallNode(Op(nn.max_pool2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32))], relay.attrs.Conv2DAttrs(0x2ff24698), [TensorType([1, 3, 256, 256], float32), TensorType([16, 3, 3, 3], float32)]), Var(_param_2, ty=TensorType([16], float32))], relay.attrs.BiasAddAttrs(0x2ff52ec8), [TensorType([1, 16, 256, 256], float32), TensorType([16], float32)])], relay.attrs.MaxPool2DAttrs(0x2ff25db8), [TensorType([1, 16, 256, 256], float32)])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anf.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = new_anf\n",
    "ann = run_opt_pass(mod, transform.ToGraphNormalForm())\n",
    "mod = tvm.IRModule.from_expr(ann)['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_0: Tensor[(1, 3, 256, 256), int8] /* ty=Tensor[(1, 3, 256, 256), int8] */, %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */, %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */) {\n",
       "  %0 = cast(%input_0, dtype=\"float32\") /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %1 = divide(%0, 7f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %2 = add(%1, 18f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %3 = nn.conv2d(%2, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %4 = nn.bias_add(%3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */\n",
       "}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anf = run_opt_pass(new_anf, transform.ToGraphNormalForm())\n",
    "new_mod = tvm.IRModule.from_expr(new_anf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant(node):\n",
    "        cast_to_int8 = relay.cast(\n",
    "            relay.clip(\n",
    "                relay.round(\n",
    "                    relay.multiply(\n",
    "                        relay.subtract(node, relay.const(18.0))\n",
    "                        , relay.const(7.0))\n",
    "                ), \n",
    "                a_min=-127.0, a_max=127.0\n",
    "            ),\n",
    "            dtype=\"int8\"\n",
    "        )\n",
    "        # result_node = relay.annotation.stop_fusion(cast_to_int8)\n",
    "        # self.tmp.append(result_node)\n",
    "        return cast_to_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#[version = \"0.0.5\"]\n",
       "def @main(%input_0: Tensor[(1, 3, 256, 256), int8] /* ty=Tensor[(1, 3, 256, 256), int8] */, %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */, %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */) {\n",
       "  %0 = cast(%input_0, dtype=\"float32\") /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %1 = divide(%0, 7f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %2 = add(%1, 18f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %3 = nn.conv2d(%2, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %4 = nn.bias_add(%3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */\n",
       "}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_func = relay.Function(new_mod['main'].params, quant(new_mod['main'].body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fn (%input_0: Tensor[(1, 3, 256, 256), int8] /* ty=Tensor[(1, 3, 256, 256), int8] */, %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */, %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */) {\n",
       "  %0 = cast(%input_0, dtype=\"float32\") /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %1 = divide(%0, 7f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %2 = add(%1, 18f /* ty=float32 */) /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
       "  %3 = nn.conv2d(%2, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %4 = nn.bias_add(%3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
       "  %6 = subtract(%5, 18f);\n",
       "  %7 = multiply(%6, 7f);\n",
       "  %8 = round(%7);\n",
       "  %9 = clip(%8, a_min=-127f, a_max=127f);\n",
       "  cast(%9, dtype=\"int8\")\n",
       "}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=4):\n",
    "    lib = relay.build(new_func, 'cuda', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_0: Tensor[(1, 3, 256, 256), int8];\n",
      "%0 = cast(%input_0, dtype=\"float32\");\n",
      "%1 = divide(%0, 7f);\n",
      "add(%1, 18f)\n"
     ]
    }
   ],
   "source": [
    "print(tt.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_0: Tensor[(1, 3, 256, 256), int8];\n",
      "%0 = cast(%input_0, dtype=\"float32\");\n",
      "%1 = divide(%0, 7f);\n",
      "let %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */ = add(%1, 18f);\n",
      "free_var %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "free_var %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_5: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "%x_5\n"
     ]
    }
   ],
   "source": [
    "print(new_anf.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Var(input_0, ty=TensorType([1, 3, 256, 256], int8)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32)), Var(_param_2, ty=TensorType([16], float32))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_anf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.expr.Let"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tt.body.body.body.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm.relay.expr.Let(\n",
    "    anf.var,\n",
    "    value,\n",
    "    _dequant(anf.body),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "free_var %input_1: Tensor[(1, 3, 256, 256), float32] /* ty=Tensor[(1, 3, 256, 256), float32] */;\n",
      "free_var %v_param_1: Tensor[(16, 3, 3, 3), float32] /* ty=Tensor[(16, 3, 3, 3), float32] */;\n",
      "let %x_3: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.conv2d(%input_1, %v_param_1, padding=[1i64, 1i64, 1i64, 1i64], channels=16, kernel_size=[3, 3]) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "free_var %v_param_2: Tensor[(16), float32] /* ty=Tensor[(16), float32] */;\n",
      "let %x_4: Tensor[(1, 16, 256, 256), float32] /* ty=Tensor[(1, 16, 256, 256), float32] */ = nn.bias_add(%x_3, %v_param_2) /* ty=Tensor[(1, 16, 256, 256), float32] */;\n",
      "let %x_5: Tensor[(1, 16, 128i64, 128i64), float32] /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */ = nn.max_pool2d(%x_4, pool_size=[2, 2], strides=[2, 2], padding=[0i64, 0i64, 0i64, 0i64]) /* ty=Tensor[(1, 16, 128i64, 128i64), float32] */;\n",
      "%x_5\n"
     ]
    }
   ],
   "source": [
    "print(anf.body.astext(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Array' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m anf\u001b[39m.\u001b[39;49mbody\u001b[39m.\u001b[39;49mvalue\u001b[39m.\u001b[39;49margs[\u001b[39m0\u001b[39;49m] \u001b[39m=\u001b[39m dequant(anf\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Array' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "anf.body.value.args[0] = dequant(anf.body.value.args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relay.expr.Call"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(anf.body.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = is_var('input_1')\n",
    "pat = is_expr(relay.analysis.free_vars(anf.body)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Var(input_1, ty=TensorType([1, 3, 256, 256], float32)), Var(_param_1, ty=TensorType([16, 3, 3, 3], float32)), Var(_param_2, ty=TensorType([16], float32))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relay.analysis.free_vars(anf.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat.match(relay.analysis.free_vars(anf.body)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
